{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8e3d0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import unittest.mock\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import psutil\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tf_agents.agents.ppo import ppo_agent\n",
    "from tf_agents.environments import PyEnvironment, tf_py_environment, py_environment\n",
    "from tf_agents.networks import actor_distribution_network, value_network\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.trajectories import from_transition, time_step as ts, policy_step\n",
    "from tf_agents.specs import array_spec\n",
    "import tensorflow_probability as tfp\n",
    "from tf_agents.policies import tf_policy, py_tf_eager_policy, policy_saver, actor_policy\n",
    "from tf_agents.policies.py_policy import PyPolicy\n",
    "from tf_agents.utils import common\n",
    "from tensorflow.keras.optimizers.legacy import Optimizer\n",
    "from tensorflow.keras.optimizers.legacy import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a275af57",
   "metadata": {},
   "source": [
    "# Environment\n",
    "\n",
    "The `Standard_Env` class defines the game environment for a Tic-Tac-Toe-like game, supporting features like action masks and probabilistic placement. Unit tests ensure the environment behaves correctly under various conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5df8dc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tf_agents.environments import py_environment\n",
    "from tf_agents.specs import array_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "class Standard_Env(py_environment.PyEnvironment):\n",
    "    \"\"\"Tic-tac-toe environment for reinforcement learning with customizable board size, win conditions, and probabilistic placement.\n",
    "\n",
    "    Supports Standard (3x3), Random (3x3 with random placement), and Super Tic-Tac-Toe (12x12 cross-shaped) boards.\n",
    "    Implements reward shaping with live/dead patterns and step penalties to facilitate agent learning.\n",
    "    Inherits from PyEnvironment for TF-Agents compatibility.\n",
    "\n",
    "    Args:\n",
    "        board_size (tuple): Rows and columns of the board (e.g., (3, 3) for 3x3).\n",
    "        win_condition (list): Number of pieces needed to win in [row, column, diagonal].\n",
    "        unplayable_grids (np.ndarray, optional): 2D array marking unplayable squares (1=unplayable).\n",
    "        rewards (dict, optional): Reward values for win, lose, tie, patterns, etc.\n",
    "        def_level (int, optional): Defense level (default: 1, not used in this version).\n",
    "        discount (float, optional): Discount factor for future rewards (default: 1.0).\n",
    "        place_prob (float, optional): Probability of placing a piece in the chosen square (default: 0.5).\n",
    "        show (bool, optional): If True, prints board and game state (default: False).\n",
    "    \"\"\"\n",
    "    def __init__(self, board_size, win_condition, unplayable_grids=None, rewards=None, def_level=1, discount=1.0, place_prob=0.5, show=False):\n",
    "        super().__init__()\n",
    "        self._rows = board_size[0]\n",
    "        self._cols = board_size[1]\n",
    "        self._win_condition = win_condition\n",
    "        self._unplayable_grids = unplayable_grids if unplayable_grids is not None else np.zeros((self._rows, self._cols))\n",
    "        self._unplayable_actions = unplayable_grids.flatten() if unplayable_grids is not None else np.zeros(self._rows * self._cols)\n",
    "        self._rewards = rewards if rewards is not None else {\n",
    "            'win': 1.0, 'lose': -1.0, 'tie': 0.0, 'illegal': -1.0, 'forfeited': 0.0, 'step': -0.1,\n",
    "            'row_live_3': 0.16, 'row_dead_3': 0.08, 'row_live_2': 0.04, 'row_dead_2': 0.02,\n",
    "            'col_live_3': 0.16, 'col_dead_3': 0.08, 'col_live_2': 0.04, 'col_dead_2': 0.02,\n",
    "            'diag_live_4': 0.16, 'diag_dead_4': 0.08, 'diag_live_3': 0.04, 'diag_dead_3': 0.02, 'diag_live_2': 0.01, 'diag_dead_2': 0.005\n",
    "        }\n",
    "        self._def_level = def_level\n",
    "        self._discount = float(discount)\n",
    "        self._place_prob = place_prob\n",
    "        self._show = show\n",
    "        \n",
    "        # Define action spec: integer action for grid position\n",
    "        self._action_spec = array_spec.BoundedArraySpec(\n",
    "            shape=(), dtype=np.int32, minimum=0, maximum=self._rows * self._cols - 1, name='action'\n",
    "        )\n",
    "        # Define observation spec: board state and legal action mask\n",
    "        self._observation_spec = {\n",
    "            'board': array_spec.ArraySpec(\n",
    "                shape=(self._rows, self._cols, 2), dtype=np.float32, name='board'\n",
    "            ),\n",
    "            'action_mask': array_spec.ArraySpec(\n",
    "                shape=(self._rows * self._cols,), dtype=np.float32, name='action_mask'\n",
    "            )\n",
    "        }\n",
    "        \n",
    "        self._board = None\n",
    "        self._action_mask = None\n",
    "        self._player = None\n",
    "        self._winner = None\n",
    "        self._step_count = 0\n",
    "        self._board_display = None\n",
    "        self._n_neighbor_row = self._win_condition[0] - 1\n",
    "        self._n_neighbor_col = self._win_condition[1] - 1\n",
    "        self._n_neighbor_diag = self._win_condition[2] - 1\n",
    "\n",
    "    def action_spec(self):\n",
    "        \"\"\"Returns the action specification for the environment.\"\"\"\n",
    "        return self._action_spec\n",
    "\n",
    "    def observation_spec(self):\n",
    "        \"\"\"Returns the observation specification for the environment.\"\"\"\n",
    "        return self._observation_spec\n",
    "\n",
    "    def get_current_player(self):\n",
    "        \"\"\"Returns the current player (1 or 2).\"\"\"\n",
    "        return self._player\n",
    "\n",
    "    def get_winner(self):\n",
    "        \"\"\"Returns the winner (1, 2, or 0 for tie, None if ongoing).\"\"\"\n",
    "        return self._winner\n",
    "\n",
    "    def _get_observation(self, current_player=None):\n",
    "        \"\"\"Returns the current observation: board state and action mask.\n",
    "\n",
    "        Args:\n",
    "            current_player (int, optional): Player perspective (1 or 2). Defaults to current player.\n",
    "\n",
    "        Returns:\n",
    "            dict: Observation with 'board' (player/opponent grids) and 'action_mask' (legal actions).\n",
    "        \"\"\"\n",
    "        if current_player is None:\n",
    "            current_player = self._player\n",
    "        board = self._board if current_player == 1 else self._board[:, :, [1, 0]]\n",
    "        return {'board': board, 'action_mask': self._action_mask}\n",
    "\n",
    "    def _reset(self):\n",
    "        \"\"\"Resets the environment to start a new episode.\n",
    "\n",
    "        Initializes board, action mask, and player; sets random starting player.\n",
    "\n",
    "        Returns:\n",
    "            TimeStep: Restart step with initial observation.\n",
    "        \"\"\"\n",
    "        self._board = np.zeros((self._rows, self._cols, 2), dtype=np.float32)\n",
    "        self._action_mask = np.ones(self._rows * self._cols, dtype=np.float32)\n",
    "        self._action_mask[self._unplayable_actions==1] = 0\n",
    "        self._player = np.random.choice([1, 2])\n",
    "        self._winner = None\n",
    "        self._step_count = 0\n",
    "        self._board_display = np.full((self._rows, self._cols), '.', dtype=object)\n",
    "        self._board_display[self._unplayable_grids==1] = '#'\n",
    "        return ts.restart(self._get_observation())\n",
    "\n",
    "    def _consecutive(self, seq, win_con):\n",
    "        \"\"\"Checks if a sequence contains enough consecutive 1s to win.\n",
    "\n",
    "        Args:\n",
    "            seq (np.ndarray): Sequence of board values (0 or 1).\n",
    "            win_con (int): Number of consecutive pieces needed to win.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if sequence meets win condition.\n",
    "        \"\"\"\n",
    "        count = 0\n",
    "        for x in seq:\n",
    "            count = count + 1 if x == 1 else 0\n",
    "            if count >= win_con:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def _get_reward_state(self, row, col):\n",
    "        \"\"\"Calculates reward and game state after a move.\n",
    "\n",
    "        Checks for win, tie, or transition; computes pattern-based rewards (e.g., live/dead 3).\n",
    "\n",
    "        Args:\n",
    "            row (int): Row of the placed piece.\n",
    "            col (int): Column of the placed piece.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (reward, state) where reward is a float and state is 'termination' or 'transition'.\n",
    "        \"\"\"\n",
    "        player_layer = self._player - 1\n",
    "        opponent_layer = 1 - player_layer\n",
    "        player_board = self._board[:, :, player_layer]\n",
    "        opponent_board = self._board[:, :, opponent_layer]\n",
    "       \n",
    "        # Check row for win condition\n",
    "        action_leftmost_index = max(0, col - self._n_neighbor_row)\n",
    "        action_rightmost_index = min(self._cols - 1, col + self._n_neighbor_row)\n",
    "        player_row = player_board[row, action_leftmost_index : action_rightmost_index + 1]\n",
    "        if self._consecutive(player_row, self._win_condition[0]):\n",
    "            self._winner = self._player\n",
    "            return self._rewards['win'], \"termination\"\n",
    "        \n",
    "        # Check column for win condition\n",
    "        action_top_index = max(0, row - self._n_neighbor_col)\n",
    "        action_bottom_index = min(self._rows - 1, row + self._n_neighbor_col)\n",
    "        player_col = player_board[action_top_index : action_bottom_index + 1, col]\n",
    "        if self._consecutive(player_col, self._win_condition[1]):\n",
    "            self._winner = self._player\n",
    "            return self._rewards['win'], \"termination\"\n",
    "        \n",
    "        # Check main diagonal for win condition\n",
    "        diag_indices = []\n",
    "        for i in range(-self._n_neighbor_diag, self._n_neighbor_diag + 1):\n",
    "            r, c = row + i, col + i\n",
    "            if 0 <= r < self._rows and 0 <= c < self._cols:\n",
    "                diag_indices.append((r, c))\n",
    "        player_diag = np.array([player_board[r, c] for r, c in diag_indices])\n",
    "        if len(player_diag) >= self._win_condition[2] and self._consecutive(player_diag, self._win_condition[2]):\n",
    "            self._winner = self._player\n",
    "            return self._rewards['win'], \"termination\"\n",
    "        \n",
    "        # Check anti-diagonal for win condition\n",
    "        antidiag_indices = []\n",
    "        for i in range(-self._n_neighbor_diag, self._n_neighbor_diag + 1):\n",
    "            r, c = row + i, col - i\n",
    "            if 0 <= r < self._rows and 0 <= c < self._cols:\n",
    "                antidiag_indices.append((r, c))\n",
    "        player_antidiag = np.array([player_board[r, c] for r, c in antidiag_indices])\n",
    "        if len(player_antidiag) >= self._win_condition[2] and self._consecutive(player_antidiag, self._win_condition[2]):\n",
    "            self._winner = self._player\n",
    "            return self._rewards['win'], \"termination\"\n",
    "\n",
    "        # Check for tie (no legal actions left)\n",
    "        if np.all(self._action_mask == 0.0):\n",
    "            self._winner = 0\n",
    "            return self._rewards['tie'], \"termination\"\n",
    "\n",
    "        # Compute pattern-based rewards for non-terminal state\n",
    "        opponent_row = opponent_board[row, action_leftmost_index : action_rightmost_index + 1]\n",
    "        unplayable_row = self._unplayable_grids[row, action_leftmost_index : action_rightmost_index + 1]\n",
    "        center_index_row = min(col, self._n_neighbor_row)\n",
    "        unblocked_player_row = self._get_unblocked_segment(player_row, opponent_row, unplayable_row, center_index_row)\n",
    "        row_pattern_reward = self.get_pattern_reward(unblocked_player_row, 'row')\n",
    "\n",
    "        opponent_col = opponent_board[action_top_index : action_bottom_index + 1, col]\n",
    "        unplayable_col = self._unplayable_grids[action_top_index : action_bottom_index + 1, col]\n",
    "        center_index_col = min(row, self._n_neighbor_col)\n",
    "        unblocked_player_col = self._get_unblocked_segment(player_col, opponent_col, unplayable_col, center_index_col)\n",
    "        col_pattern_reward = self.get_pattern_reward(unblocked_player_col, 'col')\n",
    "\n",
    "        opponent_diag = np.array([opponent_board[r, c] for r, c in diag_indices])\n",
    "        unplayable_diag = np.array([self._unplayable_grids[r, c] for r, c in diag_indices])\n",
    "        center_index_diag = min(row, self._n_neighbor_diag)\n",
    "        unblocked_player_diag = self._get_unblocked_segment(player_diag, opponent_diag, unplayable_diag, center_index_diag)\n",
    "        diag_pattern_reward = self.get_pattern_reward(unblocked_player_diag, 'diag')\n",
    "\n",
    "        opponent_antidiag = np.array([opponent_board[r, c] for r, c in antidiag_indices])\n",
    "        unplayable_antidiag = np.array([self._unplayable_grids[r, c] for r, c in antidiag_indices])\n",
    "        center_index_antidiag = min(row, self._n_neighbor_diag)\n",
    "        unblocked_player_antidiag = self._get_unblocked_segment(player_antidiag, opponent_antidiag, unplayable_antidiag, center_index_antidiag)\n",
    "        antidiag_pattern_reward = self.get_pattern_reward(unblocked_player_antidiag, 'diag')\n",
    "        \n",
    "        reward = row_pattern_reward + col_pattern_reward + diag_pattern_reward + antidiag_pattern_reward\n",
    "        return reward, \"transition\"\n",
    "\n",
    "    def _get_unblocked_segment(self, player_segment, opponent_segment, unplayable_segment, center_index):\n",
    "        \"\"\"Extracts the unblocked segment of a player’s pieces for pattern reward calculation.\n",
    "\n",
    "        Args:\n",
    "            player_segment (np.ndarray): Player’s piece sequence (0 or 1).\n",
    "            opponent_segment (np.ndarray): Opponent’s piece sequence (0 or 1).\n",
    "            unplayable_segment (np.ndarray): Unplayable squares (0 or 1).\n",
    "            center_index (int): Index of the placed piece in the segment.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Unblocked segment of player’s pieces.\n",
    "        \"\"\"\n",
    "        unblocked_mask = (opponent_segment == 0) & (unplayable_segment == 0)\n",
    "        if center_index == 0:\n",
    "            final_leftmost_index = 0\n",
    "        else:\n",
    "            unblocked_mask_left = unblocked_mask[:center_index]\n",
    "            if np.all(unblocked_mask_left):\n",
    "                final_leftmost_index = 0\n",
    "            else:\n",
    "                final_leftmost_index = np.where(~unblocked_mask_left)[0][-1] + 1\n",
    "        \n",
    "        if center_index == len(player_segment) - 1:\n",
    "            final_rightmost_index = center_index\n",
    "        else:\n",
    "            unblocked_mask_right = unblocked_mask[center_index + 1:]\n",
    "            if np.all(unblocked_mask_right):\n",
    "                final_rightmost_index = len(player_segment) - 1\n",
    "            else:\n",
    "                final_rightmost_index = center_index + np.where(~unblocked_mask_right)[0][0]\n",
    "        \n",
    "        unblocked_segment = player_segment[final_leftmost_index : final_rightmost_index + 1]\n",
    "        return unblocked_segment\n",
    "    \n",
    "    def get_pattern_reward(self, arr, arr_type):\n",
    "        \"\"\"Calculates reward for a pattern (e.g., live/dead 2/3) in a row, column, or diagonal.\n",
    "\n",
    "        Args:\n",
    "            arr (np.ndarray): Sequence of player’s pieces (0 or 1).\n",
    "            arr_type (str): Type of sequence ('row', 'col', 'diag').\n",
    "\n",
    "        Returns:\n",
    "            float: Reward for the pattern, or 0 if no pattern is found.\n",
    "        \"\"\"\n",
    "        if arr_type == 'row':\n",
    "            win_cond = self._win_condition[0]\n",
    "        elif arr_type == 'col':\n",
    "            win_cond = self._win_condition[1]\n",
    "        elif arr_type == 'diag':\n",
    "            win_cond = self._win_condition[2]\n",
    "        arr_len = len(arr)\n",
    "        if arr_len < win_cond:\n",
    "            return 0\n",
    "        elif arr_len == win_cond:\n",
    "            arr_sum = np.sum(arr)\n",
    "            if arr_sum >= 2:\n",
    "                if self._show:\n",
    "                    print(f\"Pattern: {arr_type}_dead_{int(arr_sum)}\")\n",
    "                return self._rewards[f\"{arr_type}_dead_{int(arr_sum)}\"]\n",
    "            else:\n",
    "                return 0\n",
    "        else:\n",
    "            # Scan for highest-value pattern (live/dead, number of pieces)\n",
    "            scan_len = win_cond + 1\n",
    "            pattern = (None, 0)\n",
    "            for i in range(arr_len - scan_len + 1):\n",
    "                subset = arr[i:i+scan_len]\n",
    "                subset_sum = np.sum(subset)\n",
    "                if subset[0] == 1 and subset[-1] == 1:\n",
    "                    subset_sum -= 1\n",
    "                live_dead = 'live' if subset[0] == 0 and subset[-1] == 0 else 'dead'\n",
    "                if subset_sum < 2:\n",
    "                    continue\n",
    "                elif (subset_sum > pattern[1]) or (subset_sum == pattern[1] and live_dead == 'live'):\n",
    "                    pattern = (live_dead, subset_sum)\n",
    "                if pattern == ('live', win_cond-1):\n",
    "                    break\n",
    "            if pattern[0] is None:\n",
    "                return 0\n",
    "            else:\n",
    "                if self._show:\n",
    "                    print(f\"Pattern: {arr_type}_{pattern[0]}_{int(pattern[1])}\")\n",
    "                return self._rewards[f\"{arr_type}_{pattern[0]}_{int(pattern[1])}\"]\n",
    "\n",
    "    def _place_mark(self, row, col, player):\n",
    "        \"\"\"Places a piece on the board with probabilistic placement.\n",
    "\n",
    "        With probability place_prob, places the piece in the chosen square; otherwise,\n",
    "        attempts placement in a random adjacent square (1/16 per direction).\n",
    "\n",
    "        Args:\n",
    "            row (int): Target row for placement.\n",
    "            col (int): Target column for placement.\n",
    "            player (int): Player ID (1 or 2).\n",
    "\n",
    "        Returns:\n",
    "            tuple: (row, col) of placed piece, or None if placement fails.\n",
    "        \"\"\"\n",
    "        player_layer = 0 if player == 1 else 1\n",
    "        action = self.board_map_to_action(row, col)\n",
    "        if self._action_mask[action] == 0.0:\n",
    "            return None\n",
    "        if np.random.random() < self._place_prob and self._action_mask[action] == 1.0:\n",
    "            self._board[row, col, player_layer] = 1.0\n",
    "            self._action_mask[action] = 0.0\n",
    "            return (row, col)\n",
    "        else:\n",
    "            # Randomly select an adjacent square (1/16 probability each)\n",
    "            directions = [\n",
    "                (-1, -1), (-1, 0), (-1, 1),\n",
    "                (0, -1),  (0, 1),\n",
    "                (1, -1),  (1, 0),  (1, 1)\n",
    "            ]\n",
    "            di, dj = directions[np.random.randint(8)]\n",
    "            new_row, new_col = row + di, col + dj\n",
    "\n",
    "            if new_row < 0 or new_col < 0 or new_row >= self._rows or new_col >= self._cols:\n",
    "                return None\n",
    "            new_action = self.board_map_to_action(new_row, new_col)\n",
    "            if self._action_mask[new_action] == 1.0:\n",
    "                self._board[new_row, new_col, player_layer] = 1.0\n",
    "                self._action_mask[new_action] = 0.0\n",
    "                return (new_row, new_col)\n",
    "            return None\n",
    "    \n",
    "    def _step(self, action):\n",
    "        \"\"\"Executes a single step in the environment.\n",
    "\n",
    "        Applies the action, updates board and state, and returns reward and next step.\n",
    "\n",
    "        Args:\n",
    "            action (int): Action index (grid position).\n",
    "\n",
    "        Returns:\n",
    "            TimeStep: Transition or termination step with observation, reward, and discount.\n",
    "        \"\"\"\n",
    "        if self._winner is not None:\n",
    "            return self._reset()\n",
    "        \n",
    "        self._step_count += 1\n",
    "\n",
    "        # Penalize illegal actions (occupied or unplayable squares)\n",
    "        if self._action_mask[action] == 0.0:\n",
    "            self._winner = 3 - self._player\n",
    "            reward = self._rewards['illegal']\n",
    "            return ts.termination(self._get_observation(), reward=reward)\n",
    "\n",
    "        init_row, init_col = self.action_map_to_board(action)\n",
    "        placement = self._place_mark(init_row, init_col, self._player)\n",
    "        if placement is not None:\n",
    "            row, col = placement\n",
    "            self._board_display[row, col] = f\"{'X' if self._player == 1 else 'O'}\"\n",
    "            self.print_board()\n",
    "            reward, state = self._get_reward_state(row, col)\n",
    "            if self._show:\n",
    "                print()\n",
    "            if state == \"termination\":\n",
    "                if self._show:\n",
    "                    if self._winner == 0:\n",
    "                        print(\"Tie\")\n",
    "                    elif self._winner == 1:\n",
    "                        print(\"Winner: P1\")\n",
    "                    else:\n",
    "                        print(\"Winner: P2\")\n",
    "                return ts.termination(self._get_observation(), reward=reward)\n",
    "            elif state == \"transition\":\n",
    "                self._player = 3 - self._player\n",
    "                return ts.transition(self._get_observation(), reward=reward+self._rewards['step'], discount=self._discount)\n",
    "        else:\n",
    "            self._player = 3 - self._player\n",
    "            return ts.transition(self._get_observation(), reward=self._rewards['forfeited']+self._rewards['step'], discount=self._discount)\n",
    "\n",
    "    def action_map_to_board(self, action):\n",
    "        \"\"\"Maps an action index to board coordinates.\n",
    "\n",
    "        Args:\n",
    "            action (int): Action index.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (row, col) coordinates.\n",
    "        \"\"\"\n",
    "        row = action // self._cols\n",
    "        col = action % self._cols\n",
    "        return row, col\n",
    "\n",
    "    def board_map_to_action(self, row, col):\n",
    "        \"\"\"Maps board coordinates to an action index.\n",
    "\n",
    "        Args:\n",
    "            row (int): Row coordinate.\n",
    "            col (int): Column coordinate.\n",
    "\n",
    "        Returns:\n",
    "            int: Action index.\n",
    "        \"\"\"\n",
    "        return row * self._cols + col\n",
    "\n",
    "    def print_board(self):\n",
    "        \"\"\"Prints the current board state if show is True.\"\"\"\n",
    "        if self._show:\n",
    "            print(f\"\\nRound {self._step_count} - Player {self._player} ( {'X' if self._player == 1 else 'O'} )\")\n",
    "            board_display = [' '.join(row) for row in self._board_display]\n",
    "            print('\\n'.join(board_display))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f9f4b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_consecutive (__main__.StandardEnvTest.test_consecutive)\n",
      "Test the _consecutive helper function. ... ok\n",
      "test_coordinate_mapping (__main__.StandardEnvTest.test_coordinate_mapping)\n",
      "Test action index to board coordinates and vice versa. ... ok\n",
      "test_first_step_type (__main__.StandardEnvTest.test_first_step_type)\n",
      "Test that the first step returns StepType.MID if non-terminal. ... ok\n",
      "test_get_observation (__main__.StandardEnvTest.test_get_observation)\n",
      "Test observation generation, especially player perspective. ... ok\n",
      "test_get_reward_state_tie (__main__.StandardEnvTest.test_get_reward_state_tie)\n",
      "Test tie condition detection. ... ok\n",
      "test_get_reward_state_win (__main__.StandardEnvTest.test_get_reward_state_win)\n",
      "Test win condition detection with pattern rewards. ... ok\n",
      "test_initialization (__main__.StandardEnvTest.test_initialization)\n",
      "Test environment initialization and specs. ... ok\n",
      "test_place_mark_prob_0_5_adjacent_forced (__main__.StandardEnvTest.test_place_mark_prob_0_5_adjacent_forced)\n",
      "Test _place_mark with place_prob=0.5, forcing adjacent placement. ... ok\n",
      "test_place_mark_prob_0_5_direct_forced (__main__.StandardEnvTest.test_place_mark_prob_0_5_direct_forced)\n",
      "Test _place_mark with place_prob=0.5, forcing direct placement. ... ok\n",
      "test_place_mark_prob_1 (__main__.StandardEnvTest.test_place_mark_prob_1)\n",
      "Test _place_mark when place_prob is 1.0 (direct placement). ... ok\n",
      "test_reset (__main__.StandardEnvTest.test_reset)\n",
      "Test environment reset state. ... ok\n",
      "test_reset_after_termination (__main__.StandardEnvTest.test_reset_after_termination)\n",
      "Test _step after a terminal state triggers reset. ... ok\n",
      "test_specs (__main__.StandardEnvTest.test_specs)\n",
      "Test action and observation specs. ... ok\n",
      "test_step_forfeit_prob_0_5 (__main__.StandardEnvTest.test_step_forfeit_prob_0_5)\n",
      "Test _step for a forfeited move with place_prob=0.5. ... ok\n",
      "test_step_illegal_move (__main__.StandardEnvTest.test_step_illegal_move)\n",
      "Test _step for illegal moves. ... ok\n",
      "test_step_tie_prob_0_5_direct_forced (__main__.StandardEnvTest.test_step_tie_prob_0_5_direct_forced)\n",
      "Test _step for a tie with place_prob=0.5, forcing direct placement. ... ok\n",
      "test_step_tie_prob_1 (__main__.StandardEnvTest.test_step_tie_prob_1)\n",
      "Test _step for a tie with place_prob=1.0. ... ok\n",
      "test_step_transition_prob_0_5_adjacent_forced (__main__.StandardEnvTest.test_step_transition_prob_0_5_adjacent_forced)\n",
      "Test _step for a non-terminal move with place_prob=0.5, forcing adjacent placement. ... ok\n",
      "test_step_transition_prob_0_5_direct_forced (__main__.StandardEnvTest.test_step_transition_prob_0_5_direct_forced)\n",
      "Test _step for a non-terminal move with place_prob=0.5, forcing direct placement. ... ok\n",
      "test_step_transition_prob_1 (__main__.StandardEnvTest.test_step_transition_prob_1)\n",
      "Test _step for a non-terminal move with place_prob=1.0. ... ok\n",
      "test_step_win_prob_0_5_adjacent_forced (__main__.StandardEnvTest.test_step_win_prob_0_5_adjacent_forced)\n",
      "Test _step for a move that would win but lands adjacent due to place_prob=0.5. ... ok\n",
      "test_step_win_prob_0_5_direct_forced (__main__.StandardEnvTest.test_step_win_prob_0_5_direct_forced)\n",
      "Test _step for a winning move with place_prob=0.5, forcing direct placement. ... ok\n",
      "test_step_win_prob_1 (__main__.StandardEnvTest.test_step_win_prob_1)\n",
      "Test _step for a winning move with place_prob=1.0. ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 23 tests in 0.044s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "class StandardEnvTest(unittest.TestCase):\n",
    "    def test_initialization(self):\n",
    "        \"\"\"Test environment initialization and specs.\"\"\"\n",
    "        env = Standard_Env(board_size=(3, 3), win_condition=[3, 3, 3])\n",
    "        self.assertEqual(env._rows, 3)\n",
    "        self.assertEqual(env._cols, 3)\n",
    "        self.assertEqual(env._win_condition, [3, 3, 3])\n",
    "        self.assertIsInstance(env._unplayable_grids, np.ndarray)\n",
    "        self.assertEqual(env._unplayable_grids.shape, (3, 3))\n",
    "        self.assertIsInstance(env._unplayable_actions, np.ndarray)\n",
    "        self.assertEqual(env._unplayable_actions.shape, (9,))\n",
    "        self.assertIsInstance(env._rewards, dict)\n",
    "        self.assertIn('win', env._rewards)\n",
    "        self.assertIn('row_live_3', env._rewards)\n",
    "        self.assertIn('action', env.action_spec().name)\n",
    "        self.assertIn('board', env.observation_spec())\n",
    "        self.assertIn('action_mask', env.observation_spec())\n",
    "        self.assertEqual(env.action_spec().maximum, 3*3 - 1)\n",
    "        self.assertEqual(env.observation_spec()['board'].shape, (3, 3, 2))\n",
    "        self.assertEqual(env.observation_spec()['action_mask'].shape, (3*3,))\n",
    "\n",
    "        unplayable = np.array([[0, 0, 0], [0, 1, 0], [0, 0, 0]])\n",
    "        env_unplayable = Standard_Env(board_size=(3, 3), win_condition=[3, 3, 3], unplayable_grids=unplayable)\n",
    "        self.assertEqual(np.sum(env_unplayable._unplayable_actions), 1)\n",
    "        self.assertEqual(env_unplayable._unplayable_actions[env_unplayable.board_map_to_action(1, 1)], 1)\n",
    "        env_unplayable.reset()\n",
    "        expected_mask = np.ones(9, dtype=np.float32)\n",
    "        expected_mask[env_unplayable.board_map_to_action(1, 1)] = 0.0\n",
    "        np.testing.assert_array_equal(env_unplayable._action_mask, expected_mask)\n",
    "\n",
    "    def test_reset(self):\n",
    "        \"\"\"Test environment reset state.\"\"\"\n",
    "        env = Standard_Env(board_size=(3, 3), win_condition=[3, 3, 3])\n",
    "        initial_time_step = env.reset()\n",
    "\n",
    "        self.assertEqual(initial_time_step.step_type, ts.StepType.FIRST)\n",
    "        self.assertEqual(initial_time_step.reward, 0.0)\n",
    "        self.assertEqual(initial_time_step.discount, env._discount)\n",
    "        self.assertIn('board', initial_time_step.observation)\n",
    "        self.assertIn('action_mask', initial_time_step.observation)\n",
    "\n",
    "        np.testing.assert_array_equal(env._board, np.zeros((3, 3, 2)))\n",
    "        np.testing.assert_array_equal(env._action_mask, np.ones(9))\n",
    "        self.assertIn(env._player, [1, 2])\n",
    "        self.assertIsNone(env._winner)\n",
    "        self.assertEqual(env._step_count, 0)\n",
    "\n",
    "    def test_specs(self):\n",
    "        \"\"\"Test action and observation specs.\"\"\"\n",
    "        env = Standard_Env(board_size=(4, 5), win_condition=[4, 4, 4])\n",
    "        action_spec = env.action_spec()\n",
    "        obs_spec = env.observation_spec()\n",
    "\n",
    "        self.assertIsInstance(action_spec, array_spec.BoundedArraySpec)\n",
    "        self.assertEqual(action_spec.shape, ())\n",
    "        self.assertEqual(action_spec.dtype, np.int32)\n",
    "        self.assertEqual(action_spec.minimum, 0)\n",
    "        self.assertEqual(action_spec.maximum, 4*5 - 1)\n",
    "        self.assertEqual(action_spec.name, 'action')\n",
    "\n",
    "        self.assertIsInstance(obs_spec, dict)\n",
    "        self.assertIn('board', obs_spec)\n",
    "        self.assertIn('action_mask', obs_spec)\n",
    "\n",
    "        board_spec = obs_spec['board']\n",
    "        self.assertIsInstance(board_spec, array_spec.ArraySpec)\n",
    "        self.assertEqual(board_spec.shape, (4, 5, 2))\n",
    "        self.assertEqual(board_spec.dtype, np.float32)\n",
    "        self.assertEqual(board_spec.name, 'board')\n",
    "\n",
    "        mask_spec = obs_spec['action_mask']\n",
    "        self.assertIsInstance(mask_spec, array_spec.ArraySpec)\n",
    "        self.assertEqual(mask_spec.shape, (4*5,))\n",
    "        self.assertEqual(mask_spec.dtype, np.float32)\n",
    "        self.assertEqual(mask_spec.name, 'action_mask')\n",
    "\n",
    "    def test_coordinate_mapping(self):\n",
    "        \"\"\"Test action index to board coordinates and vice versa.\"\"\"\n",
    "        env = Standard_Env(board_size=(3, 4), win_condition=[3, 3, 3])\n",
    "        self.assertEqual(env.action_map_to_board(0), (0, 0))\n",
    "        self.assertEqual(env.action_map_to_board(3), (0, 3))\n",
    "        self.assertEqual(env.action_map_to_board(4), (1, 0))\n",
    "        self.assertEqual(env.action_map_to_board(7), (1, 3))\n",
    "        self.assertEqual(env.action_map_to_board(8), (2, 0))\n",
    "        self.assertEqual(env.action_map_to_board(11), (2, 3))\n",
    "\n",
    "        self.assertEqual(env.board_map_to_action(0, 0), 0)\n",
    "        self.assertEqual(env.board_map_to_action(0, 3), 3)\n",
    "        self.assertEqual(env.board_map_to_action(1, 0), 4)\n",
    "        self.assertEqual(env.board_map_to_action(1, 3), 7)\n",
    "        self.assertEqual(env.board_map_to_action(2, 0), 8)\n",
    "        self.assertEqual(env.board_map_to_action(2, 3), 11)\n",
    "\n",
    "        for r in range(3):\n",
    "            for c in range(4):\n",
    "                action = env.board_map_to_action(r, c)\n",
    "                mapped_row, mapped_col = env.action_map_to_board(action)\n",
    "                self.assertEqual((r, c), (mapped_row, mapped_col))\n",
    "\n",
    "    def test_consecutive(self):\n",
    "        \"\"\"Test the _consecutive helper function.\"\"\"\n",
    "        env = Standard_Env(board_size=(1, 5), win_condition=[3, 0, 0])\n",
    "        self.assertFalse(env._consecutive(np.array([0, 0, 0, 0, 0]), 3))\n",
    "        self.assertFalse(env._consecutive(np.array([1, 1, 0, 1, 1]), 3))\n",
    "        self.assertTrue(env._consecutive(np.array([0, 1, 1, 1, 0]), 3))\n",
    "        self.assertTrue(env._consecutive(np.array([1, 1, 1, 0, 0]), 3))\n",
    "        self.assertTrue(env._consecutive(np.array([0, 0, 1, 1, 1]), 3))\n",
    "        self.assertTrue(env._consecutive(np.array([1, 1, 1, 1, 1]), 3))\n",
    "        self.assertTrue(env._consecutive(np.array([1, 1, 1, 1, 1]), 5))\n",
    "        self.assertFalse(env._consecutive(np.array([1, 1, 1, 1, 1]), 6))\n",
    "\n",
    "    def test_get_observation(self):\n",
    "        \"\"\"Test observation generation, especially player perspective.\"\"\"\n",
    "        env = Standard_Env(board_size=(2, 2), win_condition=[2, 2, 2])\n",
    "        env.reset()\n",
    "        env._board = np.array([[[1, 0], [0, 1]], [[0, 1], [1, 0]]], dtype=np.float32)\n",
    "        env._action_mask = np.array([1, 0, 0, 1], dtype=np.float32)\n",
    "\n",
    "        env._player = 1\n",
    "        obs_p1 = env._get_observation()\n",
    "        np.testing.assert_array_equal(obs_p1['board'], env._board)\n",
    "        np.testing.assert_array_equal(obs_p1['action_mask'], env._action_mask)\n",
    "\n",
    "        env._player = 2\n",
    "        obs_p2 = env._get_observation()\n",
    "        expected_board_p2 = np.array([[[0, 1], [1, 0]], [[1, 0], [0, 1]]], dtype=np.float32)\n",
    "        np.testing.assert_array_equal(obs_p2['board'], expected_board_p2)\n",
    "        np.testing.assert_array_equal(obs_p2['action_mask'], env._action_mask)\n",
    "\n",
    "    def test_get_reward_state_win(self):\n",
    "        \"\"\"Test win condition detection with pattern rewards.\"\"\"\n",
    "        env = Standard_Env(board_size=(3, 3), win_condition=[3, 3, 3])\n",
    "        env.reset()\n",
    "\n",
    "        # Row win\n",
    "        env._player = 1\n",
    "        env._board[0, :, 0] = 1.0\n",
    "        reward, state = env._get_reward_state(0, 2)\n",
    "        self.assertEqual(reward, env._rewards['win'])\n",
    "        self.assertEqual(state, \"termination\")\n",
    "        self.assertEqual(env._winner, 1)\n",
    "\n",
    "        # Column win\n",
    "        env.reset()\n",
    "        env._player = 2\n",
    "        env._board[:, 1, 1] = 1.0\n",
    "        reward, state = env._get_reward_state(2, 1)\n",
    "        self.assertEqual(reward, env._rewards['win'])\n",
    "        self.assertEqual(state, \"termination\")\n",
    "        self.assertEqual(env._winner, 2)\n",
    "\n",
    "        # Diagonal win\n",
    "        env.reset()\n",
    "        env._player = 1\n",
    "        env._board[0, 0, 0] = 1.0\n",
    "        env._board[1, 1, 0] = 1.0\n",
    "        env._board[2, 2, 0] = 1.0\n",
    "        reward, state = env._get_reward_state(2, 2)\n",
    "        self.assertEqual(reward, env._rewards['win'])\n",
    "        self.assertEqual(state, \"termination\")\n",
    "        self.assertEqual(env._winner, 1)\n",
    "\n",
    "        # Anti-diagonal win\n",
    "        env.reset()\n",
    "        env._player = 2\n",
    "        env._board[0, 2, 1] = 1.0\n",
    "        env._board[1, 1, 1] = 1.0\n",
    "        env._board[2, 0, 1] = 1.0\n",
    "        reward, state = env._get_reward_state(2, 0)\n",
    "        self.assertEqual(reward, env._rewards['win'])\n",
    "        self.assertEqual(state, \"termination\")\n",
    "        self.assertEqual(env._winner, 2)\n",
    "\n",
    "        # Non-winning move with pattern reward\n",
    "        env.reset()\n",
    "        env._player = 1\n",
    "        env._board[0, 0, 0] = 1.0\n",
    "        env._board[0, 1, 0] = 1.0\n",
    "        reward, state = env._get_reward_state(0, 1)\n",
    "        self.assertEqual(reward, env._rewards['row_dead_2'])\n",
    "        self.assertEqual(state, \"transition\")\n",
    "        self.assertIsNone(env._winner)\n",
    "\n",
    "    def test_get_reward_state_tie(self):\n",
    "        \"\"\"Test tie condition detection.\"\"\"\n",
    "        env = Standard_Env(board_size=(2, 2), win_condition=[3, 3, 3])\n",
    "        env.reset()\n",
    "        env._board = np.zeros((2, 2, 2), dtype=np.float32)\n",
    "        env._action_mask = np.zeros(4, dtype=np.float32)\n",
    "\n",
    "        env._player = 1\n",
    "        reward, state = env._get_reward_state(0, 0)\n",
    "        self.assertEqual(reward, env._rewards['tie'])\n",
    "        self.assertEqual(state, \"termination\")\n",
    "        self.assertEqual(env._winner, 0)\n",
    "\n",
    "    def test_place_mark_prob_1(self):\n",
    "        \"\"\"Test _place_mark when place_prob is 1.0 (direct placement).\"\"\"\n",
    "        env = Standard_Env(board_size=(3, 3), win_condition=[3, 3, 3], place_prob=1.0)\n",
    "        env.reset()\n",
    "        initial_mask = env._action_mask.copy()\n",
    "\n",
    "        env._player = 1\n",
    "        placement = env._place_mark(1, 1, env._player)\n",
    "        self.assertEqual(placement, (1, 1))\n",
    "        self.assertEqual(env._board[1, 1, 0], 1.0)\n",
    "        self.assertEqual(env._action_mask[env.board_map_to_action(1, 1)], 0.0)\n",
    "        expected_mask = initial_mask.copy()\n",
    "        expected_mask[env.board_map_to_action(1, 1)] = 0.0\n",
    "        np.testing.assert_array_equal(env._action_mask, expected_mask)\n",
    "        self.assertEqual(env._board[1, 1, 1], 0.0)\n",
    "\n",
    "        env._player = 2\n",
    "        placement = env._place_mark(0, 2, env._player)\n",
    "        self.assertEqual(placement, (0, 2))\n",
    "        self.assertEqual(env._board[0, 2, 1], 1.0)\n",
    "        self.assertEqual(env._action_mask[env.board_map_to_action(0, 2)], 0.0)\n",
    "        self.assertEqual(env._board[0, 2, 0], 0.0)\n",
    "\n",
    "        # Test illegal placement (occupied square)\n",
    "        env.reset()\n",
    "        env._board[1, 0, 0] = 1.0  # Occupy (1, 0)\n",
    "        env._action_mask[env.board_map_to_action(1, 0)] = 0.0\n",
    "        env._player = 1\n",
    "        placement = env._place_mark(1, 0, env._player)\n",
    "        self.assertIsNone(placement)\n",
    "\n",
    "    @unittest.mock.patch('numpy.random.random')\n",
    "    @unittest.mock.patch('numpy.random.randint')\n",
    "    def test_place_mark_prob_0_5_adjacent_forced(self, mock_randint, mock_random):\n",
    "        \"\"\"Test _place_mark with place_prob=0.5, forcing adjacent placement.\"\"\"\n",
    "        env = Standard_Env(board_size=(3, 3), win_condition=[3, 3, 3], place_prob=0.5)\n",
    "        env.reset()\n",
    "        initial_mask = env._action_mask.copy()\n",
    "\n",
    "        target_row, target_col = 1, 1\n",
    "        target_action = env.board_map_to_action(target_row, target_col)\n",
    "        forced_adjacent_square = (1, 0)\n",
    "        forced_adjacent_action = env.board_map_to_action(*forced_adjacent_square)\n",
    "        directions = [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1)]\n",
    "        forced_direction_index = directions.index((0, -1))  # (1,1) to (1,0)\n",
    "        mock_randint.return_value = forced_direction_index\n",
    "        mock_random.return_value = 0.6  # Force adjacent logic\n",
    "\n",
    "        # Block all other adjacent squares\n",
    "        for dr, dc in directions:\n",
    "            adj_row, adj_col = target_row + dr, target_col + dc\n",
    "            if (adj_row, adj_col) != forced_adjacent_square and 0 <= adj_row < 3 and 0 <= adj_col < 3:\n",
    "                env._action_mask[env.board_map_to_action(adj_row, adj_col)] = 0.0\n",
    "\n",
    "        env._player = 1\n",
    "        placement = env._place_mark(target_row, target_col, env._player)\n",
    "\n",
    "        self.assertEqual(placement, forced_adjacent_square)\n",
    "        self.assertEqual(env._board[1, 0, 0], 1.0)\n",
    "        self.assertEqual(env._action_mask[forced_adjacent_action], 0.0)\n",
    "        self.assertEqual(env._action_mask[target_action], 1.0)\n",
    "\n",
    "    @unittest.mock.patch('numpy.random.random')\n",
    "    def test_place_mark_prob_0_5_direct_forced(self, mock_random):\n",
    "        \"\"\"Test _place_mark with place_prob=0.5, forcing direct placement.\"\"\"\n",
    "        env = Standard_Env(board_size=(3, 3), win_condition=[3, 3, 3], place_prob=0.5)\n",
    "        env.reset()\n",
    "\n",
    "        target_row, target_col = 1, 1\n",
    "        target_action = env.board_map_to_action(target_row, target_col)\n",
    "        self.assertEqual(env._action_mask[target_action], 1.0)\n",
    "\n",
    "        mock_random.return_value = 0.4  # Force direct logic\n",
    "        env._player = 1\n",
    "        placement = env._place_mark(target_row, target_col, env._player)\n",
    "\n",
    "        self.assertEqual(placement, (target_row, target_col))\n",
    "        self.assertEqual(env._board[target_row, target_col, 0], 1.0)\n",
    "        self.assertEqual(env._action_mask[target_action], 0.0)\n",
    "\n",
    "    def test_step_illegal_move(self):\n",
    "        \"\"\"Test _step for illegal moves.\"\"\"\n",
    "        env = Standard_Env(board_size=(3, 3), win_condition=[3, 3, 3])\n",
    "        env.reset()\n",
    "        initial_player = env._player\n",
    "        opponent_player = 3 - initial_player\n",
    "        illegal_action = env.board_map_to_action(0, 0)\n",
    "\n",
    "        env._action_mask[illegal_action] = 0.0\n",
    "        expected_mask_before_step = env._action_mask.copy()\n",
    "\n",
    "        time_step = env.step(illegal_action)\n",
    "\n",
    "        self.assertEqual(time_step.step_type, ts.StepType.LAST)\n",
    "        self.assertTrue(np.isclose(time_step.reward.item(), env._rewards['illegal']))\n",
    "        self.assertEqual(env._winner, opponent_player)\n",
    "        self.assertEqual(env._player, initial_player)\n",
    "        np.testing.assert_array_equal(env._board, np.zeros((3, 3, 2)))\n",
    "        np.testing.assert_array_equal(time_step.observation['action_mask'], expected_mask_before_step)\n",
    "        self.assertEqual(env._step_count, 1)\n",
    "\n",
    "    def test_step_win_prob_1(self):\n",
    "        \"\"\"Test _step for a winning move with place_prob=1.0.\"\"\"\n",
    "        env = Standard_Env(board_size=(3, 3), win_condition=[3, 3, 3], rewards={'win': 10.0, 'step': -0.1}, place_prob=1.0)\n",
    "        env.reset()\n",
    "        env._player = 1\n",
    "        env._board[0, 0, 0] = 1.0\n",
    "        env._board[0, 1, 0] = 1.0\n",
    "        env._action_mask[env.board_map_to_action(0, 0)] = 0.0\n",
    "        env._action_mask[env.board_map_to_action(0, 1)] = 0.0\n",
    "\n",
    "        winning_action = env.board_map_to_action(0, 2)\n",
    "        time_step = env.step(winning_action)\n",
    "\n",
    "        self.assertEqual(time_step.step_type, ts.StepType.LAST)\n",
    "        self.assertTrue(np.isclose(time_step.reward.item(), env._rewards['win']))\n",
    "        self.assertEqual(env._winner, 1)\n",
    "        self.assertEqual(env._board[0, 2, 0], 1.0)\n",
    "        self.assertEqual(env._action_mask[winning_action], 0.0)\n",
    "        self.assertEqual(env._step_count, 1)\n",
    "        self.assertEqual(env._player, 1)\n",
    "\n",
    "    @unittest.mock.patch('numpy.random.random')\n",
    "    def test_step_win_prob_0_5_direct_forced(self, mock_random):\n",
    "        \"\"\"Test _step for a winning move with place_prob=0.5, forcing direct placement.\"\"\"\n",
    "        env = Standard_Env(board_size=(3, 3), win_condition=[3, 0, 0], rewards={'win': 10.0, 'step': -0.1}, place_prob=0.5)\n",
    "        env.reset()\n",
    "        env._player = 1\n",
    "        env._board[0, 0, 0] = 1.0\n",
    "        env._board[0, 1, 0] = 1.0\n",
    "        env._action_mask[env.board_map_to_action(0, 0)] = 0.0\n",
    "        env._action_mask[env.board_map_to_action(0, 1)] = 0.0\n",
    "\n",
    "        mock_random.return_value = 0.4  # Force direct placement\n",
    "        winning_action = env.board_map_to_action(0, 2)\n",
    "        time_step = env.step(winning_action)\n",
    "\n",
    "        self.assertEqual(time_step.step_type, ts.StepType.LAST)\n",
    "        self.assertTrue(np.isclose(time_step.reward.item(), env._rewards['win']))\n",
    "        self.assertEqual(env._winner, 1)\n",
    "        self.assertEqual(env._board[0, 2, 0], 1.0)\n",
    "        self.assertEqual(env._action_mask[winning_action], 0.0)\n",
    "        self.assertEqual(env._step_count, 1)\n",
    "        self.assertEqual(env._player, 1)\n",
    "\n",
    "    @unittest.mock.patch('numpy.random.random')\n",
    "    @unittest.mock.patch('numpy.random.randint')\n",
    "    def test_step_win_prob_0_5_adjacent_forced(self, mock_randint, mock_random):\n",
    "        \"\"\"Test _step for a move that would win but lands adjacent due to place_prob=0.5.\"\"\"\n",
    "        env = Standard_Env(board_size=(3, 3), win_condition=[3, 0, 0], rewards={'win': 10.0, 'step': -0.1}, place_prob=0.5)\n",
    "        env.reset()\n",
    "        env._player = 1\n",
    "        env._board[0, 0, 0] = 1.0\n",
    "        env._board[0, 1, 0] = 1.0\n",
    "        env._action_mask[env.board_map_to_action(0, 0)] = 0.0\n",
    "        env._action_mask[env.board_map_to_action(0, 1)] = 0.0\n",
    "        winning_action = env.board_map_to_action(0, 2)\n",
    "\n",
    "        # Force placement to (1, 2)\n",
    "        forced_adjacent_square = (1, 2)\n",
    "        forced_adjacent_action = env.board_map_to_action(*forced_adjacent_square)\n",
    "        directions = [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1)]\n",
    "        forced_direction_index = directions.index((1, 0))  # (0,2) to (1,2)\n",
    "        mock_randint.return_value = forced_direction_index\n",
    "        mock_random.return_value = 0.6  # Force adjacent placement\n",
    "\n",
    "        # Block other adjacent squares\n",
    "        for dr, dc in directions:\n",
    "            adj_row, adj_col = 0 + dr, 2 + dc\n",
    "            if (adj_row, adj_col) != forced_adjacent_square and 0 <= adj_row < 3 and 0 <= adj_col < 3:\n",
    "                env._action_mask[env.board_map_to_action(adj_row, adj_col)] = 0.0\n",
    "\n",
    "        time_step = env.step(winning_action)\n",
    "\n",
    "        self.assertEqual(time_step.step_type, ts.StepType.MID)\n",
    "        self.assertTrue(np.isclose(time_step.reward.item(), env._rewards['step']))\n",
    "        self.assertIsNone(env._winner)\n",
    "        self.assertEqual(env._board[1, 2, 0], 1.0)\n",
    "        self.assertEqual(env._action_mask[forced_adjacent_action], 0.0)\n",
    "        self.assertEqual(env._action_mask[winning_action], 1.0)\n",
    "        self.assertEqual(env._step_count, 1)\n",
    "        self.assertEqual(env._player, 2)\n",
    "\n",
    "    def test_step_tie_prob_1(self):\n",
    "        \"\"\"Test _step for a tie with place_prob=1.0.\"\"\"\n",
    "        env = Standard_Env(board_size=(2, 2), win_condition=[3, 3, 3], rewards={'tie': 5.0, 'step': -0.1}, place_prob=1.0)\n",
    "        env.reset()\n",
    "        actions_to_fill = [(0, 0), (0, 1), (1, 0)]\n",
    "        players_to_fill = [1, 2, 1]\n",
    "        for (r, c), p in zip(actions_to_fill, players_to_fill):\n",
    "            action = env.board_map_to_action(r, c)\n",
    "            env._board[r, c, p-1] = 1.0\n",
    "            env._action_mask[action] = 0.0\n",
    "\n",
    "        env._player = 2\n",
    "        final_action = env.board_map_to_action(1, 1)\n",
    "        self.assertEqual(env._action_mask[final_action], 1.0)\n",
    "        self.assertEqual(env._step_count, 0)\n",
    "\n",
    "        time_step = env.step(final_action)\n",
    "\n",
    "        self.assertEqual(time_step.step_type, ts.StepType.LAST)\n",
    "        self.assertTrue(np.isclose(time_step.reward.item(), env._rewards['tie']))\n",
    "        self.assertEqual(env._winner, 0)\n",
    "        np.testing.assert_array_equal(env._action_mask, np.zeros(4))\n",
    "        self.assertEqual(env._step_count, 1)\n",
    "        self.assertEqual(env._player, 2)\n",
    "\n",
    "    @unittest.mock.patch('numpy.random.random')\n",
    "    def test_step_tie_prob_0_5_direct_forced(self, mock_random):\n",
    "        \"\"\"Test _step for a tie with place_prob=0.5, forcing direct placement.\"\"\"\n",
    "        env = Standard_Env(board_size=(2, 2), win_condition=[3, 3, 3], rewards={'tie': 5.0, 'step': -0.1}, place_prob=0.5)\n",
    "        env.reset()\n",
    "        actions_to_fill = [(0, 0), (0, 1), (1, 0)]\n",
    "        players_to_fill = [1, 2, 1]\n",
    "        for (r, c), p in zip(actions_to_fill, players_to_fill):\n",
    "            action = env.board_map_to_action(r, c)\n",
    "            env._board[r, c, p-1] = 1.0\n",
    "            env._action_mask[action] = 0.0\n",
    "\n",
    "        env._player = 2\n",
    "        final_action = env.board_map_to_action(1, 1)\n",
    "        self.assertEqual(env._action_mask[final_action], 1.0)\n",
    "        self.assertEqual(env._step_count, 0)\n",
    "\n",
    "        mock_random.return_value = 0.4  # Force direct placement\n",
    "        time_step = env.step(final_action)\n",
    "\n",
    "        self.assertEqual(time_step.step_type, ts.StepType.LAST)\n",
    "        self.assertTrue(np.isclose(time_step.reward.item(), env._rewards['tie']))\n",
    "        self.assertEqual(env._winner, 0)\n",
    "        np.testing.assert_array_equal(env._action_mask, np.zeros(4))\n",
    "        self.assertEqual(env._step_count, 1)\n",
    "        self.assertEqual(env._player, 2)\n",
    "\n",
    "    def test_step_transition_prob_1(self):\n",
    "        \"\"\"Test _step for a non-terminal move with place_prob=1.0.\"\"\"\n",
    "        env = Standard_Env(board_size=(3, 3), win_condition=[3, 3, 3], rewards={'step': -0.1, 'row_dead_2': 0.02}, place_prob=1.0)\n",
    "        env.reset()\n",
    "        env._player = 1\n",
    "        env._board[0, 0, 0] = 1.0  # Set up for row_dead_2\n",
    "        env._action_mask[env.board_map_to_action(0, 0)] = 0.0\n",
    "\n",
    "        valid_action = env.board_map_to_action(0, 1)\n",
    "        self.assertEqual(env._action_mask[valid_action], 1.0)\n",
    "        self.assertEqual(env._step_count, 0)\n",
    "\n",
    "        time_step = env.step(valid_action)\n",
    "\n",
    "        self.assertEqual(time_step.step_type, ts.StepType.MID)\n",
    "        self.assertTrue(np.isclose(time_step.reward.item(), env._rewards['row_dead_2'] + env._rewards['step']))\n",
    "        self.assertEqual(time_step.discount, env._discount)\n",
    "        self.assertEqual(env._player, 2)\n",
    "        self.assertEqual(env._board[0, 1, 0], 1.0)\n",
    "        self.assertEqual(env._board[0, 1, 1], 0.0)\n",
    "        self.assertEqual(env._action_mask[valid_action], 0.0)\n",
    "        self.assertEqual(env._step_count, 1)\n",
    "\n",
    "    @unittest.mock.patch('numpy.random.random')\n",
    "    def test_step_transition_prob_0_5_direct_forced(self, mock_random):\n",
    "        \"\"\"Test _step for a non-terminal move with place_prob=0.5, forcing direct placement.\"\"\"\n",
    "        env = Standard_Env(board_size=(3, 3), win_condition=[3, 3, 3], rewards={'step': -0.1, 'row_dead_2': 0.02}, place_prob=0.5)\n",
    "        env.reset()\n",
    "        env._player = 1\n",
    "        env._board[0, 0, 0] = 1.0  # Set up for row_dead_2\n",
    "        env._action_mask[env.board_map_to_action(0, 0)] = 0.0\n",
    "\n",
    "        valid_action = env.board_map_to_action(0, 1)\n",
    "        self.assertEqual(env._action_mask[valid_action], 1.0)\n",
    "        self.assertEqual(env._step_count, 0)\n",
    "\n",
    "        mock_random.return_value = 0.4  # Force direct placement\n",
    "        time_step = env.step(valid_action)\n",
    "\n",
    "        self.assertEqual(time_step.step_type, ts.StepType.MID)\n",
    "        self.assertTrue(np.isclose(time_step.reward.item(), env._rewards['row_dead_2'] + env._rewards['step']))\n",
    "        self.assertEqual(time_step.discount, env._discount)\n",
    "        self.assertEqual(env._player, 2)\n",
    "        self.assertEqual(env._board[0, 1, 0], 1.0)\n",
    "        self.assertEqual(env._board[0, 1, 1], 0.0)\n",
    "        self.assertEqual(env._action_mask[valid_action], 0.0)\n",
    "        self.assertEqual(env._step_count, 1)\n",
    "\n",
    "    @unittest.mock.patch('numpy.random.random')\n",
    "    @unittest.mock.patch('numpy.random.randint')\n",
    "    def test_step_transition_prob_0_5_adjacent_forced(self, mock_randint, mock_random):\n",
    "        \"\"\"Test _step for a non-terminal move with place_prob=0.5, forcing adjacent placement.\"\"\"\n",
    "        env = Standard_Env(board_size=(3, 3), win_condition=[3, 3, 3], rewards={'step': -0.1, 'row_dead_2': 0.02}, place_prob=0.5)\n",
    "        env.reset()\n",
    "        env._player = 1\n",
    "        env._board[0, 0, 0] = 1.0  # Set up for row_dead_2\n",
    "        env._action_mask[env.board_map_to_action(0, 0)] = 0.0\n",
    "\n",
    "        target_row, target_col = 0, 2\n",
    "        target_action = env.board_map_to_action(target_row, target_col)\n",
    "        forced_adjacent_square = (0, 1)\n",
    "        forced_adjacent_action = env.board_map_to_action(*forced_adjacent_square)\n",
    "        directions = [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1)]\n",
    "        forced_direction_index = directions.index((0, -1))  # (0,2) to (0,1)\n",
    "        mock_randint.return_value = forced_direction_index\n",
    "        mock_random.return_value = 0.6  # Force adjacent placement\n",
    "\n",
    "        # Block other adjacent squares\n",
    "        for dr, dc in directions:\n",
    "            adj_row, adj_col = target_row + dr, target_col + dc\n",
    "            if (adj_row, adj_col) != forced_adjacent_square and 0 <= adj_row < 3 and 0 <= adj_col < 3:\n",
    "                env._action_mask[env.board_map_to_action(adj_row, adj_col)] = 0.0\n",
    "\n",
    "        time_step = env.step(target_action)\n",
    "\n",
    "        self.assertEqual(time_step.step_type, ts.StepType.MID)\n",
    "        self.assertTrue(np.isclose(time_step.reward.item(), env._rewards['row_dead_2'] + env._rewards['step']))\n",
    "        self.assertEqual(time_step.discount, env._discount)\n",
    "        self.assertEqual(env._player, 2)\n",
    "        self.assertEqual(env._board[0, 1, 0], 1.0)\n",
    "        self.assertEqual(env._board[target_row, target_col, 0], 0.0)\n",
    "        self.assertEqual(env._action_mask[forced_adjacent_action], 0.0)\n",
    "        self.assertEqual(env._action_mask[target_action], 1.0)\n",
    "        self.assertEqual(env._step_count, 1)\n",
    "    \n",
    "    @unittest.mock.patch('numpy.random.random')\n",
    "    def test_step_forfeit_prob_0_5(self, mock_random):\n",
    "        \"\"\"Test _step for a forfeited move with place_prob=0.5.\"\"\"\n",
    "        env = Standard_Env(board_size=(3, 3), win_condition=[3, 3, 3], rewards={'forfeited': 0.0, 'step': -0.1}, place_prob=0.5)\n",
    "        env.reset()\n",
    "        initial_player = env._player\n",
    "\n",
    "        target_row, target_col = 1, 1\n",
    "        target_action = env.board_map_to_action(target_row, target_col)\n",
    "        env._action_mask[target_action] = 1.0  # Ensure target is valid\n",
    "        # Block all adjacent squares\n",
    "        for dr, dc in [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1)]:\n",
    "            adj_row, adj_col = target_row + dr, target_col + dc\n",
    "            if 0 <= adj_row < 3 and 0 <= adj_col < 3:\n",
    "                env._action_mask[env.board_map_to_action(adj_row, adj_col)] = 0.0\n",
    "\n",
    "        mock_random.return_value = 0.6  # Force adjacent placement\n",
    "        time_step = env.step(target_action)\n",
    "\n",
    "        self.assertEqual(time_step.step_type, ts.StepType.MID)\n",
    "        self.assertTrue(np.isclose(time_step.reward.item(), env._rewards['forfeited'] + env._rewards['step']))\n",
    "        self.assertIsNone(env._winner)\n",
    "        self.assertEqual(env._player, 3 - initial_player)\n",
    "        np.testing.assert_array_equal(env._board, np.zeros((3, 3, 2)))\n",
    "        self.assertEqual(env._step_count, 1)\n",
    "\n",
    "    def test_reset_after_termination(self):\n",
    "        \"\"\"Test _step after a terminal state triggers reset.\"\"\"\n",
    "        env = Standard_Env(board_size=(3, 3), win_condition=[3, 3, 3], rewards={'win': 10.0, 'step': -0.1, 'forfeited': 0.0}, place_prob=1.0)\n",
    "        env.reset()\n",
    "        env._player = 1\n",
    "        env._board[0, 0, 0] = 1.0\n",
    "        env._board[0, 1, 0] = 1.0\n",
    "        env._action_mask[env.board_map_to_action(0, 0)] = 0.0\n",
    "        env._action_mask[env.board_map_to_action(0, 1)] = 0.0\n",
    "        winning_action = env.board_map_to_action(0, 2)\n",
    "\n",
    "        time_step_terminal = env.step(winning_action)\n",
    "        self.assertEqual(time_step_terminal.step_type, ts.StepType.LAST)\n",
    "        self.assertEqual(env._winner, 1)\n",
    "\n",
    "        time_step_after_terminal = env.step(0)\n",
    "        self.assertEqual(time_step_after_terminal.step_type, ts.StepType.FIRST)\n",
    "        self.assertEqual(time_step_after_terminal.reward, 0.0)\n",
    "        self.assertIsNone(env._winner)\n",
    "        self.assertEqual(env._step_count, 0)\n",
    "        np.testing.assert_array_equal(env._board, np.zeros((3, 3, 2)))\n",
    "        np.testing.assert_array_equal(env._action_mask, np.ones(9))\n",
    "\n",
    "    def test_first_step_type(self):\n",
    "        \"\"\"Test that the first step returns StepType.MID if non-terminal.\"\"\"\n",
    "        env = Standard_Env(board_size=(3, 3), win_condition=[3, 3, 3])\n",
    "        env.reset()\n",
    "        initial_player = env._player\n",
    "\n",
    "        time_step = env.step(0)\n",
    "        self.assertEqual(time_step.step_type, ts.StepType.MID)\n",
    "        self.assertEqual(env._step_count, 1)\n",
    "        self.assertEqual(env._player, 3 - initial_player)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False, verbosity=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c88f2d",
   "metadata": {},
   "source": [
    "# Optimizer\n",
    "\n",
    "The `ScheduledAdamOptimizer` class extends TensorFlow's `Optimizer` to incorporate a dynamic learning rate schedule. It wraps the standard Adam optimizer, updating the learning rate based on the current training step, suitable for reinforcement learning tasks like PPO training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f9ed059",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScheduledAdamOptimizer(Optimizer):\n",
    "    \"\"\"Optimizer that applies the Adam algorithm with a dynamic learning rate schedule.\n",
    "\n",
    "    Args:\n",
    "        learning_rate_schedule: Callable that takes the current step and returns the learning rate.\n",
    "        **kwargs: Additional arguments passed to the base Adam optimizer.\n",
    "    \"\"\"\n",
    "    def __init__(self, learning_rate_schedule, **kwargs):\n",
    "        super().__init__(name='Adam', **kwargs)\n",
    "        self._learning_rate_schedule = learning_rate_schedule\n",
    "        self._current_step = tf.Variable(0, dtype=tf.int64, trainable=False)  # Tracks optimization steps\n",
    "        self._optimizer = Adam(learning_rate=self._learning_rate_schedule(self._current_step), **kwargs)  # Internal Adam optimizer\n",
    "\n",
    "    def _resource_apply_dense(self, grad, var, apply_state=None):\n",
    "        \"\"\"Applies gradients to dense variables using the internal Adam optimizer.\"\"\"\n",
    "        return self._optimizer._resource_apply_dense(grad, var, apply_state)\n",
    "\n",
    "    def _resource_apply_sparse(self, grad, var, indices, apply_state=None):\n",
    "        \"\"\"Applies gradients to sparse variables using the internal Adam optimizer.\"\"\"\n",
    "        return self._optimizer._resource_apply_sparse(grad, var, indices, apply_state)\n",
    "\n",
    "    def get_config(self):\n",
    "        \"\"\"Returns the configuration of the optimizer.\"\"\"\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'learning_rate_schedule': self._learning_rate_schedule\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @property\n",
    "    def learning_rate(self):\n",
    "        \"\"\"Evaluates and returns the current learning rate based on the schedule.\"\"\"\n",
    "        return self._learning_rate_schedule(self._current_step)\n",
    "\n",
    "    def _create_slots(self, var_list):\n",
    "        \"\"\"Creates slots for the internal Adam optimizer.\"\"\"\n",
    "        self._optimizer._create_slots(var_list)\n",
    "\n",
    "    def _prepare_local(self, var_device, var_dtype, apply_state):\n",
    "        \"\"\"Prepares local state, including the current learning rate.\"\"\"\n",
    "        apply_state = super()._prepare_local(var_device, var_dtype, apply_state)\n",
    "        apply_state[('learning_rate',)] = self.learning_rate\n",
    "        return apply_state\n",
    "\n",
    "    def apply_gradients(self, grads_and_vars, name=None, **kwargs):\n",
    "        \"\"\"Applies gradients to variables and increments the step counter.\"\"\"\n",
    "        self._current_step.assign_add(1)  # Increment step count\n",
    "        return self._optimizer.apply_gradients(grads_and_vars, name, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd1b199",
   "metadata": {},
   "source": [
    "# Utility Functions\n",
    "\n",
    "Utility functions for managing actions and trajectories in the reinforcement learning environment. These include selecting valid actions for Player 2 and preparing trajectories for the replay buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee04883a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p2_action(action_mask):\n",
    "    \"\"\"Select a random valid action for Player 2 based on the action mask.\n",
    "\n",
    "    Args:\n",
    "        action_mask: Array indicating valid actions (1 for valid, 0 for invalid).\n",
    "\n",
    "    Returns:\n",
    "        int: A randomly selected valid action.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If no valid actions are available.\n",
    "    \"\"\"\n",
    "    action_mask_np = action_mask[0] if action_mask.ndim > 1 else action_mask  # Flatten if needed\n",
    "    valid_actions = np.where(action_mask_np == 1)[0]  # Get indices of valid actions\n",
    "    if len(valid_actions) == 0:\n",
    "        raise ValueError(\"No valid actions available for P2\")\n",
    "    return np.random.choice(valid_actions)  # Randomly choose a valid action\n",
    "\n",
    "def prepare_trajectory_for_buffer(traj):\n",
    "    \"\"\"Prepare a trajectory for adding to the replay buffer by adjusting tensor shapes.\n",
    "\n",
    "    Args:\n",
    "        traj: Trajectory data with potentially unbatched tensors.\n",
    "\n",
    "    Returns:\n",
    "        Trajectory with tensors reshaped for batch compatibility.\n",
    "    \"\"\"\n",
    "    traj = tf.nest.map_structure(lambda t: tf.squeeze(t, axis=0) if t.shape.rank > 0 else t, traj)  # Remove batch dimension\n",
    "    batched_traj = tf.nest.map_structure(\n",
    "        lambda t: tf.expand_dims(t, axis=0) if t.shape.rank > 0 else tf.expand_dims(t, axis=0) if t.shape.rank == 0 else t,\n",
    "        traj\n",
    "    )  # Add batch dimension\n",
    "    return batched_traj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb60e238",
   "metadata": {},
   "source": [
    "# Logging\n",
    "\n",
    "The `PrintLogger` class redirects standard output and error streams to both the terminal and a specified log file, ensuring all training logs are persisted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f33f7999",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintLogger:\n",
    "    \"\"\"Redirects stdout/stderr to both terminal and a log file.\n",
    "\n",
    "    Args:\n",
    "        terminal: Original output stream (e.g., sys.stdout).\n",
    "        log_file: Path to the log file.\n",
    "\n",
    "    Raises:\n",
    "        OSError: If the log file cannot be opened.\n",
    "    \"\"\"\n",
    "    def __init__(self, terminal, log_file):\n",
    "        self.terminal = terminal\n",
    "        try:\n",
    "            self.log = open(log_file, 'a')  # Open log file in append mode\n",
    "        except OSError as e:\n",
    "            raise OSError(f\"Failed to open log file {log_file}: {e}\") from e\n",
    "    \n",
    "    def _write_to_log(self, message):\n",
    "        \"\"\"Writes a message to the log file if it is open.\"\"\"\n",
    "        if not self.log.closed:\n",
    "            self.log.write(message)\n",
    "            self.log.flush()\n",
    "\n",
    "    def write(self, message):\n",
    "        \"\"\"Writes a message to both terminal and log file.\"\"\"\n",
    "        self.terminal.write(message)\n",
    "        self._write_to_log(message)\n",
    "    \n",
    "    def flush(self):\n",
    "        \"\"\"Flushes both terminal and log file streams.\"\"\"\n",
    "        self.terminal.flush()\n",
    "        if not self.log.closed:\n",
    "            self.log.flush()\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Closes the log file if it is open.\"\"\"\n",
    "        if not self.log.closed:\n",
    "            self.log.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d259ac",
   "metadata": {},
   "source": [
    "# Policy Classes\n",
    "\n",
    "Policy classes for reinforcement learning, including `MaskedPolicy` for probabilistic action selection with action masks and `DeterministicMaskedPolicy` for deterministic action selection based on the highest valid action probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df5e5783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Policy Classes\n",
    "class MaskedPolicy(PyPolicy):\n",
    "    \"\"\"Wraps a base policy to mask invalid actions using an action mask.\n",
    "\n",
    "    Args:\n",
    "        base_policy: The underlying policy to wrap.\n",
    "        verbose: If True, prints debugging information about actions and probabilities.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_policy, verbose=False):\n",
    "        super().__init__(\n",
    "            time_step_spec=base_policy.time_step_spec,\n",
    "            action_spec=base_policy.action_spec,\n",
    "            policy_state_spec=base_policy.policy_state_spec\n",
    "        ) \n",
    "        self._base_policy = base_policy\n",
    "        self._verbose = verbose\n",
    "\n",
    "    def _action(self, timestep, policy_state, seed=None):\n",
    "        \"\"\"Generates an action by masking invalid actions in the base policy's distribution.\n",
    "\n",
    "        Args:\n",
    "            timestep: Current time step containing observation with action mask.\n",
    "            policy_state: Current state of the policy.\n",
    "            seed: Optional seed for sampling.\n",
    "\n",
    "        Returns:\n",
    "            PolicyStep: Contains the sampled action, state, and info.\n",
    "        \"\"\"\n",
    "        dist_step = self._base_policy.distribution(timestep, policy_state)\n",
    "        logits = dist_step.action.logits\n",
    "        action_mask = timestep.observation['action_mask']\n",
    "\n",
    "        masked_logits = logits + (action_mask - 1) * 1e10  # Apply mask to logits\n",
    "        dist = tfp.distributions.Categorical(logits=masked_logits)\n",
    "\n",
    "        action = dist.sample()\n",
    "        if self._verbose:\n",
    "            probs = tf.nn.softmax(logits).numpy()  # Compute probabilities before masking\n",
    "            print(f\"Action Mask: {action_mask.numpy()[0]}\")\n",
    "            print(f\"Before Masking - Logits: {logits.numpy()[0]}\")\n",
    "            print(f\"Before Masking - Probs: {probs[0]}\")\n",
    "            masked_probs = tf.nn.softmax(masked_logits).numpy()  # Compute probabilities after masking\n",
    "            print(f\"After Masking - Logits: {masked_logits.numpy()[0]}\")\n",
    "            print(f\"After Masking - Probs: {masked_probs[0]}\")\n",
    "            print(f\"After Masking - Action: {action[0]}\")\n",
    "\n",
    "        return policy_step.PolicyStep(action, dist_step.state, dist_step.info)\n",
    "\n",
    "class DeterministicMaskedPolicy(PyPolicy):\n",
    "    \"\"\"Wraps a base policy to select the best valid action deterministically.\n",
    "\n",
    "    Args:\n",
    "        base_policy: The underlying policy to wrap.\n",
    "        actor_network: Network used to compute action logits.\n",
    "        verbose: If True, prints debugging information about actions and probabilities.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_policy, actor_network, verbose=False):\n",
    "        super().__init__(\n",
    "            time_step_spec=base_policy.time_step_spec,\n",
    "            action_spec=base_policy.action_spec,\n",
    "            policy_state_spec=base_policy.policy_state_spec\n",
    "        )\n",
    "        self._base_policy = base_policy\n",
    "        self._actor_network = actor_network\n",
    "        self._verbose = verbose\n",
    "\n",
    "    def _action(self, timestep, policy_state, seed=None):\n",
    "        \"\"\"Generates a deterministic action by selecting the best valid action.\n",
    "\n",
    "        Args:\n",
    "            timestep: Current time step containing observation with action mask.\n",
    "            policy_state: Current state of the policy.\n",
    "            seed: Optional seed (unused in deterministic policy).\n",
    "\n",
    "        Returns:\n",
    "            PolicyStep: Contains the chosen action, state, and empty info.\n",
    "        \"\"\"\n",
    "        observation = timestep.observation\n",
    "        batched_observation = {\n",
    "            key: tf.expand_dims(value, axis=0) if value.shape.rank == 1 else value\n",
    "            for key, value in observation.items()\n",
    "        }\n",
    "        dist, _ = self._actor_network(batched_observation, timestep.step_type, policy_state)\n",
    "        logits = dist.logits\n",
    "        action_mask = timestep.observation['action_mask']\n",
    "\n",
    "        masked_logits = logits + (action_mask - 1) * 1e10  # Apply mask to logits\n",
    "        action = tf.argmax(masked_logits, axis=-1, output_type=tf.int32)  # Select action with highest logit\n",
    "\n",
    "        if self._verbose:\n",
    "            probs = tf.nn.softmax(logits).numpy()  # Compute probabilities before masking\n",
    "            print(f\"Action Mask (Eval): {action_mask.numpy()[0]}\")\n",
    "            print(f\"Before Masking - Logits (Eval): {logits.numpy()[0]}\")\n",
    "            print(f\"Before Masking - Probs (Eval): {probs[0]}\")\n",
    "            masked_probs = tf.nn.softmax(masked_logits).numpy()  # Compute probabilities after masking\n",
    "            print(f\"After Masking - Logits (Eval): {masked_logits.numpy()[0]}\")\n",
    "            print(f\"After Masking - Probs (Eval): {masked_probs[0]}\")\n",
    "            print(f\"After Masking - Action (Eval): {action[0]}\")\n",
    "\n",
    "        return policy_step.PolicyStep(action, policy_state, ())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737a2938",
   "metadata": {},
   "source": [
    "# Episode Collection\n",
    "\n",
    "The `EpisodeCollector` class manages the collection of training episodes for reinforcement learning, supporting both random and greedy opponents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "454332e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpisodeCollector:\n",
    "    \"\"\"Collects episodes for training using random or greedy opponents.\n",
    "\n",
    "    Args:\n",
    "        env: Environment to interact with.\n",
    "        rewards: Dictionary of reward values for win, lose, tie, and step.\n",
    "        def_level: Defensive level for reward adjustment.\n",
    "        deterministic_policy: Optional policy for greedy opponent.\n",
    "    \"\"\"\n",
    "    def __init__(self, env, rewards, def_level, deterministic_policy=None):\n",
    "        self.env = env\n",
    "        self.rewards = rewards\n",
    "        self.def_level = def_level\n",
    "        self.deterministic_policy = deterministic_policy\n",
    "\n",
    "    def collect_random(self, policy, replay_buffer, num_episodes, verbose=False):\n",
    "        \"\"\"Collects episodes with a random opponent and stores trajectories in the replay buffer.\n",
    "\n",
    "        Args:\n",
    "            policy: Policy for Player 1.\n",
    "            replay_buffer: Buffer to store trajectories.\n",
    "            num_episodes: Number of episodes to collect.\n",
    "            verbose: If True, prints trajectory and observation details.\n",
    "        \"\"\"\n",
    "        for _ in range(num_episodes):\n",
    "            timestep = self.env.reset()\n",
    "            if self.env._env._envs[0].get_current_player() == 2:\n",
    "                p2_action = get_p2_action(timestep.observation['action_mask'])  # Get random P2 action\n",
    "                timestep = self.env.step(p2_action)\n",
    "                timestep = timestep._replace(step_type=tf.constant(0, dtype=tf.int32))  # Set step type\n",
    "            \n",
    "            p1_policy_state = policy.get_initial_state(batch_size=1)\n",
    "            while not timestep.is_last():\n",
    "                action_step = policy.action(timestep, p1_policy_state)\n",
    "                p1_next_timestep = self.env.step(action_step.action)\n",
    "                p1_reward = p1_next_timestep.reward\n",
    "\n",
    "                if self.env._env._envs[0].get_winner() == 1:\n",
    "                    p1_observation = self.env._env._envs[0]._get_observation(current_player=1)  # Get P1 observation\n",
    "                    p1_next_timestep = p1_next_timestep._replace(observation=p1_observation)  # Update observation\n",
    "                    traj = from_transition(timestep, action_step, p1_next_timestep)  # Create trajectory\n",
    "                    if verbose:\n",
    "                        print(\"P1 traj:\", traj)\n",
    "                        print(\"p1_next_timestep obs:\", p1_next_timestep.observation, \"\\n\")\n",
    "                    replay_buffer.add_batch(prepare_trajectory_for_buffer(traj))\n",
    "                    break\n",
    "                \n",
    "                if p1_next_timestep.is_last():\n",
    "                    p1_observation = self.env._env._envs[0]._get_observation(current_player=1)  # Get P1 observation\n",
    "                    p1_next_timestep = p1_next_timestep._replace(observation=p1_observation)  # Update observation\n",
    "                    traj = from_transition(timestep, action_step, p1_next_timestep)  # Create trajectory\n",
    "                    if verbose:\n",
    "                        print(\"P1 traj:\", traj)\n",
    "                        print(\"p1_next_timestep obs:\", p1_next_timestep.observation, \"\\n\")\n",
    "                    replay_buffer.add_batch(prepare_trajectory_for_buffer(traj))\n",
    "                    break\n",
    "                \n",
    "                p1_policy_state = action_step.state\n",
    "                p2_action = get_p2_action(p1_next_timestep.observation['action_mask'])  # Get random P2 action\n",
    "                p2_next_timestep = self.env.step(p2_action)\n",
    "\n",
    "                if self.env._env._envs[0].get_winner() == 2:\n",
    "                    p2_observation = self.env._env._envs[0]._get_observation(current_player=1)  # Get P1 observation\n",
    "                    p2_next_timestep = p2_next_timestep._replace(\n",
    "                        observation=p2_observation,\n",
    "                        reward=tf.constant(self.rewards['lose'], dtype=tf.float32),\n",
    "                        step_type=tf.constant(2, dtype=tf.int32)\n",
    "                    )  # Update timestep\n",
    "                    traj = from_transition(timestep, action_step, p2_next_timestep)  # Create trajectory\n",
    "                    if verbose:\n",
    "                        print(\"P1 traj:\", traj)\n",
    "                        print(\"p2_next_timestep obs:\", p2_next_timestep.observation, \"\\n\")\n",
    "                    replay_buffer.add_batch(prepare_trajectory_for_buffer(traj))\n",
    "                    break\n",
    "                \n",
    "                if p2_next_timestep.is_last():\n",
    "                    p2_observation = self.env._env._envs[0]._get_observation(current_player=1)  # Get P1 observation\n",
    "                    p2_next_timestep = p2_next_timestep._replace(\n",
    "                        observation=p2_observation,\n",
    "                        reward=tf.constant(self.rewards['tie'], dtype=tf.float32),\n",
    "                        step_type=tf.constant(2, dtype=tf.int32)\n",
    "                    )  # Update timestep\n",
    "                    traj = from_transition(timestep, action_step, p2_next_timestep)  # Create trajectory\n",
    "                    if verbose:\n",
    "                        print(\"P1 traj:\", traj)\n",
    "                        print(\"p2_next_timestep obs:\", p2_next_timestep.observation, \"\\n\")\n",
    "                    replay_buffer.add_batch(prepare_trajectory_for_buffer(traj))\n",
    "                    break\n",
    "                \n",
    "                p2_pattern_reward = p2_next_timestep.reward - self.rewards['step']  # Compute P2 pattern reward\n",
    "                adjusted_reward = p1_reward - self.def_level * p2_pattern_reward  # Adjust reward\n",
    "                p2_next_timestep = p2_next_timestep._replace(reward=adjusted_reward)  # Update reward\n",
    "                traj = from_transition(timestep, action_step, p2_next_timestep)  # Create trajectory\n",
    "                if verbose:\n",
    "                    print(\"P1 traj:\", traj)\n",
    "                    print(\"p2_next_timestep obs:\", p2_next_timestep.observation, \"\\n\")\n",
    "                replay_buffer.add_batch(prepare_trajectory_for_buffer(traj))\n",
    "                timestep = p2_next_timestep  # Update timestep\n",
    "\n",
    "    def collect_selfplay(self, policy, replay_buffer, num_episodes, verbose=False):\n",
    "        \"\"\"Collects episodes with a greedy opponent using DeterministicMaskedPolicy.\n",
    "\n",
    "        Args:\n",
    "            policy: Policy for Player 1.\n",
    "            replay_buffer: Buffer to store trajectories.\n",
    "            num_episodes: Number of episodes to collect.\n",
    "            verbose: If True, prints trajectory and observation details.\n",
    "        \"\"\"\n",
    "        for _ in range(num_episodes):\n",
    "            timestep = self.env.reset()  # Reset environment\n",
    "            p2_policy_state = self.deterministic_policy.get_initial_state(batch_size=1)  # Initialize P2 policy state\n",
    "            if self.env._env._envs[0].get_current_player() == 2:\n",
    "                p2_action_step = self.deterministic_policy.action(timestep, p2_policy_state)  # Get P2 action\n",
    "                p2_action = p2_action_step.action\n",
    "                p2_policy_state = p2_action_step.state\n",
    "                timestep = self.env.step(p2_action)  # Step environment\n",
    "                timestep = timestep._replace(step_type=tf.constant(0, dtype=tf.int32))  # Set step type\n",
    "            \n",
    "            p1_policy_state = policy.get_initial_state(batch_size=1)  # Initialize P1 policy state\n",
    "            while not timestep.is_last():\n",
    "                action_step = policy.action(timestep, p1_policy_state)  # Get P1 action\n",
    "                p1_next_timestep = self.env.step(action_step.action)  # Step environment\n",
    "                p1_reward = p1_next_timestep.reward  # Get P1 reward\n",
    "\n",
    "                if self.env._env._envs[0].get_winner() == 1:\n",
    "                    p1_observation = self.env._env._envs[0]._get_observation(current_player=1)  # Get P1 observation\n",
    "                    p1_next_timestep = p1_next_timestep._replace(observation=p1_observation)  # Update observation\n",
    "                    traj = from_transition(timestep, action_step, p1_next_timestep)  # Create trajectory\n",
    "                    if verbose:\n",
    "                        print(\"P1 traj:\", traj)\n",
    "                        print(\"p1_next_timestep obs:\", p1_next_timestep.observation, \"\\n\")\n",
    "                    replay_buffer.add_batch(prepare_trajectory_for_buffer(traj))  # Add to buffer\n",
    "                    break\n",
    "                \n",
    "                if p1_next_timestep.is_last():\n",
    "                    p1_observation = self.env._env._envs[0]._get_observation(current_player=1)  # Get P1 observation\n",
    "                    p1_next_timestep = p1_next_timestep._replace(observation=p1_observation)  # Update observation\n",
    "                    traj = from_transition(timestep, action_step, p1_next_timestep)  # Create trajectory\n",
    "                    if verbose:\n",
    "                        print(\"P1 traj:\", traj)\n",
    "                        print(\"p1_next_timestep obs:\", p1_next_timestep.observation, \"\\n\")\n",
    "                    replay_buffer.add_batch(prepare_trajectory_for_buffer(traj))  # Add to buffer\n",
    "                    break\n",
    "                \n",
    "                p1_policy_state = action_step.state  # Update P1 policy state\n",
    "                p2_action_step = self.deterministic_policy.action(p1_next_timestep, p2_policy_state)  # Get P2 action\n",
    "                p2_action = p2_action_step.action\n",
    "                p2_policy_state = p2_action_step.state\n",
    "                p2_next_timestep = self.env.step(p2_action)  # Step environment\n",
    "\n",
    "                if self.env._env._envs[0].get_winner() == 2:\n",
    "                    p2_observation = self.env._env._envs[0]._get_observation(current_player=1)  # Get P1 observation\n",
    "                    p2_next_timestep = p2_next_timestep._replace(\n",
    "                        observation=p2_observation,\n",
    "                        reward=tf.constant(self.rewards['lose'], dtype=tf.float32),\n",
    "                        step_type=tf.constant(2, dtype=tf.int32)\n",
    "                    )  # Update timestep\n",
    "                    traj = from_transition(timestep, action_step, p2_next_timestep)  # Create trajectory\n",
    "                    if verbose:\n",
    "                        print(\"P1 traj:\", traj)\n",
    "                        print(\"p2_next_timestep obs:\", p2_next_timestep.observation, \"\\n\")\n",
    "                    replay_buffer.add_batch(prepare_trajectory_for_buffer(traj))  # Add to buffer\n",
    "                    break\n",
    "                \n",
    "                if p2_next_timestep.is_last():\n",
    "                    p2_observation = self.env._env._envs[0]._get_observation(current_player=1)  # Get P1 observation\n",
    "                    p2_next_timestep = p2_next_timestep._replace(\n",
    "                        observation=p2_observation,\n",
    "                        reward=tf.constant(self.rewards['tie'], dtype=tf.float32),\n",
    "                        step_type=tf.constant(2, dtype=tf.int32)\n",
    "                    )  # Update timestep\n",
    "                    traj = from_transition(timestep, action_step, p2_next_timestep)  # Create trajectory\n",
    "                    if verbose:\n",
    "                        print(\"P1 traj:\", traj)\n",
    "                        print(\"p2_next_timestep obs:\", p2_next_timestep.observation, \"\\n\")\n",
    "                    replay_buffer.add_batch(prepare_trajectory_for_buffer(traj))  # Add to buffer\n",
    "                    break\n",
    "                \n",
    "                p2_pattern_reward = p2_next_timestep.reward - self.rewards['step']  # Compute P2 pattern reward\n",
    "                adjusted_reward = p1_reward - self.def_level * p2_pattern_reward  # Adjust reward\n",
    "                p2_next_timestep = p2_next_timestep._replace(reward=adjusted_reward)  # Update reward\n",
    "                traj = from_transition(timestep, action_step, p2_next_timestep)  # Create trajectory\n",
    "                if verbose:\n",
    "                    print(\"P1 traj:\", traj)\n",
    "                    print(\"p2_next_timestep obs:\", p2_next_timestep.observation, \"\\n\")\n",
    "                replay_buffer.add_batch(prepare_trajectory_for_buffer(traj))  # Add to buffer\n",
    "                timestep = p2_next_timestep  # Update timestep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c73a20a",
   "metadata": {},
   "source": [
    "# Policy Evaluation\n",
    "\n",
    "The `PolicyEvaluator` class evaluates a policy's performance by playing against random or greedy opponents, tracking metrics like average reward, win rate, and step count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90c0b401",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyEvaluator:\n",
    "    \"\"\"Evaluates a policy against random or greedy opponents.\n",
    "\n",
    "    Args:\n",
    "        env: Environment to interact with.\n",
    "        rewards: Dictionary of reward values for win, lose, tie, and step.\n",
    "        def_level: Defensive level for reward adjustment.\n",
    "        deterministic_policy: Optional policy for greedy opponent.\n",
    "    \"\"\"\n",
    "    def __init__(self, env, rewards, def_level, deterministic_policy=None):\n",
    "        self.env = env  # Store environment\n",
    "        self.rewards = rewards  # Store reward configuration\n",
    "        self.def_level = def_level  # Store defensive level\n",
    "        self.deterministic_policy = deterministic_policy  # Store deterministic policy\n",
    "\n",
    "    def evaluate_random(self, policy, num_episodes, verbose=False):\n",
    "        \"\"\"Evaluates a policy against a random opponent.\n",
    "\n",
    "        Args:\n",
    "            policy: Policy for Player 1.\n",
    "            num_episodes: Number of episodes to evaluate.\n",
    "            verbose: If True, prints reward and termination details.\n",
    "\n",
    "        Returns:\n",
    "            tuple: Average reward, win rate, loss rate, tie rate, average steps, P1 illegal rate, P2 illegal rate.\n",
    "        \"\"\"\n",
    "        total_reward = 0.0\n",
    "        wins = 0\n",
    "        losses = 0\n",
    "        ties = 0\n",
    "        step_counts = 0\n",
    "        p1_illegals = 0\n",
    "        p2_illegals = 0\n",
    "        \n",
    "        for _ in range(num_episodes):\n",
    "            timestep = self.env.reset()  # Reset environment\n",
    "            policy_state = policy.get_initial_state(batch_size=1)  # Initialize policy state\n",
    "            episode_reward = 0.0\n",
    "            \n",
    "            while not timestep.is_last():\n",
    "                if self.env._env._envs[0].get_current_player() == 1:\n",
    "                    action_step = policy.action(timestep, policy_state)  # Get P1 action\n",
    "                    next_timestep = self.env.step(action_step.action)  # Step environment\n",
    "                    p1_reward = next_timestep.reward  # Get P1 reward\n",
    "                    \n",
    "                    if next_timestep.is_last():\n",
    "                        episode_reward += p1_reward.numpy()[0]  # Accumulate reward\n",
    "                        if verbose:\n",
    "                            print(f\"P1 terminates. P1 reward = {p1_reward.numpy()[0]}\")\n",
    "                    else:\n",
    "                        p2_action = get_p2_action(next_timestep.observation['action_mask'])  # Get random P2 action\n",
    "                        p2_next_timestep = self.env.step(p2_action)  # Step environment\n",
    "                        p2_reward = p2_next_timestep.reward  # Get P2 reward\n",
    "                        winner = self.env._env._envs[0].get_winner()  # Check winner\n",
    "                        if winner == 2:\n",
    "                            episode_reward += self.rewards['lose']  # Accumulate loss reward\n",
    "                            if verbose:\n",
    "                                print(f\"P2 terminates. P1 reward = {self.rewards['lose']}\")\n",
    "                        elif winner == 0:\n",
    "                            episode_reward += self.rewards['tie']  # Accumulate tie reward\n",
    "                            if verbose:\n",
    "                                print(f\"P2 terminates. P1 reward = {self.rewards['tie']}\")\n",
    "                        elif winner is None:\n",
    "                            p2_pattern_reward = p2_reward.numpy()[0] - self.rewards['step']  # Compute P2 pattern reward\n",
    "                            mid_reward = p1_reward.numpy()[0] - self.def_level * p2_pattern_reward  # Adjust reward\n",
    "                            episode_reward += mid_reward  # Accumulate adjusted reward\n",
    "                            if verbose:\n",
    "                                print(f\"Mid. P1 reward = {p1_reward.numpy()[0]} - {self.def_level} * {p2_pattern_reward} = {mid_reward}\")\n",
    "                        else:\n",
    "                            raise ValueError(\"Random P2 makes illegal move!\")\n",
    "                        timestep = p2_next_timestep  # Update timestep\n",
    "                        continue\n",
    "                    \n",
    "                    policy_state = action_step.state  # Update policy state\n",
    "                else:\n",
    "                    p2_action = get_p2_action(timestep.observation['action_mask'])  # Get random P2 action\n",
    "                    next_timestep = self.env.step(p2_action)  # Step environment\n",
    "                \n",
    "                timestep = next_timestep  # Update timestep\n",
    "            if verbose:\n",
    "                print(f\"P1 episode reward = {episode_reward}\")\n",
    "\n",
    "            if timestep.is_last():\n",
    "                winner = self.env._env._envs[0].get_winner()  # Check winner\n",
    "                current_player = self.env._env._envs[0].get_current_player()  # Check current player\n",
    "                if winner == 1 and current_player == 1:\n",
    "                    wins += 1  # Increment wins\n",
    "                elif winner == 2 and current_player == 2:\n",
    "                    losses += 1  # Increment losses\n",
    "                elif winner == 0:\n",
    "                    ties += 1  # Increment ties\n",
    "                elif winner == 2 and current_player == 1:\n",
    "                    p1_illegals += 1  # Increment P1 illegal moves\n",
    "                elif winner == 1 and current_player == 2:\n",
    "                    p2_illegals += 1  # Increment P2 illegal moves\n",
    "            \n",
    "            total_reward += episode_reward  # Accumulate total reward\n",
    "            step_counts += self.env._env._envs[0]._step_count  # Accumulate step count\n",
    "        return (total_reward / num_episodes, wins / num_episodes,\n",
    "                losses / num_episodes, ties / num_episodes, step_counts / num_episodes,\n",
    "                p1_illegals / num_episodes, p2_illegals / num_episodes)  # Return averages\n",
    "\n",
    "    def evaluate_selfplay(self, policy, num_episodes, verbose=False):\n",
    "        \"\"\"Evaluates a policy against a greedy opponent using DeterministicMaskedPolicy.\n",
    "\n",
    "        Args:\n",
    "            policy: Policy for Player 1.\n",
    "            num_episodes: Number of episodes to evaluate.\n",
    "            verbose: If True, prints reward and termination details.\n",
    "\n",
    "        Returns:\n",
    "            tuple: Average reward, win rate, loss rate, tie rate, average steps, P1 illegal rate, P2 illegal rate.\n",
    "        \"\"\"\n",
    "        total_reward = 0.0\n",
    "        wins = 0\n",
    "        losses = 0\n",
    "        ties = 0\n",
    "        step_counts = 0\n",
    "        p1_illegals = 0\n",
    "        p2_illegals = 0\n",
    "        \n",
    "        for _ in range(num_episodes):\n",
    "            timestep = self.env.reset()  # Reset environment\n",
    "            policy_state = policy.get_initial_state(batch_size=1)  # Initialize P1 policy state\n",
    "            p2_policy_state = self.deterministic_policy.get_initial_state(batch_size=1)  # Initialize P2 policy state\n",
    "            episode_reward = 0.0\n",
    "            \n",
    "            while not timestep.is_last():\n",
    "                if self.env._env._envs[0].get_current_player() == 1:\n",
    "                    action_step = policy.action(timestep, policy_state)  # Get P1 action\n",
    "                    next_timestep = self.env.step(action_step.action)  # Step environment\n",
    "                    p1_reward = next_timestep.reward  # Get P1 reward\n",
    "                    \n",
    "                    if next_timestep.is_last():\n",
    "                        episode_reward += p1_reward.numpy()[0]  # Accumulate reward\n",
    "                        if verbose:\n",
    "                            print(f\"P1 terminates. P1 reward = {p1_reward.numpy()[0]}\")\n",
    "                    else:\n",
    "                        p2_action_step = self.deterministic_policy.action(next_timestep, p2_policy_state)  # Get P2 action\n",
    "                        p2_action = p2_action_step.action\n",
    "                        p2_policy_state = p2_action_step.state\n",
    "                        p2_next_timestep = self.env.step(p2_action)  # Step environment\n",
    "                        p2_reward = p2_next_timestep.reward  # Get P2 reward\n",
    "                        winner = self.env._env._envs[0].get_winner()  # Check winner\n",
    "                        if winner == 2:\n",
    "                            episode_reward += self.rewards['lose']  # Accumulate loss reward\n",
    "                            if verbose:\n",
    "                                print(f\"P2 terminates. P1 reward = {self.rewards['lose']}\")\n",
    "                        elif winner == 0:\n",
    "                            episode_reward += self.rewards['tie']  # Accumulate tie reward\n",
    "                            if verbose:\n",
    "                                print(f\"P2 terminates. P1 reward = {self.rewards['tie']}\")\n",
    "                        elif winner is None:\n",
    "                            p2_pattern_reward = p2_reward.numpy()[0] - self.rewards['step']  # Compute P2 pattern reward\n",
    "                            mid_reward = p1_reward.numpy()[0] - self.def_level * p2_pattern_reward  # Adjust reward\n",
    "                            episode_reward += mid_reward  # Accumulate adjusted reward\n",
    "                            if verbose:\n",
    "                                print(f\"Mid. P1 reward = {p1_reward.numpy()[0]} - {self.def_level} * {p2_pattern_reward} = {mid_reward}\")\n",
    "                        else:\n",
    "                            raise ValueError(\"Greedy P2 makes illegal move!\")\n",
    "                        timestep = p2_next_timestep  # Update timestep\n",
    "                        continue\n",
    "                    \n",
    "                    policy_state = action_step.state  # Update P1 policy state\n",
    "                else:\n",
    "                    p2_action_step = self.deterministic_policy.action(timestep, p2_policy_state)  # Get P2 action\n",
    "                    p2_action = p2_action_step.action\n",
    "                    p2_policy_state = p2_action_step.state\n",
    "                    next_timestep = self.env.step(p2_action)  # Step environment\n",
    "                \n",
    "                timestep = next_timestep  # Update timestep\n",
    "            if verbose:\n",
    "                print(f\"P1 episode reward = {episode_reward}\")\n",
    "\n",
    "            if timestep.is_last():\n",
    "                winner = self.env._env._envs[0].get_winner()  # Check winner\n",
    "                current_player = self.env._env._envs[0].get_current_player()  # Check current player\n",
    "                if winner == 1 and current_player == 1:\n",
    "                    wins += 1  # Increment wins\n",
    "                elif winner == 2 and current_player == 2:\n",
    "                    losses += 1  # Increment losses\n",
    "                elif winner == 0:\n",
    "                    ties += 1  # Increment ties\n",
    "                elif winner == 2 and current_player == 1:\n",
    "                    p1_illegals += 1  # Increment P1 illegal moves\n",
    "                elif winner == 1 and current_player == 2:\n",
    "                    p2_illegals += 1  # Increment P2 illegal moves\n",
    "            \n",
    "            total_reward += episode_reward  # Accumulate total reward\n",
    "            step_counts += self.env._env._envs[0]._step_count  # Accumulate step count\n",
    "        return (total_reward / num_episodes, wins / num_episodes,\n",
    "                losses / num_episodes, ties / num_episodes, step_counts / num_episodes,\n",
    "                p1_illegals / num_episodes, p2_illegals / num_episodes)  # Return averages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572daab0",
   "metadata": {},
   "source": [
    "# PPO Training\n",
    "\n",
    "The `PPOTrainer` class orchestrates the Proximal Policy Optimization (PPO) training pipeline, including environment setup, agent training, episode collection, evaluation, and logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3878c948",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPOTrainer:\n",
    "    \"\"\"Manages the PPO training pipeline, including environment, agent, and metrics.\n",
    "\n",
    "    Args:\n",
    "        config: Dictionary containing training configuration parameters.\n",
    "        resume_from_checkpoint: Optional path to checkpoint for resuming training.\n",
    "    \"\"\"\n",
    "    def __init__(self, config, resume_from_checkpoint=None):\n",
    "        self.config = config\n",
    "        self.save_dir = config['train_log_dir']\n",
    "        self.checkpoint_dir = os.path.join(self.save_dir, 'checkpoint')\n",
    "        self.metrics_file = os.path.join(self.save_dir, 'metrics.npz')\n",
    "        self.policy_dir = os.path.join(self.save_dir, 'actor_network')\n",
    "        self.policy_v1_dir = os.path.join(self.save_dir, 'policy_v1')\n",
    "        self.policy_v2_dir = os.path.join(self.save_dir, 'policy_v2')\n",
    "        self.num_iterations = config['phase1_iterations'] + config['phase2_iterations']\n",
    "        \n",
    "        # Validate and create directories\n",
    "        try:\n",
    "            os.makedirs(self.save_dir, exist_ok=True)\n",
    "            os.makedirs(self.checkpoint_dir, exist_ok=True)\n",
    "            os.makedirs(self.policy_dir, exist_ok=True)\n",
    "            os.makedirs(self.policy_v1_dir, exist_ok=True)\n",
    "            os.makedirs(self.policy_v2_dir, exist_ok=True)\n",
    "            if not os.access(self.save_dir, os.W_OK):\n",
    "                raise PermissionError(f\"No write permission for directory: {self.save_dir}\")\n",
    "            if not os.access(self.checkpoint_dir, os.W_OK):\n",
    "                raise PermissionError(f\"No write permission for directory: {self.checkpoint_dir}\")\n",
    "            if not os.access(self.policy_dir, os.W_OK):\n",
    "                raise PermissionError(f\"No write permission for directory: {self.policy_dir}\")\n",
    "            if not os.access(self.policy_v1_dir, os.W_OK):\n",
    "                raise PermissionError(f\"No write permission for directory: {self.policy_v1_dir}\")\n",
    "            if not os.access(self.policy_v2_dir, os.W_OK):\n",
    "                raise PermissionError(f\"No write permission for directory: {self.policy_v2_dir}\")\n",
    "        except OSError as e:\n",
    "            raise OSError(f\"Failed to set up directories: {e}\") from e\n",
    "\n",
    "        # Initialize training and evaluation environments\n",
    "        self.train_env = tf_py_environment.TFPyEnvironment(\n",
    "            Standard_Env(\n",
    "                board_size=config['board_size'],\n",
    "                win_condition=config['win_condition'],\n",
    "                unplayable_grids=config['unplayable_grids'],\n",
    "                rewards=config['rewards'],\n",
    "                def_level=config['def_level'],\n",
    "                place_prob=config['place_prob'],\n",
    "                show=False\n",
    "            )\n",
    "        )\n",
    "        self.eval_env = tf_py_environment.TFPyEnvironment(\n",
    "            Standard_Env(\n",
    "                board_size=config['board_size'],\n",
    "                win_condition=config['win_condition'],\n",
    "                unplayable_grids=config['unplayable_grids'],\n",
    "                rewards=config['rewards'],\n",
    "                def_level=config['def_level'],\n",
    "                place_prob=config['place_prob'],\n",
    "                show=True\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Initialize neural networks for actor and value functions\n",
    "        preprocessing_layers = {\n",
    "            'board': tf.keras.Sequential([\n",
    "                tf.keras.layers.Conv2D(16, 2, activation='relu', padding='same'),\n",
    "                tf.keras.layers.Flatten()\n",
    "            ]),\n",
    "            'action_mask': tf.keras.layers.Dense(16, activation='relu')\n",
    "        }\n",
    "        self.actor_net = actor_distribution_network.ActorDistributionNetwork(\n",
    "            self.train_env.observation_spec(),\n",
    "            self.train_env.action_spec(),\n",
    "            preprocessing_layers=preprocessing_layers,\n",
    "            preprocessing_combiner=tf.keras.layers.Concatenate(),\n",
    "            fc_layer_params=config['fc_layer_params']\n",
    "        )\n",
    "        self.value_net = value_network.ValueNetwork(\n",
    "            self.train_env.observation_spec(),\n",
    "            preprocessing_layers=preprocessing_layers,\n",
    "            preprocessing_combiner=tf.keras.layers.Concatenate(),\n",
    "            fc_layer_params=config['fc_layer_params']\n",
    "        )\n",
    "\n",
    "        # Set up learning rate schedule and optimizer\n",
    "        learning_rate_schedule = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "            initial_learning_rate=config['initial_learning_rate'],\n",
    "            decay_steps=config['decay_steps'],\n",
    "            end_learning_rate=config['end_learning_rate'],\n",
    "            power=1.0\n",
    "        )\n",
    "        optimizer = ScheduledAdamOptimizer(learning_rate_schedule=learning_rate_schedule)\n",
    "\n",
    "        # Initialize PPO agent\n",
    "        self.agent = ppo_agent.PPOAgent(\n",
    "            self.train_env.time_step_spec(),\n",
    "            self.train_env.action_spec(),\n",
    "            actor_net=self.actor_net,\n",
    "            value_net=self.value_net,\n",
    "            optimizer=optimizer,\n",
    "            num_epochs=5,\n",
    "            entropy_regularization=0.2,\n",
    "            importance_ratio_clipping=0.2\n",
    "        )\n",
    "        self.agent.initialize()\n",
    "\n",
    "        self.replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "            data_spec=self.agent.collect_data_spec,\n",
    "            batch_size=self.train_env.batch_size,\n",
    "            max_length=10000\n",
    "        )\n",
    "\n",
    "        self.masked_policy = MaskedPolicy(self.agent.collect_policy, verbose=False)\n",
    "        self.deterministic_masked_policy = DeterministicMaskedPolicy(self.agent.policy, self.actor_net, verbose=False)\n",
    "        self.policy_v1 = None\n",
    "\n",
    "        self.collector = EpisodeCollector(self.train_env, config['rewards'], config['def_level'], deterministic_policy=self.deterministic_masked_policy)\n",
    "        self.evaluator = PolicyEvaluator(self.eval_env, config['rewards'], config['def_level'], deterministic_policy=self.deterministic_masked_policy)\n",
    "\n",
    "        self.train_summary_phase1 = tf.summary.create_file_writer(os.path.join(self.save_dir, 'phase1'))\n",
    "        self.train_summary_phase2 = tf.summary.create_file_writer(os.path.join(self.save_dir, 'phase2'))\n",
    "        self.checkpointer = common.Checkpointer(\n",
    "            ckpt_dir=self.checkpoint_dir,\n",
    "            max_to_keep=1,\n",
    "            agent=self.agent,\n",
    "            actor_net=self.actor_net,\n",
    "            value_net=self.value_net,\n",
    "            global_step=self.agent.train_step_counter\n",
    "        )\n",
    "\n",
    "        # Initialize metrics dictionary for tracking training and evaluation\n",
    "        self.metrics = {\n",
    "            'train_losses': [],\n",
    "            'random_avg_rewards_phase1': [],\n",
    "            'random_win_rates_phase1': [],\n",
    "            'random_tie_rates_phase1': [],\n",
    "            'random_lose_rates_phase1': [],\n",
    "            'random_avg_step_counts_phase1': [],\n",
    "            'random_avg_rewards_phase2': [],\n",
    "            'random_win_rates_phase2': [],\n",
    "            'random_tie_rates_phase2': [],\n",
    "            'random_lose_rates_phase2': [],\n",
    "            'random_avg_step_counts_phase2': [],\n",
    "            'selfplay_avg_rewards_phase2': [],\n",
    "            'selfplay_win_rates_phase2': [],\n",
    "            'selfplay_tie_rates_phase2': [],\n",
    "            'selfplay_lose_rates_phase2': [],\n",
    "            'selfplay_avg_step_counts_phase2': []\n",
    "        }\n",
    "\n",
    "        if resume_from_checkpoint:\n",
    "            self.load_from_checkpoint(resume_from_checkpoint)\n",
    "\n",
    "    def save_metrics(self):\n",
    "        \"\"\"Saves training metrics to a .npz file.\"\"\"\n",
    "        try:\n",
    "            np.savez(self.metrics_file, **self.metrics)\n",
    "            print(f\"Metrics saved to {self.metrics_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to save metrics: {e}\")\n",
    "\n",
    "    def save_policy(self, policy_dir, policy_name):\n",
    "        \"\"\"Saves the actor network to the specified directory.\n",
    "\n",
    "        Args:\n",
    "            policy_dir: Directory to save the policy.\n",
    "            policy_name: Name of the policy for logging.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            tf.saved_model.save(self.actor_net, policy_dir)\n",
    "            print(f\"{policy_name} saved to {policy_dir}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to save {policy_name}: {e}\")\n",
    "\n",
    "    def log_train_loss(self, step, train_loss, phase):\n",
    "        \"\"\"Logs training loss to TensorBoard for the specified phase.\n",
    "\n",
    "        Args:\n",
    "            step: Current training step.\n",
    "            train_loss: Loss value to log.\n",
    "            phase: Training phase (1 or 2).\n",
    "        \"\"\"\n",
    "        summary_writer = self.train_summary_phase1 if phase == 1 else self.train_summary_phase2\n",
    "        prefix = 'phase1' if phase == 1 else 'phase2'\n",
    "        with summary_writer.as_default():\n",
    "            tf.summary.scalar(f'{prefix}/train/loss', train_loss, step=step)\n",
    "        summary_writer.flush()\n",
    "\n",
    "    def log_eval_metrics(self, step, phase):\n",
    "        \"\"\"Logs evaluation metrics to TensorBoard for the specified phase.\n",
    "\n",
    "        Args:\n",
    "            step: Current training step.\n",
    "            phase: Training phase (1 or 2).\n",
    "        \"\"\"\n",
    "        summary_writer = self.train_summary_phase1 if phase == 1 else self.train_summary_phase2\n",
    "        prefix = 'phase1' if phase == 1 else 'phase2'\n",
    "        with summary_writer.as_default():\n",
    "            if phase == 1 and self.metrics['random_avg_rewards_phase1']:\n",
    "                tf.summary.scalar(f'{prefix}/eval/random_avg_reward', self.metrics['random_avg_rewards_phase1'][-1], step=step)\n",
    "                tf.summary.scalar(f'{prefix}/eval/random_win_rate', self.metrics['random_win_rates_phase1'][-1], step=step)\n",
    "                tf.summary.scalar(f'{prefix}/eval/random_tie_rate', self.metrics['random_tie_rates_phase1'][-1], step=step)\n",
    "                tf.summary.scalar(f'{prefix}/eval/random_loss_rate', self.metrics['random_lose_rates_phase1'][-1], step=step)\n",
    "                tf.summary.scalar(f'{prefix}/eval/random_avg_step_count', self.metrics['random_avg_step_counts_phase1'][-1], step=step)\n",
    "            if phase == 2:\n",
    "                if self.metrics['random_avg_rewards_phase2']:\n",
    "                    tf.summary.scalar(f'{prefix}/eval/random_avg_reward', self.metrics['random_avg_rewards_phase2'][-1], step=step)\n",
    "                    tf.summary.scalar(f'{prefix}/eval/random_win_rate', self.metrics['random_win_rates_phase2'][-1], step=step)\n",
    "                    tf.summary.scalar(f'{prefix}/eval/random_tie_rate', self.metrics['random_tie_rates_phase2'][-1], step=step)\n",
    "                    tf.summary.scalar(f'{prefix}/eval/random_loss_rate', self.metrics['random_lose_rates_phase2'][-1], step=step)\n",
    "                    tf.summary.scalar(f'{prefix}/eval/random_avg_step_count', self.metrics['random_avg_step_counts_phase2'][-1], step=step)\n",
    "                if self.metrics['selfplay_avg_rewards_phase2']:\n",
    "                    tf.summary.scalar(f'{prefix}/eval/selfplay_avg_reward', self.metrics['selfplay_avg_rewards_phase2'][-1], step=step)\n",
    "                    tf.summary.scalar(f'{prefix}/eval/selfplay_win_rate', self.metrics['selfplay_win_rates_phase2'][-1], step=step)\n",
    "                    tf.summary.scalar(f'{prefix}/eval/selfplay_tie_rate', self.metrics['selfplay_tie_rates_phase2'][-1], step=step)\n",
    "                    tf.summary.scalar(f'{prefix}/eval/selfplay_lose_rate', self.metrics['selfplay_lose_rates_phase2'][-1], step=step)\n",
    "                    tf.summary.scalar(f'{prefix}/eval/selfplay_avg_step_count', self.metrics['selfplay_avg_step_counts_phase2'][-1], step=step)\n",
    "        summary_writer.flush()\n",
    "\n",
    "    def trigger_system_sleep(self):\n",
    "        \"\"\"Triggers system sleep on macOS.\"\"\"\n",
    "        try:\n",
    "            subprocess.run(\"pmset sleepnow\", shell=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to trigger system sleep: {e}\")\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Executes the PPO training loop with two phases: random opponent and self-play.\"\"\"\n",
    "        def handle_crash(exctype, value, traceback):\n",
    "            print(f\"\\nKernel crashed with {exctype}: {value}\")\n",
    "            print(\"Saving policy and metrics...\")\n",
    "            self.save_metrics()\n",
    "            self.save_policy(self.policy_v1_dir, \"Policy V1\")\n",
    "            self.save_policy(self.policy_v2_dir, \"Policy V2\")\n",
    "            sys.__excepthook__(exctype, value, traceback)\n",
    "\n",
    "        sys.excepthook = handle_crash  # Override default exception handler for crashes\n",
    "\n",
    "        try:\n",
    "            for i in range(self.config['phase1_iterations']):\n",
    "                print(f\"Phase 1 - Iteration {i+1}/{self.config['phase1_iterations']}\")\n",
    "                self.collector.collect_random(\n",
    "                    self.masked_policy,\n",
    "                    self.replay_buffer,\n",
    "                    self.config['num_collect_episodes'],\n",
    "                    verbose=False\n",
    "                )\n",
    "                experience = self.replay_buffer.gather_all()\n",
    "                weights_before = self.actor_net.get_weights()\n",
    "                train_loss = self.agent.train(experience).loss\n",
    "                weights_after = self.actor_net.get_weights()\n",
    "                weight_diff = [np.any(w_before != w_after) for w_before, w_after in zip(weights_before, weights_after)]\n",
    "                print(f\"Weights updated: {any(weight_diff)}\")\n",
    "                self.replay_buffer.clear()\n",
    "                \n",
    "                print(f\"Loss: {train_loss.numpy():.4f}\")\n",
    "                self.metrics['train_losses'].append(train_loss.numpy())\n",
    "                self.log_train_loss(i, train_loss.numpy(), phase=1)\n",
    "                \n",
    "                print(f\"Iteration {i+1} memory: {psutil.Process().memory_info().rss / 1024**2:.2f} MB\")\n",
    "                \n",
    "                if (i + 1) % self.config['eval_interval'] == 0:\n",
    "                    random_metrics = self.evaluator.evaluate_random(\n",
    "                        self.deterministic_masked_policy,\n",
    "                        self.config['num_eval_episodes'],\n",
    "                        verbose=True\n",
    "                    )\n",
    "                    print(\"Random Opponent:\")\n",
    "                    print(f\"Avg Reward: {random_metrics[0]:.2f}\")\n",
    "                    print(f\"Win Rate: {random_metrics[1]:.2%}, Lose Rate: {random_metrics[2]:.2%}, \"\n",
    "                          f\"Tie Rate: {random_metrics[3]:.2%}, Avg Step Count: {random_metrics[4]}, \"\n",
    "                          f\"P1 Illegal Rate: {random_metrics[5]:.2%}, P2 Illegal Rate: {random_metrics[6]:.2%}\")\n",
    "\n",
    "                    self.metrics['random_avg_rewards_phase1'].append(random_metrics[0])\n",
    "                    self.metrics['random_win_rates_phase1'].append(random_metrics[1])\n",
    "                    self.metrics['random_tie_rates_phase1'].append(random_metrics[3])\n",
    "                    self.metrics['random_lose_rates_phase1'].append(random_metrics[2])\n",
    "                    self.metrics['random_avg_step_counts_phase1'].append(random_metrics[4])\n",
    "\n",
    "                    self.log_eval_metrics(i, phase=1)\n",
    "\n",
    "            self.save_policy(self.policy_v1_dir, \"Policy V1\")\n",
    "\n",
    "            # Create and initialize Policy V1 for self-play in Phase 2\n",
    "            policy_v1_actor_net = actor_distribution_network.ActorDistributionNetwork(\n",
    "                self.train_env.observation_spec(),\n",
    "                self.train_env.action_spec(),\n",
    "                preprocessing_layers={\n",
    "                    'board': tf.keras.Sequential([\n",
    "                        tf.keras.layers.Conv2D(16, 2, activation='relu', padding='same'),\n",
    "                        tf.keras.layers.Flatten()\n",
    "                    ]),\n",
    "                    'action_mask': tf.keras.layers.Dense(16, activation='relu')\n",
    "                },\n",
    "                preprocessing_combiner=tf.keras.layers.Concatenate(),\n",
    "                fc_layer_params=config['fc_layer_params']\n",
    "            )\n",
    "\n",
    "            policy_v1_actor_net.create_variables(training=False)\n",
    "            policy_v1_actor_net.set_weights(self.actor_net.get_weights())\n",
    "\n",
    "            policy_v1_base_policy = actor_policy.ActorPolicy(\n",
    "                time_step_spec=self.train_env.time_step_spec(),\n",
    "                action_spec=self.train_env.action_spec(),\n",
    "                actor_network=policy_v1_actor_net,\n",
    "                clip=True\n",
    "            )\n",
    "\n",
    "            self.policy_v1 = DeterministicMaskedPolicy(policy_v1_base_policy, policy_v1_actor_net, verbose=False)\n",
    "            self.collector.deterministic_policy = self.policy_v1\n",
    "            self.evaluator.deterministic_policy = self.policy_v1\n",
    "\n",
    "            for i in range(self.config['phase1_iterations'], self.num_iterations):\n",
    "                print(f\"Phase 2 - Iteration {i+1}/{self.num_iterations}\")\n",
    "                num_random_episodes = int(self.config['num_collect_episodes'] * self.config['random_proportion'])\n",
    "                num_selfplay_episodes = self.config['num_collect_episodes'] - num_random_episodes\n",
    "                \n",
    "                if num_random_episodes > 0:\n",
    "                    self.collector.collect_random(\n",
    "                        self.masked_policy,\n",
    "                        self.replay_buffer,\n",
    "                        num_random_episodes,\n",
    "                        verbose=False\n",
    "                    )\n",
    "\n",
    "                if num_selfplay_episodes > 0:\n",
    "                    self.collector.collect_selfplay(\n",
    "                        self.masked_policy,\n",
    "                        self.replay_buffer,\n",
    "                        num_selfplay_episodes,\n",
    "                        verbose=False\n",
    "                    )\n",
    "\n",
    "                experience = self.replay_buffer.gather_all()\n",
    "                weights_before = self.actor_net.get_weights()\n",
    "                train_loss = self.agent.train(experience).loss\n",
    "                weights_after = self.actor_net.get_weights()\n",
    "                weight_diff = [np.any(w_before != w_after) for w_before, w_after in zip(weights_before, weights_after)]\n",
    "                print(f\"Weights updated: {any(weight_diff)}\")\n",
    "                self.replay_buffer.clear()\n",
    "                \n",
    "                print(f\"Loss: {train_loss.numpy():.4f}\")\n",
    "                self.metrics['train_losses'].append(train_loss.numpy())\n",
    "                self.log_train_loss(i, train_loss.numpy(), phase=2)\n",
    "                \n",
    "                print(f\"Iteration {i+1} memory: {psutil.Process().memory_info().rss / 1024**2:.2f} MB\")\n",
    "                \n",
    "                if (i + 1) % self.config['eval_interval'] == 0:\n",
    "                    random_metrics = self.evaluator.evaluate_random(\n",
    "                        self.deterministic_masked_policy,\n",
    "                        self.config['num_eval_episodes'],\n",
    "                        verbose=True\n",
    "                    )\n",
    "                    print(\"Random Opponent:\")\n",
    "                    print(f\"Avg Reward: {random_metrics[0]:.2f}\")\n",
    "                    print(f\"Win Rate: {random_metrics[1]:.2%}, Lose Rate: {random_metrics[2]:.2%}, \"\n",
    "                          f\"Tie Rate: {random_metrics[3]:.2%}, Avg Step Count: {random_metrics[4]}, \"\n",
    "                          f\"P1 Illegal Rate: {random_metrics[5]:.2%}, P2 Illegal Rate: {random_metrics[6]:.2%}\")\n",
    "\n",
    "                    selfplay_metrics = self.evaluator.evaluate_selfplay(\n",
    "                        self.deterministic_masked_policy,\n",
    "                        self.config['num_eval_episodes'],\n",
    "                        verbose=True\n",
    "                    )\n",
    "                    print(\"Self-play (Policy V1):\")\n",
    "                    print(f\"Avg Reward: {selfplay_metrics[0]:.2f}\")\n",
    "                    print(f\"Win Rate: {selfplay_metrics[1]:.2%}, Lose Rate: {selfplay_metrics[2]:.2%}, \"\n",
    "                          f\"Tie Rate: {selfplay_metrics[3]:.2%}, Avg Step Count: {selfplay_metrics[4]}, \"\n",
    "                          f\"P1 Illegal Rate: {selfplay_metrics[5]:.2%}, P2 Illegal Rate: {selfplay_metrics[6]:.2%}\")\n",
    "\n",
    "                    self.metrics['random_avg_rewards_phase2'].append(random_metrics[0])\n",
    "                    self.metrics['random_win_rates_phase2'].append(random_metrics[1])\n",
    "                    self.metrics['random_tie_rates_phase2'].append(random_metrics[3])\n",
    "                    self.metrics['random_lose_rates_phase2'].append(random_metrics[2])\n",
    "                    self.metrics['random_avg_step_counts_phase2'].append(random_metrics[4])\n",
    "                    self.metrics['selfplay_avg_rewards_phase2'].append(selfplay_metrics[0])\n",
    "                    self.metrics['selfplay_win_rates_phase2'].append(selfplay_metrics[1])\n",
    "                    self.metrics['selfplay_tie_rates_phase2'].append(selfplay_metrics[3])\n",
    "                    self.metrics['selfplay_lose_rates_phase2'].append(selfplay_metrics[2])\n",
    "                    self.metrics['selfplay_avg_step_counts_phase2'].append(selfplay_metrics[4])\n",
    "\n",
    "                    self.log_eval_metrics(i, phase=2)\n",
    "\n",
    "            self.save_policy(self.policy_v2_dir, \"Policy V2\")\n",
    "            self.save_metrics()\n",
    "            self.train_summary_phase1.close()\n",
    "            self.train_summary_phase2.close()\n",
    "            self.trigger_system_sleep()\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nTraining interrupted. Saving policy and metrics...\")\n",
    "            self.save_metrics()\n",
    "            self.save_policy(self.policy_v1_dir, \"Policy V1\")\n",
    "            self.save_policy(self.policy_v2_dir, \"Policy V2\")\n",
    "            self.train_summary_phase1.close()\n",
    "            self.train_summary_phase2.close()\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error: {e}\")\n",
    "            self.save_metrics()\n",
    "            self.save_policy(self.policy_v1_dir, \"Policy V1\")\n",
    "            self.save_policy(self.policy_v2_dir, \"Policy V2\")\n",
    "            self.train_summary_phase1.close()\n",
    "            self.train_summary_phase2.close()\n",
    "            raise\n",
    "        finally:\n",
    "            print(\"Closing PrintLogger...\")\n",
    "            if isinstance(sys.stdout, PrintLogger):\n",
    "                sys.stdout.close()\n",
    "            if isinstance(sys.stderr, PrintLogger):\n",
    "                sys.stderr.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b769333b",
   "metadata": {},
   "source": [
    "# 3x3_No random_trained solely against random agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c53d31ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Only tf.keras.optimizers.Optimiers are well supported, got a non-TF2 optimizer: <__main__.ScheduledAdamOptimizer object at 0x29fe48f90>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PrintLogger initialized. Starting training...\n",
      "Phase 1 - Iteration 1/10\n",
      "WARNING:tensorflow:From /var/folders/zg/3l3tmlk16w55k4mhcm059hn80000gn/T/ipykernel_94060/2836184389.py:247: ReplayBuffer.gather_all (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=True)` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/folders/zg/3l3tmlk16w55k4mhcm059hn80000gn/T/ipykernel_94060/2836184389.py:247: ReplayBuffer.gather_all (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=True)` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights updated: True\n",
      "Loss: 46.2992\n",
      "Iteration 1 memory: 436.08 MB\n",
      "Phase 1 - Iteration 2/10\n",
      "Weights updated: True\n",
      "Loss: 1.3466\n",
      "Iteration 2 memory: 437.44 MB\n",
      "Phase 1 - Iteration 3/10\n",
      "Weights updated: True\n",
      "Loss: 0.6466\n",
      "Iteration 3 memory: 438.83 MB\n",
      "Phase 1 - Iteration 4/10\n",
      "Weights updated: True\n",
      "Loss: 1.7794\n",
      "Iteration 4 memory: 439.66 MB\n",
      "Phase 1 - Iteration 5/10\n",
      "Weights updated: True\n",
      "Loss: 1.2629\n",
      "Iteration 5 memory: 440.25 MB\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . O\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". . O\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . .\n",
      ". O O\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". X .\n",
      ". O O\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". X O\n",
      ". O O\n",
      "X . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X X O\n",
      ". O O\n",
      "X . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      "X X O\n",
      ". O O\n",
      "X . O\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.3000000029802323\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". O .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . X\n",
      ". O .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . X\n",
      ". O .\n",
      "X O .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . X\n",
      ". O .\n",
      "X O .\n",
      "Pattern: row_dead_2\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "X . X\n",
      ". O .\n",
      "X O O\n",
      "\n",
      "Mid. P1 reward = 0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = 0.10000000223517418\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      "X . X\n",
      "X O .\n",
      "X O O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.8500000000000001\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". . O\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X O\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . .\n",
      "O X O\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". X .\n",
      "O X O\n",
      "X . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      ". X .\n",
      "O X O\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      ". X X\n",
      "O X O\n",
      "X O .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.900000000745058\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      ". O .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X O .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . .\n",
      ". O .\n",
      "X O .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . X\n",
      ". O .\n",
      "X O .\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . X\n",
      ". O .\n",
      "X O O\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". . X\n",
      "X O .\n",
      "X O O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      "O . X\n",
      "X O .\n",
      "X O O\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.3000000029802323\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      "O . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      "O X .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      "O X .\n",
      ". . .\n",
      "X . O\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "O X .\n",
      "X . .\n",
      "X . O\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O X .\n",
      "X . .\n",
      "X O O\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      "O X .\n",
      "X X .\n",
      "X O O\n",
      "Pattern: row_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 8 - Player 2 ( O )\n",
      "O X .\n",
      "X X O\n",
      "X O O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.10000000149011612 - 0.5 * 0.1 = 0.05000000149011612\n",
      "\n",
      "Round 9 - Player 1 ( X )\n",
      "O X X\n",
      "X X O\n",
      "X O O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.6999999985098839\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      "O . .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      "O . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      "O . .\n",
      "O . .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      "O X .\n",
      "O . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      "O X .\n",
      "O . .\n",
      "X . O\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "O X .\n",
      "O X .\n",
      "X . O\n",
      "Pattern: col_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      "O X .\n",
      "O X O\n",
      "X . O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.10000000149011612 - 0.5 * 0.1 = 0.05000000149011612\n",
      "\n",
      "Round 8 - Player 1 ( X )\n",
      "O X X\n",
      "O X O\n",
      "X . O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.799999999254942\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      "O . .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". X .\n",
      "O . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". X .\n",
      "O . .\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". X .\n",
      "O X .\n",
      "X O .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      ". X .\n",
      "O X O\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      ". X X\n",
      "O X O\n",
      "X O .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.7999999992549419\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . O\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". . O\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . .\n",
      "O . O\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . .\n",
      "O X O\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . .\n",
      "O X O\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". X .\n",
      "O X O\n",
      "X O .\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      ". X .\n",
      "O X O\n",
      "X O O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 8 - Player 1 ( X )\n",
      ". X X\n",
      "O X O\n",
      "X O O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.6999999977648259\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . O\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". X O\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". X O\n",
      "O . .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". X O\n",
      "O . .\n",
      "X X .\n",
      "Pattern: row_dead_2\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O X O\n",
      "O . .\n",
      "X X .\n",
      "\n",
      "Mid. P1 reward = 0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = 0.10000000223517418\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      "O X O\n",
      "O X .\n",
      "X X .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.900000000745058\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". . O\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X O\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . .\n",
      "O X O\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". X .\n",
      "O X O\n",
      "X . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      ". X O\n",
      "O X O\n",
      "X . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      ". X O\n",
      "O X O\n",
      "X . X\n",
      "Pattern: row_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 8 - Player 2 ( O )\n",
      ". X O\n",
      "O X O\n",
      "X O X\n",
      "\n",
      "Mid. P1 reward = 0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = 0.10000000223517418\n",
      "\n",
      "Round 9 - Player 1 ( X )\n",
      "X X O\n",
      "O X O\n",
      "X O X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9500000022351741\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      "O . .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". X .\n",
      "O . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". X O\n",
      "O . .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". X O\n",
      "O . .\n",
      "X X .\n",
      "Pattern: row_dead_2\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      ". X O\n",
      "O O .\n",
      "X X .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.10000000149011612 - 0.5 * 0.1 = 0.05000000149011612\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      ". X O\n",
      "O O .\n",
      "X X X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.85\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . O\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". . O\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . .\n",
      ". O O\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". X .\n",
      ". O O\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". X .\n",
      ". O O\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". X X\n",
      ". O O\n",
      "X O .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      ". X X\n",
      "O O O\n",
      "X O .\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.2500000022351743\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "X . O\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "X . O\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . .\n",
      ". X O\n",
      "X . O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . .\n",
      "X X O\n",
      "X . O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      ". O .\n",
      "X X O\n",
      "X . O\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      ". O X\n",
      "X X O\n",
      "X . O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.85\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      "O . .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      "O . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      "O . .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      "O X .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      "O . O\n",
      "O X .\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "O X O\n",
      "O X .\n",
      "X . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      "O X O\n",
      "O X .\n",
      "X . O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 8 - Player 1 ( X )\n",
      "O X O\n",
      "O X .\n",
      "X X O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.6999999977648259\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      "O . .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      "O . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . .\n",
      "O . .\n",
      "X . O\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . .\n",
      "O X .\n",
      "X . O\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "X . O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". X O\n",
      "O X .\n",
      "X . O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      ". X O\n",
      "O X .\n",
      "X O O\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 8 - Player 1 ( X )\n",
      "X X O\n",
      "O X .\n",
      "X O O\n",
      "\n",
      "\n",
      "Round 9 - Player 2 ( O )\n",
      "X X O\n",
      "O X O\n",
      "X O O\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.15\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      ". O .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X O .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". . .\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "X O .\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". . O\n",
      "O X .\n",
      "X O X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      "O . O\n",
      "O X .\n",
      "X O X\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 8 - Player 1 ( X )\n",
      "O X O\n",
      "O X .\n",
      "X O X\n",
      "\n",
      "\n",
      "Round 9 - Player 2 ( O )\n",
      "O X O\n",
      "O X O\n",
      "X O X\n",
      "\n",
      "Tie\n",
      "P2 terminates. P1 reward = 0.0\n",
      "P1 episode reward = -0.25000000149011614\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      "O . .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". X .\n",
      "O . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". X O\n",
      "O . .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". X O\n",
      "O . .\n",
      "X X .\n",
      "Pattern: row_dead_2\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      ". X O\n",
      "O . .\n",
      "X X O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.10000000149011612 - 0.5 * 0.1 = 0.05000000149011612\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      ". X O\n",
      "O X .\n",
      "X X O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.85\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". O .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". O .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". O .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      "X O .\n",
      "X . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "X O .\n",
      "X O .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "X O .\n",
      "X O .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      ". . O\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . O\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . .\n",
      "O . .\n",
      "X . O\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . .\n",
      "O X .\n",
      "X . O\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". O .\n",
      "O X .\n",
      "X . O\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". O X\n",
      "O X .\n",
      "X . O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". O .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . X\n",
      ". O .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      "O . X\n",
      ". O .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "O X X\n",
      ". O .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O X X\n",
      ". O .\n",
      "X . O\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.2500000022351743\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      "O . .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". X .\n",
      "O . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". X .\n",
      "O . O\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". X .\n",
      "O X O\n",
      "X . .\n",
      "Pattern: col_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      ". X O\n",
      "O X O\n",
      "X . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.10000000149011612 - 0.5 * 0.1 = 0.05000000149011612\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      ". X O\n",
      "O X O\n",
      "X . X\n",
      "Pattern: row_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 8 - Player 2 ( O )\n",
      "O X O\n",
      "O X O\n",
      "X . X\n",
      "\n",
      "Mid. P1 reward = 0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = 0.10000000223517418\n",
      "\n",
      "Round 9 - Player 1 ( X )\n",
      "O X O\n",
      "O X O\n",
      "X X X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9000000014901162\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". O .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". O .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". O .\n",
      ". O .\n",
      "X . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". O X\n",
      ". O .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". O X\n",
      "O O .\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". O X\n",
      "O O .\n",
      "X X .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      ". O X\n",
      "O O O\n",
      "X X .\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.3000000029802323\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      "O . .\n",
      ". X .\n",
      "O . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      "O . .\n",
      "X X .\n",
      "O . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      "O . O\n",
      "X X .\n",
      "O . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "O . O\n",
      "X X .\n",
      "O . X\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      "O O O\n",
      "X X .\n",
      "O . X\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.2000000014901162\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . .\n",
      "O X .\n",
      "O . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . .\n",
      "O X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      "O . .\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.1500000014901162\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      "O . .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      "O . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . .\n",
      "O . O\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . .\n",
      "O X O\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . .\n",
      "O X O\n",
      "X . O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". . X\n",
      "O X O\n",
      "X . O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.7999999985098839\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . O\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". . O\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . .\n",
      "O . O\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . .\n",
      "O X O\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . .\n",
      "O X O\n",
      "X . O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". . X\n",
      "O X O\n",
      "X . O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.7999999985098839\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      ". O .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X O .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "X O O\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "X O O\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . .\n",
      "O X .\n",
      "X O O\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". . .\n",
      "O X X\n",
      "X O O\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      ". . O\n",
      "O X X\n",
      "X O O\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 8 - Player 1 ( X )\n",
      ". X O\n",
      "O X X\n",
      "X O O\n",
      "\n",
      "\n",
      "Round 9 - Player 2 ( O )\n",
      "O X O\n",
      "O X X\n",
      "X O O\n",
      "\n",
      "Tie\n",
      "P2 terminates. P1 reward = 0.0\n",
      "P1 episode reward = -0.20000000074505808\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". O .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". O .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . .\n",
      "O O .\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". X .\n",
      "O O .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". X O\n",
      "O O .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". X O\n",
      "O O .\n",
      "X X .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      "O X O\n",
      "O O .\n",
      "X X .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 8 - Player 1 ( X )\n",
      "O X O\n",
      "O O .\n",
      "X X X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.6999999977648259\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      "O . .\n",
      ". . .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      "O . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      "O . .\n",
      ". O .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      "O X .\n",
      ". O .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      "O X O\n",
      ". O .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "O X O\n",
      ". O .\n",
      "X X .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      "O X O\n",
      ". O O\n",
      "X X .\n",
      "Pattern: row_dead_2\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.20000000149011612 = -0.10000000074505806\n",
      "\n",
      "Round 8 - Player 1 ( X )\n",
      "O X O\n",
      ". O O\n",
      "X X X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.6499999970197679\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". O .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". O X\n",
      ". . .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". O X\n",
      ". . .\n",
      "X . O\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". O X\n",
      ". X .\n",
      "X . O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      ". O .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X O .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "X O O\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "X O O\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "X O O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". . O\n",
      "X X .\n",
      "X O O\n",
      "Pattern: row_dead_2\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      ". O O\n",
      "X X .\n",
      "X O O\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.10000000149011612 - 0.5 * 0.1 = 0.05000000149011612\n",
      "\n",
      "Round 8 - Player 1 ( X )\n",
      "X O O\n",
      "X X .\n",
      "X O O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.900000000745058\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". O .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". O .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". O .\n",
      ". O .\n",
      "X . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". O X\n",
      ". O .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". O X\n",
      ". O .\n",
      "X O .\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.1500000014901162\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      ". O .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X O .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . .\n",
      ". . O\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . .\n",
      ". X O\n",
      "X O .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . .\n",
      "O X O\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". X .\n",
      "O X O\n",
      "X O .\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      "O X .\n",
      "O X O\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 8 - Player 1 ( X )\n",
      "O X X\n",
      "O X O\n",
      "X O .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.7999999992549419\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      "O . .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". X .\n",
      "O . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". X .\n",
      "O . .\n",
      "X . O\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". X .\n",
      "O X .\n",
      "X . O\n",
      "Pattern: col_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      ". X O\n",
      "O X .\n",
      "X . O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.10000000149011612 - 0.5 * 0.1 = 0.05000000149011612\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      ". X O\n",
      "O X .\n",
      "X X O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.85\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . O\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". . O\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      "O . .\n",
      ". . O\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      "O . .\n",
      ". X O\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      "O O .\n",
      ". X O\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "O O .\n",
      "X X O\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      "O O .\n",
      "X X O\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 8 - Player 1 ( X )\n",
      "O O X\n",
      "X X O\n",
      "X O .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.7499999985098839\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". O .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . X\n",
      ". O .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . X\n",
      ". O O\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". X X\n",
      ". O O\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      ". X X\n",
      ". O O\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      ". X X\n",
      "X O O\n",
      "X O .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 8 - Player 2 ( O )\n",
      ". X X\n",
      "X O O\n",
      "X O O\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 9 - Player 1 ( X )\n",
      "X X X\n",
      "X O O\n",
      "X O O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.6999999985098839\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . O\n",
      ". . .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . O\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". O O\n",
      ". . .\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". O O\n",
      "X . .\n",
      "X . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". O O\n",
      "X . O\n",
      "X . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". O O\n",
      "X X O\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      ". O O\n",
      "X X O\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 8 - Player 1 ( X )\n",
      ". O O\n",
      "X X O\n",
      "X O X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 9 - Player 2 ( O )\n",
      "O O O\n",
      "X X O\n",
      "X O X\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.300000002235174\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . O\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". X O\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". X O\n",
      ". O .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". X O\n",
      ". O .\n",
      "X X .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      ". X O\n",
      "O O .\n",
      "X X .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      ". X O\n",
      "O O .\n",
      "X X X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.7499999985098839\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". O .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". O .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". O .\n",
      ". O .\n",
      "X . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". O X\n",
      ". O .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". O X\n",
      ". O O\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X O X\n",
      ". O O\n",
      "X . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      "X O X\n",
      ". O O\n",
      "X O .\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.3000000029802323\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . O\n",
      ". . .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . O\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". O O\n",
      ". . .\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". O O\n",
      "X . .\n",
      "X . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". O O\n",
      "X O .\n",
      "X . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". O O\n",
      "X O .\n",
      "X X .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      ". O O\n",
      "X O .\n",
      "X X O\n",
      "Pattern: col_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.20000000149011612 = -0.10000000074505806\n",
      "\n",
      "Round 8 - Player 1 ( X )\n",
      "X O O\n",
      "X O .\n",
      "X X O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.6999999977648259\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      ". . O\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . O\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". O .\n",
      ". . .\n",
      "X . O\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". O .\n",
      "X . .\n",
      "X . O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". O .\n",
      "X O .\n",
      "X . O\n",
      "Pattern: col_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.20000000149011612 = -0.10000000074505806\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". O X\n",
      "X O .\n",
      "X . O\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      ". O X\n",
      "X O .\n",
      "X O O\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.2000000014901162\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      ". . O\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . O\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      "O . .\n",
      ". . .\n",
      "X . O\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      "O . .\n",
      "X . .\n",
      "X . O\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      "O . .\n",
      "X . .\n",
      "X O O\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "O . .\n",
      "X X .\n",
      "X O O\n",
      "Pattern: row_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      "O . .\n",
      "X X O\n",
      "X O O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.10000000149011612 - 0.5 * 0.1 = 0.05000000149011612\n",
      "\n",
      "Round 8 - Player 1 ( X )\n",
      "O X .\n",
      "X X O\n",
      "X O O\n",
      "\n",
      "\n",
      "Round 9 - Player 2 ( O )\n",
      "O X O\n",
      "X X O\n",
      "X O O\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.200000000745058\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      ". . O\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . O\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". . .\n",
      "X . O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "X . O\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "X . O\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". X O\n",
      "O X .\n",
      "X . O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      ". X O\n",
      "O X .\n",
      "X O O\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 8 - Player 1 ( X )\n",
      "X X O\n",
      "O X .\n",
      "X O O\n",
      "\n",
      "\n",
      "Round 9 - Player 2 ( O )\n",
      "X X O\n",
      "O X O\n",
      "X O O\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.250000001490116\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      ". . O\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . O\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      "O . .\n",
      ". . .\n",
      "X . O\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      "O . .\n",
      "X . .\n",
      "X . O\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      "O . .\n",
      "X O .\n",
      "X . O\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.1500000014901162\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". . O\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X O\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . .\n",
      ". X O\n",
      "X . O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . .\n",
      "X X O\n",
      "X . O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      ". O .\n",
      "X X O\n",
      "X . O\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      ". O X\n",
      "X X O\n",
      "X . O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.85\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . .\n",
      ". X O\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . .\n",
      "X X O\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . .\n",
      "X X O\n",
      "O . O\n",
      "Pattern: row_dead_2\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.20000000149011612 = -0.20000000223517417\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". . X\n",
      "X X O\n",
      "O . O\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      ". . X\n",
      "X X O\n",
      "O O O\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.3000000029802323\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "X O .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". O .\n",
      ". X .\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". O .\n",
      ". X .\n",
      "X O X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O O .\n",
      ". X .\n",
      "X O X\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      "O O X\n",
      ". X .\n",
      "X O X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.85\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". . O\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X O\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      ". X O\n",
      "X . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . O\n",
      "X X O\n",
      "X . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      ". O O\n",
      "X X O\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      ". O O\n",
      "X X O\n",
      "X . X\n",
      "Pattern: row_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 8 - Player 2 ( O )\n",
      "O O O\n",
      "X X O\n",
      "X . X\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.200000000745058\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "X . O\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "X . O\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . .\n",
      ". X O\n",
      "X . O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . .\n",
      "X X O\n",
      "X . O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      ". . .\n",
      "X X O\n",
      "X O O\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      ". X .\n",
      "X X O\n",
      "X O O\n",
      "\n",
      "\n",
      "Round 8 - Player 2 ( O )\n",
      ". X O\n",
      "X X O\n",
      "X O O\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.15\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". O .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". O X\n",
      ". . .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". O X\n",
      ". . O\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". O X\n",
      ". X O\n",
      "X . .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "Random Opponent:\n",
      "Avg Reward: 0.04\n",
      "Win Rate: 60.00%, Lose Rate: 36.00%, Tie Rate: 4.00%, Avg Step Count: 7.32, P1 Illegal Rate: 0.00%, P2 Illegal Rate: 0.00%\n",
      "Phase 1 - Iteration 6/10\n",
      "Weights updated: True\n",
      "Loss: 1.1623\n",
      "Iteration 6 memory: 441.66 MB\n",
      "Phase 1 - Iteration 7/10\n",
      "Weights updated: True\n",
      "Loss: 1.0102\n",
      "Iteration 7 memory: 442.31 MB\n",
      "Phase 1 - Iteration 8/10\n",
      "Weights updated: True\n",
      "Loss: 1.3204\n",
      "Iteration 8 memory: 442.78 MB\n",
      "Phase 1 - Iteration 9/10\n",
      "Weights updated: True\n",
      "Loss: 0.9641\n",
      "Iteration 9 memory: 443.44 MB\n",
      "Phase 1 - Iteration 10/10\n",
      "Weights updated: True\n",
      "Loss: 1.1158\n",
      "Iteration 10 memory: 444.34 MB\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "X O .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      "O . .\n",
      ". X .\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "O . X\n",
      ". X .\n",
      "X O .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "X . O\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "X . O\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . .\n",
      "O X .\n",
      "X . O\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      "O X .\n",
      "X . O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      ". . O\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . O\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "X O O\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "X O O\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". O .\n",
      ". X .\n",
      "X O O\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". O X\n",
      ". X .\n",
      "X O O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . O\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". . O\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . .\n",
      ". O O\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . X\n",
      ". O O\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". O X\n",
      ". O O\n",
      "X . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X O X\n",
      ". O O\n",
      "X . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      "X O X\n",
      ". O O\n",
      "X O .\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.3000000029802323\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". O .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". O X\n",
      ". . .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      "O O X\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "O O X\n",
      ". X .\n",
      "X . .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". O O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". O O\n",
      "X X .\n",
      "O . X\n",
      "Pattern: row_dead_2\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      ". O O\n",
      "X X .\n",
      "O O X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 8 - Player 1 ( X )\n",
      "X O O\n",
      "X X .\n",
      "O O X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.85\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". O .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . X\n",
      ". O .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      "O . X\n",
      ". O .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "O . X\n",
      "X O .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O O X\n",
      "X O .\n",
      "X . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      "O O X\n",
      "X O .\n",
      "X . X\n",
      "Pattern: row_dead_2\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 8 - Player 2 ( O )\n",
      "O O X\n",
      "X O O\n",
      "X . X\n",
      "\n",
      "Mid. P1 reward = 0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = 0.10000000223517418\n",
      "\n",
      "Round 9 - Player 1 ( X )\n",
      "O O X\n",
      "X O O\n",
      "X X X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.6999999985098839\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". O .\n",
      ". . .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". O .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". O .\n",
      "O . .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". O .\n",
      "O X .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". O .\n",
      "O X .\n",
      "X . O\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". O X\n",
      "O X .\n",
      "X . O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". O .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". O .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      "O . .\n",
      ". O .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      "O . X\n",
      ". O .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      "O . X\n",
      "O O .\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "O X X\n",
      "O O .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      "O X X\n",
      "O O O\n",
      "X . .\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.3000000029802323\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      "O . .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      "O . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      "O . .\n",
      "O . .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      "O . .\n",
      "O X .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      "O . .\n",
      "O X .\n",
      "X . O\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "O . X\n",
      "O X .\n",
      "X . O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". O .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". O X\n",
      ". . .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      "O O X\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "O O X\n",
      ". X .\n",
      "X . .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "X O .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . .\n",
      ". X O\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      ". X O\n",
      "X O .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      ". O .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X O .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". O .\n",
      ". . .\n",
      "X O .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". O X\n",
      ". . .\n",
      "X O .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". O X\n",
      ". . O\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". O X\n",
      ". X O\n",
      "X O .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". O .\n",
      ". . .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". O .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". O .\n",
      ". . O\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". O .\n",
      ". X O\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". O .\n",
      ". X O\n",
      "X . O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". O X\n",
      ". X O\n",
      "X . O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". O .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". O X\n",
      ". . .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". O X\n",
      ". . .\n",
      "X . O\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". O X\n",
      ". X .\n",
      "X . O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      "O . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      "O . .\n",
      ". X .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      "O . O\n",
      ". X .\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "O . O\n",
      ". X .\n",
      "X . X\n",
      "Pattern: row_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O O O\n",
      ". X .\n",
      "X . X\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.1500000007450581\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      ". . O\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . O\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . .\n",
      ". . O\n",
      "X . O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . .\n",
      ". X O\n",
      "X . O\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". O .\n",
      ". X O\n",
      "X . O\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". O X\n",
      ". X O\n",
      "X . O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". O .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". O X\n",
      ". . .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      "O O X\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "O O X\n",
      ". X .\n",
      "X . .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". O .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". O .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . .\n",
      "O O .\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . X\n",
      "O O .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . X\n",
      "O O O\n",
      "X . .\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.1500000014901162\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". O .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". O X\n",
      ". . .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". O X\n",
      "O . .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". O X\n",
      "O X .\n",
      "X . .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "X . O\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "X . O\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "X . O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . O\n",
      "X X .\n",
      "X . O\n",
      "Pattern: row_dead_2\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      ". . O\n",
      "X X O\n",
      "X . O\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.1500000007450581\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "X . O\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "X . O\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . .\n",
      "O X .\n",
      "X . O\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      "O X .\n",
      "X . O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "X O .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      "O . .\n",
      ". X .\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "O . X\n",
      ". X .\n",
      "X O .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      "O . .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      "O X .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . .\n",
      "O X O\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      "O X O\n",
      "X . .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . O\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". . O\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . .\n",
      ". . O\n",
      "X . O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . .\n",
      ". X O\n",
      "X . O\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      ". X O\n",
      "X . O\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.1500000014901162\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      ". . O\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . O\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". . .\n",
      "X . O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "X . O\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      ". X O\n",
      "X . O\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.1500000014901162\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". O .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . X\n",
      ". O .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . X\n",
      "O O .\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". X X\n",
      "O O .\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      ". X X\n",
      "O O .\n",
      "X . O\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      "X X X\n",
      "O O .\n",
      "X . O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.6999999977648259\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". . O\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X O\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". O .\n",
      ". X O\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". O X\n",
      ". X O\n",
      "X . .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". O .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". O X\n",
      ". . .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". O X\n",
      ". . .\n",
      "X . O\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". O X\n",
      ". X .\n",
      "X . O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      "O . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      "O . .\n",
      ". X .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      "O . .\n",
      ". X .\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "O . X\n",
      ". X .\n",
      "X O .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      ". . O\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . O\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . .\n",
      "O . .\n",
      "X . O\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . .\n",
      "O X .\n",
      "X . O\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . .\n",
      "O X .\n",
      "X O O\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". . X\n",
      "O X .\n",
      "X O O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      "O . .\n",
      ". . .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      "O . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      "O O .\n",
      ". . .\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      "O O .\n",
      ". X .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      "O O .\n",
      "O X .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "O O .\n",
      "O X .\n",
      "X . X\n",
      "Pattern: row_dead_2\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      "O O O\n",
      "O X .\n",
      "X . X\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.1500000007450581\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . O\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". . O\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . .\n",
      ". . O\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . .\n",
      ". X O\n",
      "X O .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . .\n",
      "O X O\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". . X\n",
      "O X O\n",
      "X O .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". O .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". O X\n",
      ". . .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". O X\n",
      ". O .\n",
      "X . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X O X\n",
      ". O .\n",
      "X . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "X O X\n",
      ". O O\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      "X O X\n",
      "X O O\n",
      "X . .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.7999999992549419\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "X . O\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "X . O\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "X . O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . O\n",
      "X X .\n",
      "X . O\n",
      "Pattern: row_dead_2\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      ". . O\n",
      "X X O\n",
      "X . O\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.1500000007450581\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". O .\n",
      ". . .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". O .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". O .\n",
      ". O .\n",
      "X . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". O X\n",
      ". O .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". O X\n",
      ". O .\n",
      "X O .\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.1500000014901162\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      "O . .\n",
      ". . .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      "O . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      "O . .\n",
      ". . O\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      "O . .\n",
      ". X O\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      "O . .\n",
      ". X O\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "O . X\n",
      ". X O\n",
      "X O .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". O .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". O .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . .\n",
      ". O O\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . X\n",
      ". O O\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      "O . X\n",
      ". O O\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "O X X\n",
      ". O O\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      "O X X\n",
      ". O O\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 8 - Player 1 ( X )\n",
      "O X X\n",
      "X O O\n",
      "X O .\n",
      "\n",
      "\n",
      "Round 9 - Player 2 ( O )\n",
      "O X X\n",
      "X O O\n",
      "X O O\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.4000000037252902\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". O .\n",
      ". . .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". O .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". O .\n",
      ". . O\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". O .\n",
      ". X O\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". O .\n",
      "O X O\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". O X\n",
      "O X O\n",
      "X . .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      "O . .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      "O X .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . .\n",
      "O X O\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      "O X O\n",
      "X . .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . O\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". O O\n",
      ". X .\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". O O\n",
      ". X .\n",
      "X . X\n",
      "Pattern: row_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      ". O O\n",
      ". X .\n",
      "X O X\n",
      "\n",
      "Mid. P1 reward = 0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = 0.10000000223517418\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      "X O O\n",
      ". X .\n",
      "X O X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.8500000000000001\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "X . O\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "X . O\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "X O O\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      ". X .\n",
      "X O O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "X O .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . .\n",
      ". X O\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      ". X O\n",
      "X O .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      "O . .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      "O X .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". O .\n",
      "O X .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". O .\n",
      "O X .\n",
      "X . X\n",
      "Pattern: row_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      ". O .\n",
      "O X O\n",
      "X . X\n",
      "\n",
      "Mid. P1 reward = 0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = 0.10000000223517418\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      ". O X\n",
      "O X O\n",
      "X . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 1.0000000022351743\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      "O . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      "O . .\n",
      ". X .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      "O . O\n",
      ". X .\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "O . O\n",
      ". X .\n",
      "X . X\n",
      "Pattern: row_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O O O\n",
      ". X .\n",
      "X . X\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.1500000007450581\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      "O . .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      "O X .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . .\n",
      "O X O\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      "O X O\n",
      "X . .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". . .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      "O . .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      "O X .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". O .\n",
      "O X .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". O .\n",
      "O X .\n",
      "X . X\n",
      "Pattern: row_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O O .\n",
      "O X .\n",
      "X . X\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.10000000149011612 - 0.5 * 0.1 = 0.05000000149011612\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      "O O X\n",
      "O X .\n",
      "X . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9500000014901161\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . O\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". . O\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . .\n",
      ". . O\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . .\n",
      ". X O\n",
      "X O .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . .\n",
      "O X O\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". . X\n",
      "O X O\n",
      "X O .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". O .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". O .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      "O . .\n",
      ". O .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      "O . X\n",
      ". O .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      "O . X\n",
      ". O O\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "O X X\n",
      ". O O\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      "O X X\n",
      ". O O\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 8 - Player 1 ( X )\n",
      "O X X\n",
      "X O O\n",
      "X O .\n",
      "\n",
      "\n",
      "Round 9 - Player 2 ( O )\n",
      "O X X\n",
      "X O O\n",
      "X O O\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.4000000037252902\n",
      "Random Opponent:\n",
      "Avg Reward: 0.34\n",
      "Win Rate: 74.00%, Lose Rate: 26.00%, Tie Rate: 0.00%, Avg Step Count: 5.94, P1 Illegal Rate: 0.00%, P2 Illegal Rate: 0.00%\n",
      "INFO:tensorflow:Assets written to: logs/test_3x3_no_random/PPO trained against random policy_20250512_180146/policy_v1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: logs/test_3x3_no_random/PPO trained against random policy_20250512_180146/policy_v1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy V1 saved to logs/test_3x3_no_random/PPO trained against random policy_20250512_180146/policy_v1\n",
      "Phase 2 - Iteration 11/20\n",
      "Weights updated: True\n",
      "Loss: 1.2822\n",
      "Iteration 11 memory: 460.92 MB\n",
      "Phase 2 - Iteration 12/20\n",
      "Weights updated: True\n",
      "Loss: 1.0064\n",
      "Iteration 12 memory: 461.72 MB\n",
      "Phase 2 - Iteration 13/20\n",
      "Weights updated: True\n",
      "Loss: 1.5719\n",
      "Iteration 13 memory: 462.27 MB\n",
      "Phase 2 - Iteration 14/20\n",
      "Weights updated: True\n",
      "Loss: 0.8784\n",
      "Iteration 14 memory: 462.75 MB\n",
      "Phase 2 - Iteration 15/20\n",
      "Weights updated: True\n",
      "Loss: 1.3771\n",
      "Iteration 15 memory: 463.27 MB\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      ". . O\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "X . O\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "X O O\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      ". X .\n",
      "X O O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      "O . O\n",
      ". X .\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "O . O\n",
      ". X .\n",
      "X . X\n",
      "Pattern: row_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O . O\n",
      ". X .\n",
      "X O X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      "O X O\n",
      ". X .\n",
      "X O X\n",
      "\n",
      "\n",
      "Round 8 - Player 2 ( O )\n",
      "O X O\n",
      "O X .\n",
      "X O X\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 9 - Player 1 ( X )\n",
      "O X O\n",
      "O X X\n",
      "X O X\n",
      "\n",
      "Tie\n",
      "P1 terminates. P1 reward = 0.0\n",
      "P1 episode reward = -0.35000000223517413\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . O\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X O\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . .\n",
      ". X O\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . X\n",
      ". X O\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      "O . X\n",
      ". X O\n",
      "O . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "O X X\n",
      ". X O\n",
      "O . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      "O X X\n",
      "O X O\n",
      "O . .\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.2500000022351743\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". O O\n",
      ". X .\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X O O\n",
      ". X .\n",
      "X . .\n",
      "Pattern: col_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "X O O\n",
      ". X O\n",
      "X . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.10000000149011612 - 0.5 * 0.1 = 0.05000000149011612\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      "X O O\n",
      ". X O\n",
      "X . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.799999999254942\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . .\n",
      ". X O\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . X\n",
      ". X O\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      "O . X\n",
      ". X O\n",
      "O . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "O X X\n",
      ". X O\n",
      "O . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      "O X X\n",
      "O X O\n",
      "O . .\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.2500000022351743\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      "O . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      "O . .\n",
      ". X .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      "O . .\n",
      ". X .\n",
      "X . O\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "O . X\n",
      ". X .\n",
      "X . O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      "O . .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      "O X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". O .\n",
      "O X .\n",
      ". . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". O .\n",
      "O X .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". O .\n",
      "O X .\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". O X\n",
      "O X .\n",
      "X O .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      "O . .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      "O X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      ". . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      "O X .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "X . O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "X . O\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      "X O O\n",
      "O X .\n",
      "X . O\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 8 - Player 1 ( X )\n",
      "X O O\n",
      "O X X\n",
      "X . O\n",
      "\n",
      "\n",
      "Round 9 - Player 2 ( O )\n",
      "X O O\n",
      "O X X\n",
      "X O O\n",
      "\n",
      "Tie\n",
      "P2 terminates. P1 reward = 0.0\n",
      "P1 episode reward = -0.3500000029802322\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . O\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X O\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . .\n",
      ". X O\n",
      ". . O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . .\n",
      ". X O\n",
      "X . O\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". O .\n",
      ". X O\n",
      "X . O\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". O X\n",
      ". X O\n",
      "X . O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . O\n",
      ". . .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". O O\n",
      ". X .\n",
      ". . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". O O\n",
      ". X .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      "O O O\n",
      ". X .\n",
      "X . .\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.1500000014901162\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      "O . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      "O . .\n",
      ". X .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      "O . O\n",
      ". X .\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "O . O\n",
      ". X .\n",
      "X . X\n",
      "Pattern: row_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O O O\n",
      ". X .\n",
      "X . X\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.1500000007450581\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      ". . O\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "X . O\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "X . O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . O\n",
      ". X .\n",
      "X . O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "X . O\n",
      ". X .\n",
      "X O O\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      "X X O\n",
      ". X .\n",
      "X O O\n",
      "\n",
      "\n",
      "Round 8 - Player 2 ( O )\n",
      "X X O\n",
      "O X .\n",
      "X O O\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 9 - Player 1 ( X )\n",
      "X X O\n",
      "O X X\n",
      "X O O\n",
      "\n",
      "Tie\n",
      "P1 terminates. P1 reward = 0.0\n",
      "P1 episode reward = -0.25000000074505807\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      ". . O\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "X . O\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "X . O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . O\n",
      ". X .\n",
      "X . O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "X . O\n",
      ". X .\n",
      "X O O\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      "X X O\n",
      ". X .\n",
      "X O O\n",
      "\n",
      "\n",
      "Round 8 - Player 2 ( O )\n",
      "X X O\n",
      "O X .\n",
      "X O O\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 9 - Player 1 ( X )\n",
      "X X O\n",
      "O X X\n",
      "X O O\n",
      "\n",
      "Tie\n",
      "P1 terminates. P1 reward = 0.0\n",
      "P1 episode reward = -0.25000000074505807\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      "O X .\n",
      ". . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      "O X .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      "O . .\n",
      "O X .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "O . .\n",
      "O X .\n",
      "X . X\n",
      "Pattern: row_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O O .\n",
      "O X .\n",
      "X . X\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      "O O X\n",
      "O X .\n",
      "X . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.85\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      ". O .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "X O .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . .\n",
      ". X O\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      ". X O\n",
      "X O .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O O .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . X\n",
      ". X .\n",
      "O O .\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . X\n",
      "O X .\n",
      "O O .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . X\n",
      "O X .\n",
      "O O .\n",
      "Pattern: row_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      "X . X\n",
      "O X .\n",
      "O O O\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.3000000029802323\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". O .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . X\n",
      ". O .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". O X\n",
      ". O .\n",
      ". . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". O X\n",
      ". O .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". O X\n",
      "O O .\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X O X\n",
      "O O .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      "X O X\n",
      "O O .\n",
      "X . O\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 8 - Player 1 ( X )\n",
      "X O X\n",
      "O O X\n",
      "X . O\n",
      "\n",
      "\n",
      "Round 9 - Player 2 ( O )\n",
      "X O X\n",
      "O O X\n",
      "X O O\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.4000000037252902\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . .\n",
      "O X .\n",
      "O . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . .\n",
      "O X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". O .\n",
      ". . .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". O .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      "O O .\n",
      ". X .\n",
      ". . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      "O O .\n",
      ". X .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      "O O .\n",
      ". X O\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "O O X\n",
      ". X O\n",
      "X . .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      "O X .\n",
      ". . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      "O X .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "X . O\n",
      "O X .\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "X O X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.900000000745058\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      "O . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      "O . .\n",
      ". X .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      "O . .\n",
      ". X .\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "O . X\n",
      ". X .\n",
      "X O .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". O .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". O .\n",
      ". X .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". O .\n",
      "O X .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". O X\n",
      "O X .\n",
      "X . .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      "O . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      "O . .\n",
      ". X .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      "O . .\n",
      ". X .\n",
      "X . O\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "O . X\n",
      ". X .\n",
      "X . O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      ". . O\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "X . O\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "X O O\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      ". X .\n",
      "X O O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      "O X .\n",
      ". . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      "O X .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . .\n",
      "O X .\n",
      "X . O\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      "O X .\n",
      "X . O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". O .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . X\n",
      ". O .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . X\n",
      ". O .\n",
      ". . O\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . X\n",
      ". O .\n",
      "X . O\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". O X\n",
      ". O .\n",
      "X . O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X O X\n",
      ". O .\n",
      "X . O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      "X O X\n",
      ". O .\n",
      "X O O\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.3000000029802323\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      ". . O\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "X . O\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . .\n",
      "O X .\n",
      "X . O\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      "O X .\n",
      "X . O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". O .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . X\n",
      ". O .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". O X\n",
      ". O .\n",
      ". . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". O X\n",
      ". O .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". O X\n",
      ". O O\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X O X\n",
      ". O O\n",
      "X . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      "X O X\n",
      "O O O\n",
      "X . .\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.3000000029802323\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . X\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . X\n",
      ". X .\n",
      "O O .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . X\n",
      ". X .\n",
      "O O .\n",
      "Pattern: row_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "X . X\n",
      ". X .\n",
      "O O O\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.2500000022351743\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "X . O\n",
      "O X .\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "X O X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.7999999992549419\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . O\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X O\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . .\n",
      "O X O\n",
      ". . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . .\n",
      "O X O\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      "O . .\n",
      "O X O\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "O . X\n",
      "O X O\n",
      "X . .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "X . O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . O\n",
      ". X .\n",
      "X . O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "X . O\n",
      ". X .\n",
      "X O O\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      "X X O\n",
      ". X .\n",
      "X O O\n",
      "\n",
      "\n",
      "Round 8 - Player 2 ( O )\n",
      "X X O\n",
      "O X .\n",
      "X O O\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 9 - Player 1 ( X )\n",
      "X X O\n",
      "O X X\n",
      "X O O\n",
      "\n",
      "Tie\n",
      "P1 terminates. P1 reward = 0.0\n",
      "P1 episode reward = -0.35000000223517413\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      "O . .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      "O X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      "O . .\n",
      "O X .\n",
      ". . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      "O . .\n",
      "O X .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      "O . O\n",
      "O X .\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "O . O\n",
      "O X .\n",
      "X . X\n",
      "Pattern: row_dead_2\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      "O . O\n",
      "O X .\n",
      "X O X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 8 - Player 1 ( X )\n",
      "O X O\n",
      "O X .\n",
      "X O X\n",
      "\n",
      "\n",
      "Round 9 - Player 2 ( O )\n",
      "O X O\n",
      "O X O\n",
      "X O X\n",
      "\n",
      "Tie\n",
      "P2 terminates. P1 reward = 0.0\n",
      "P1 episode reward = -0.20000000074505803\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      "O . .\n",
      ". . .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      "O . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      "O . .\n",
      ". X .\n",
      ". O .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      "O . .\n",
      ". X .\n",
      "X O .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      "O . .\n",
      ". X O\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "O . X\n",
      ". X O\n",
      "X O .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      ". . O\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "X . O\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      "O . .\n",
      ". X .\n",
      "X . O\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "O . X\n",
      ". X .\n",
      "X . O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X O\n",
      ". . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X O\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". O .\n",
      ". X O\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". O X\n",
      ". X O\n",
      "X . .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . X\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . X\n",
      "O X .\n",
      "O . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      ". . X\n",
      "O X .\n",
      "O O X\n",
      "\n",
      "Mid. P1 reward = 0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = 0.10000000223517418\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      "X . X\n",
      "O X .\n",
      "O O X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.8500000000000001\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . X\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . X\n",
      ". X .\n",
      "O . O\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . X\n",
      ". X .\n",
      "O . O\n",
      "Pattern: row_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "X . X\n",
      "O X .\n",
      "O . O\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      "X X X\n",
      "O X .\n",
      "O . O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.749999998509884\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . O\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X O\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      "O . .\n",
      ". X O\n",
      ". . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      "O . .\n",
      ". X O\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      "O O .\n",
      ". X O\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "O O X\n",
      ". X O\n",
      "X . .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      "O X .\n",
      ". . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      "O X .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . .\n",
      "O X .\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      "O X .\n",
      "X O .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      ". O .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "X O .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      "O . .\n",
      ". X .\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "O . X\n",
      ". X .\n",
      "X O .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      "O . .\n",
      ". . .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      "O . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      "O O .\n",
      ". X .\n",
      ". . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      "O O .\n",
      ". X .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      "O O .\n",
      ". X O\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "O O X\n",
      ". X O\n",
      "X . .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". O .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". O .\n",
      ". X .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". O O\n",
      ". X .\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X O O\n",
      ". X .\n",
      "X . .\n",
      "Pattern: col_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "X O O\n",
      "O X .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = 0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = 0.10000000223517418\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      "X O O\n",
      "O X .\n",
      "X . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9500000014901161\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . O\n",
      ". . .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". O .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . X\n",
      ". O .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . X\n",
      ". O .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      "X . X\n",
      ". O .\n",
      "O . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      "X . X\n",
      ". O .\n",
      "O . O\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . X\n",
      ". O X\n",
      "O . O\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      "X O X\n",
      ". O X\n",
      "O . O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 8 - Player 1 ( X )\n",
      "X O X\n",
      "X O X\n",
      "O . O\n",
      "\n",
      "\n",
      "Round 9 - Player 2 ( O )\n",
      "X O X\n",
      "X O X\n",
      "O O O\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.300000002235174\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      "O X .\n",
      ". . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      "O X .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "X . O\n",
      "O X .\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "X O X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.900000000745058\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . X\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      "O . X\n",
      ". X .\n",
      "O . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "O . X\n",
      ". X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O O X\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      "O O X\n",
      ". X X\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.749999998509884\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      ". . O\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . O\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . .\n",
      "O X .\n",
      ". . O\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . .\n",
      "O X .\n",
      "X . O\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      "O . .\n",
      "O X .\n",
      "X . O\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "O . X\n",
      "O X .\n",
      "X . O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      ". O .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "X O .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "X O O\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      ". X .\n",
      "X O O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "Random Opponent:\n",
      "Avg Reward: 0.31\n",
      "Win Rate: 68.00%, Lose Rate: 20.00%, Tie Rate: 12.00%, Avg Step Count: 6.46, P1 Illegal Rate: 0.00%, P2 Illegal Rate: 0.00%\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . X\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . X\n",
      "O X .\n",
      "O . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O . X\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.2500000022351743\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . X\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . X\n",
      "O X .\n",
      "O . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O . X\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.2500000022351743\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . X\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . X\n",
      "O X .\n",
      "O . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O . X\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.2500000022351743\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . X\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . X\n",
      "O X .\n",
      "O . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O . X\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.2500000022351743\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . X\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . X\n",
      "O X .\n",
      "O . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O . X\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.2500000022351743\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . X\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . X\n",
      "O X .\n",
      "O . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O . X\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.2500000022351743\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . X\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . X\n",
      "O X .\n",
      "O . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O . X\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.2500000022351743\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . X\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . X\n",
      "O X .\n",
      "O . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O . X\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.2500000022351743\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . X\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . X\n",
      "O X .\n",
      "O . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O . X\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.2500000022351743\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . X\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . X\n",
      "O X .\n",
      "O . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O . X\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.2500000022351743\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . X\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . X\n",
      "O X .\n",
      "O . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O . X\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.2500000022351743\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . X\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . X\n",
      "O X .\n",
      "O . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O . X\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.2500000022351743\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . X\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . X\n",
      "O X .\n",
      "O . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O . X\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.2500000022351743\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . X\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . X\n",
      "O X .\n",
      "O . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O . X\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.2500000022351743\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . X\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . X\n",
      "O X .\n",
      "O . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O . X\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.2500000022351743\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . X\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . X\n",
      "O X .\n",
      "O . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O . X\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.2500000022351743\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . X\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . X\n",
      "O X .\n",
      "O . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O . X\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.2500000022351743\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . X\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . X\n",
      "O X .\n",
      "O . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O . X\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.2500000022351743\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . X\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . X\n",
      "O X .\n",
      "O . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O . X\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.2500000022351743\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . X\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . X\n",
      "O X .\n",
      "O . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O . X\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.2500000022351743\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . X\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . X\n",
      "O X .\n",
      "O . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O . X\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.2500000022351743\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . X\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . X\n",
      "O X .\n",
      "O . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O . X\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.2500000022351743\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . X\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . X\n",
      "O X .\n",
      "O . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O . X\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.2500000022351743\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . X\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . X\n",
      "O X .\n",
      "O . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O . X\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.2500000022351743\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . X\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . X\n",
      "O X .\n",
      "O . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O . X\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.2500000022351743\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . X\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . X\n",
      "O X .\n",
      "O . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O . X\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.2500000022351743\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "Self-play (Policy V1):\n",
      "Avg Reward: -0.24\n",
      "Win Rate: 48.00%, Lose Rate: 52.00%, Tie Rate: 0.00%, Avg Step Count: 6.0, P1 Illegal Rate: 0.00%, P2 Illegal Rate: 0.00%\n",
      "Phase 2 - Iteration 16/20\n",
      "Weights updated: True\n",
      "Loss: 0.4639\n",
      "Iteration 16 memory: 465.86 MB\n",
      "Phase 2 - Iteration 17/20\n",
      "Weights updated: True\n",
      "Loss: 1.0099\n",
      "Iteration 17 memory: 466.75 MB\n",
      "Phase 2 - Iteration 18/20\n",
      "Weights updated: True\n",
      "Loss: 1.1752\n",
      "Iteration 18 memory: 467.25 MB\n",
      "Phase 2 - Iteration 19/20\n",
      "Weights updated: True\n",
      "Loss: 0.8091\n",
      "Iteration 19 memory: 467.75 MB\n",
      "Phase 2 - Iteration 20/20\n",
      "Weights updated: True\n",
      "Loss: 0.9937\n",
      "Iteration 20 memory: 468.30 MB\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "X . O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . O\n",
      ". X .\n",
      "X . O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "X . O\n",
      "O X .\n",
      "X . O\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      "X . O\n",
      "O X X\n",
      "X . O\n",
      "\n",
      "\n",
      "Round 8 - Player 2 ( O )\n",
      "X . O\n",
      "O X X\n",
      "X O O\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 9 - Player 1 ( X )\n",
      "X X O\n",
      "O X X\n",
      "X O O\n",
      "\n",
      "Tie\n",
      "P1 terminates. P1 reward = 0.0\n",
      "P1 episode reward = -0.35000000223517413\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . O\n",
      ". . .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      ". . O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "X . O\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "X O O\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      ". X .\n",
      "X O O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      "X . O\n",
      ". X O\n",
      "X O O\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.2500000022351743\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      "O X .\n",
      ". . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      "O X .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . .\n",
      "O X .\n",
      "X . O\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      "O X .\n",
      "X . O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". O .\n",
      ". . .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". O .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      "O O .\n",
      ". X .\n",
      ". . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      "O O .\n",
      ". X .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      "O O .\n",
      ". X .\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "O O .\n",
      ". X .\n",
      "X O X\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      "O O .\n",
      ". X O\n",
      "X O X\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 8 - Player 1 ( X )\n",
      "O O X\n",
      ". X O\n",
      "X O X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.749999998509884\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". O .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". O .\n",
      ". X .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      "O O .\n",
      ". X .\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "O O X\n",
      ". X .\n",
      "X . .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". O .\n",
      ". . .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". O .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". O O\n",
      ". X .\n",
      ". . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". O O\n",
      ". X .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". O O\n",
      "O X .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". O O\n",
      "O X .\n",
      "X . X\n",
      "Pattern: row_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      ". O O\n",
      "O X O\n",
      "X . X\n",
      "\n",
      "Mid. P1 reward = 0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = 0.10000000223517418\n",
      "\n",
      "Round 8 - Player 1 ( X )\n",
      "X O O\n",
      "O X O\n",
      "X . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.8500000000000001\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      ". . O\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "X . O\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". O .\n",
      ". X .\n",
      "X . O\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". O X\n",
      ". X .\n",
      "X . O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      ". . O\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . O\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . .\n",
      "O X .\n",
      ". . O\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . .\n",
      "O X .\n",
      "X . O\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . .\n",
      "O X .\n",
      "X O O\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". . X\n",
      "O X .\n",
      "X O O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". O .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". O .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      "O . .\n",
      ". O .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      "O . X\n",
      ". O .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      "O . X\n",
      ". O O\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "O X X\n",
      ". O O\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      "O X X\n",
      ". O O\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 8 - Player 1 ( X )\n",
      "O X X\n",
      ". O O\n",
      "X O X\n",
      "\n",
      "\n",
      "Round 9 - Player 2 ( O )\n",
      "O X X\n",
      "O O O\n",
      "X O X\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.4000000037252902\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". O .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". O .\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". O .\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". O X\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      ". O X\n",
      "O X O\n",
      "O . X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 8 - Player 1 ( X )\n",
      "X O X\n",
      "O X O\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.85\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". O O\n",
      ". X .\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". O O\n",
      ". X .\n",
      "X . X\n",
      "Pattern: row_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      ". O O\n",
      ". X .\n",
      "X O X\n",
      "\n",
      "Mid. P1 reward = 0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = 0.10000000223517418\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      "X O O\n",
      ". X .\n",
      "X O X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.8500000000000001\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      ". . O\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "X . O\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". O .\n",
      ". X .\n",
      "X . O\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". O X\n",
      ". X .\n",
      "X . O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      ". . O\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . O\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . .\n",
      ". X O\n",
      ". . O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . .\n",
      ". X O\n",
      "X . O\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      ". X O\n",
      "X . O\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.1500000014901162\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      "O . .\n",
      ". . .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      "O . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      "O O .\n",
      ". X .\n",
      ". . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      "O O .\n",
      ". X .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      "O O .\n",
      ". X .\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "O O .\n",
      ". X .\n",
      "X O X\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      "O O .\n",
      ". X O\n",
      "X O X\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 8 - Player 1 ( X )\n",
      "O O X\n",
      ". X O\n",
      "X O X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.749999998509884\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      ". . O\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "X . O\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "X . O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . O\n",
      ". X .\n",
      "X . O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "X . O\n",
      ". X .\n",
      "X O O\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      "X . O\n",
      ". X X\n",
      "X O O\n",
      "Pattern: row_dead_2\n",
      "\n",
      "\n",
      "Round 8 - Player 2 ( O )\n",
      "X . O\n",
      "O X X\n",
      "X O O\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 9 - Player 1 ( X )\n",
      "X X O\n",
      "O X X\n",
      "X O O\n",
      "\n",
      "Tie\n",
      "P1 terminates. P1 reward = 0.0\n",
      "P1 episode reward = -0.14999999925494195\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . O\n",
      ". . .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      ". . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      "O X .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". . O\n",
      "O X .\n",
      "X O X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      ". O O\n",
      "O X .\n",
      "X O X\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 8 - Player 1 ( X )\n",
      "X O O\n",
      "O X .\n",
      "X O X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.7499999985098839\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". O .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". O .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". O .\n",
      ". O .\n",
      "X . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". O X\n",
      ". O .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". O X\n",
      ". O O\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X O X\n",
      ". O O\n",
      "X . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      "X O X\n",
      ". O O\n",
      "X O .\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.3000000029802323\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      "O . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      "O . .\n",
      ". X .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      "O . O\n",
      ". X .\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "O . O\n",
      ". X .\n",
      "X . X\n",
      "Pattern: row_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O . O\n",
      ". X O\n",
      "X . X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      "O X O\n",
      ". X O\n",
      "X . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 8 - Player 2 ( O )\n",
      "O X O\n",
      ". X O\n",
      "X O X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 9 - Player 1 ( X )\n",
      "O X O\n",
      "X X O\n",
      "X O X\n",
      "\n",
      "Tie\n",
      "P1 terminates. P1 reward = 0.0\n",
      "P1 episode reward = -0.14999999925494195\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      "O . O\n",
      ". X .\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "O . O\n",
      ". X .\n",
      "X . X\n",
      "Pattern: row_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O . O\n",
      ". X .\n",
      "X O X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      "O . O\n",
      ". X X\n",
      "X O X\n",
      "Pattern: row_dead_2\n",
      "\n",
      "\n",
      "Round 8 - Player 2 ( O )\n",
      "O O O\n",
      ". X X\n",
      "X O X\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.250000001490116\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". O .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". O .\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". O .\n",
      ". X .\n",
      "O O X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". O X\n",
      ". X .\n",
      "O O X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      ". O X\n",
      "O X .\n",
      "O O X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 8 - Player 1 ( X )\n",
      ". O X\n",
      "O X X\n",
      "O O X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.85\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". O O\n",
      ". X .\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". O O\n",
      ". X .\n",
      "X . X\n",
      "Pattern: row_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      ". O O\n",
      ". X .\n",
      "X O X\n",
      "\n",
      "Mid. P1 reward = 0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = 0.10000000223517418\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      "X O O\n",
      ". X .\n",
      "X O X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.8500000000000001\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      ". O .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". O .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O O .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O O X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O O X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      ". X .\n",
      "O O X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". O .\n",
      ". . .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". O .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". O O\n",
      ". X .\n",
      ". . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". O O\n",
      ". X .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". O O\n",
      "O X .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". O O\n",
      "O X .\n",
      "X . X\n",
      "Pattern: row_dead_2\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      "O O O\n",
      "O X .\n",
      "X . X\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.2500000022351743\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      "O . .\n",
      ". . .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      "O . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      "O . O\n",
      ". X .\n",
      ". . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      "O . O\n",
      ". X .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      "O . O\n",
      "O X .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "O . O\n",
      "O X .\n",
      "X . X\n",
      "Pattern: row_dead_2\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      "O . O\n",
      "O X O\n",
      "X . X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 8 - Player 1 ( X )\n",
      "O X O\n",
      "O X O\n",
      "X . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 9 - Player 2 ( O )\n",
      "O X O\n",
      "O X O\n",
      "X O X\n",
      "\n",
      "Tie\n",
      "P2 terminates. P1 reward = 0.0\n",
      "P1 episode reward = -0.2500000014901161\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X O\n",
      ". . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X O\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . .\n",
      ". X O\n",
      "X . O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      ". X O\n",
      "X . O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      ". O .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "X O .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . .\n",
      ". X O\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      ". X O\n",
      "X O .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". O .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". O .\n",
      ". X .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". O .\n",
      "O X .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". O X\n",
      "O X .\n",
      "X . .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . O\n",
      ". . .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X O\n",
      ". . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X O\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      "O . O\n",
      ". X O\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "O . O\n",
      ". X O\n",
      "X . X\n",
      "Pattern: row_dead_2\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      "O . O\n",
      ". X O\n",
      "X O X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 8 - Player 1 ( X )\n",
      "O X O\n",
      ". X O\n",
      "X O X\n",
      "\n",
      "\n",
      "Round 9 - Player 2 ( O )\n",
      "O X O\n",
      "O X O\n",
      "X O X\n",
      "\n",
      "Tie\n",
      "P2 terminates. P1 reward = 0.0\n",
      "P1 episode reward = -0.30000000223517415\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      "O . .\n",
      ". . .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      "O . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      "O . .\n",
      ". X .\n",
      ". O .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      "O . .\n",
      ". X .\n",
      "X O .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      "O . .\n",
      "O X .\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "O . .\n",
      "O X .\n",
      "X O X\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      "O . .\n",
      "O X O\n",
      "X O X\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 8 - Player 1 ( X )\n",
      "O . X\n",
      "O X O\n",
      "X O X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.7999999992549419\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". O .\n",
      ". . .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". O .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". O .\n",
      ". X .\n",
      ". O .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". O .\n",
      ". X .\n",
      "X O .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". O O\n",
      ". X .\n",
      "X O .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". O O\n",
      ". X .\n",
      "X O X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      "O O O\n",
      ". X .\n",
      "X O X\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.1500000007450581\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      ". O .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "X O .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". O .\n",
      ". X .\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". O .\n",
      ". X .\n",
      "X O X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      ". O .\n",
      "O X .\n",
      "X O X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      ". O X\n",
      "O X .\n",
      "X O X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.900000000745058\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      ". O .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". O .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      ". O O\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "X O O\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . .\n",
      ". X O\n",
      "X O O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". . X\n",
      ". X O\n",
      "X O O\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.7999999985098839\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      ". O .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "X O .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . .\n",
      ". X O\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      ". X O\n",
      "X O .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      "O . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      "O . .\n",
      ". X .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      "O O .\n",
      ". X .\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "O O X\n",
      ". X .\n",
      "X . .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "X . .\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      "O . O\n",
      ". X .\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "O . O\n",
      ". X .\n",
      "X . X\n",
      "Pattern: row_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O . O\n",
      ". X .\n",
      "X O X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      "O . O\n",
      ". X X\n",
      "X O X\n",
      "Pattern: row_dead_2\n",
      "\n",
      "\n",
      "Round 8 - Player 2 ( O )\n",
      "O O O\n",
      ". X X\n",
      "X O X\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.250000001490116\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . O\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X O\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      "O . .\n",
      ". X O\n",
      ". . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      "O . .\n",
      ". X O\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      "O . .\n",
      "O X O\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "O . X\n",
      "O X O\n",
      "X . .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      "O . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      "O . .\n",
      ". X .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      "O O .\n",
      ". X .\n",
      "X . .\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "O O X\n",
      ". X .\n",
      "X . .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". O .\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". O X\n",
      ". X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O O X\n",
      ". X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      "O O X\n",
      ". X X\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.85\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X O\n",
      ". . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X O\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      "O . .\n",
      ". X O\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "O . X\n",
      ". X O\n",
      "X . .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      ". . O\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . O\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      ". . O\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "X . O\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "X . O\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "X . O\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      "X . O\n",
      "O X O\n",
      "X . O\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.2500000022351743\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". O .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". O .\n",
      ". X .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". O .\n",
      ". X .\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". O .\n",
      ". X .\n",
      "X O X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      ". O .\n",
      ". X O\n",
      "X O X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      ". O X\n",
      ". X O\n",
      "X O X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.900000000745058\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      "O . .\n",
      ". . .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      "O . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      "O . .\n",
      ". X O\n",
      ". . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      "O . .\n",
      ". X O\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      "O . .\n",
      ". X O\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "O . X\n",
      ". X O\n",
      "X O .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . O\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X O\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". O .\n",
      ". X O\n",
      ". . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". O .\n",
      ". X O\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". O .\n",
      ". X O\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". O X\n",
      ". X O\n",
      "X O .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      ". O .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "X O .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . .\n",
      "O X .\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . .\n",
      "O X .\n",
      "X O X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      ". O .\n",
      "O X .\n",
      "X O X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      ". O X\n",
      "O X .\n",
      "X O X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.900000000745058\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . .\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      ". . X\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      ". O X\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      ". O X\n",
      "O X X\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.85\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      ". O .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". O .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      ". O .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "X O .\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". . O\n",
      "O X .\n",
      "X O X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      ". O O\n",
      "O X .\n",
      "X O X\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 8 - Player 1 ( X )\n",
      "X O O\n",
      "O X .\n",
      "X O X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.7499999985098839\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      "O X .\n",
      ". . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      "O X .\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      "O . .\n",
      "O X .\n",
      "X . .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "O . .\n",
      "O X .\n",
      "X . X\n",
      "Pattern: row_dead_2\n",
      "\n",
      "\n",
      "Round 6 - Player 2 ( O )\n",
      "O O .\n",
      "O X .\n",
      "X . X\n",
      "Pattern: row_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 7 - Player 1 ( X )\n",
      "O O X\n",
      "O X .\n",
      "X . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.85\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      "O . .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      "O X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . .\n",
      "O X O\n",
      ". . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . .\n",
      "O X O\n",
      "X . .\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . .\n",
      "O X O\n",
      "X O .\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". . X\n",
      "O X O\n",
      "X O .\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      "O . .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      "O X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . .\n",
      "O X .\n",
      "O . .\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * 0.1 = -0.1500000014901161\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . .\n",
      "O X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      "O . .\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P2\n",
      "P2 terminates. P1 reward = -1.0\n",
      "P1 episode reward = -1.1500000014901162\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". O .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". O .\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". O .\n",
      ". X .\n",
      "O O X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      ". O X\n",
      ". X .\n",
      "O O X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "\n",
      "Round 7 - Player 2 ( O )\n",
      ". O X\n",
      ". X O\n",
      "O O X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 8 - Player 1 ( X )\n",
      "X O X\n",
      ". X O\n",
      "O O X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.900000000745058\n",
      "Random Opponent:\n",
      "Avg Reward: 0.33\n",
      "Win Rate: 70.00%, Lose Rate: 20.00%, Tie Rate: 10.00%, Avg Step Count: 6.8, P1 Illegal Rate: 0.00%, P2 Illegal Rate: 0.00%\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 2 ( O )\n",
      ". . .\n",
      ". . .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 2 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "\n",
      "Round 3 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 4 - Player 1 ( X )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 5 - Player 2 ( O )\n",
      ". . O\n",
      "O X .\n",
      "O . X\n",
      "Pattern: col_dead_2\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * 0.1 = -0.05\n",
      "\n",
      "Round 6 - Player 1 ( X )\n",
      "X . O\n",
      "O X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.849999999254942\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "\n",
      "Round 1 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "\n",
      "Round 2 - Player 2 ( O )\n",
      ". . .\n",
      ". X .\n",
      "O . .\n",
      "\n",
      "Mid. P1 reward = -0.10000000149011612 - 0.5 * -1.4901161138336505e-09 = -0.10000000074505806\n",
      "\n",
      "Round 3 - Player 1 ( X )\n",
      ". . .\n",
      ". X .\n",
      "O . X\n",
      "Pattern: diag_dead_2\n",
      "\n",
      "\n",
      "Round 4 - Player 2 ( O )\n",
      ". . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Mid. P1 reward = 0.0 - 0.5 * -1.4901161138336505e-09 = 7.450580569168253e-10\n",
      "\n",
      "Round 5 - Player 1 ( X )\n",
      "X . O\n",
      ". X .\n",
      "O . X\n",
      "\n",
      "Winner: P1\n",
      "P1 terminates. P1 reward = 1.0\n",
      "P1 episode reward = 0.9\n",
      "Self-play (Policy V1):\n",
      "Avg Reward: 0.88\n",
      "Win Rate: 100.00%, Lose Rate: 0.00%, Tie Rate: 0.00%, Avg Step Count: 5.36, P1 Illegal Rate: 0.00%, P2 Illegal Rate: 0.00%\n",
      "INFO:tensorflow:Assets written to: logs/test_3x3_no_random/PPO trained against random policy_20250512_180146/policy_v2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: logs/test_3x3_no_random/PPO trained against random policy_20250512_180146/policy_v2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy V2 saved to logs/test_3x3_no_random/PPO trained against random policy_20250512_180146/policy_v2\n",
      "Metrics saved to logs/test_3x3_no_random/PPO trained against random policy_20250512_180146/metrics.npz\n",
      "Sleeping now...\n",
      "Closing PrintLogger...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Only tf.keras.optimizers.Optimiers are well supported, got a non-TF2 optimizer: <__main__.ScheduledAdamOptimizer object at 0x2b1ed8f10>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PrintLogger initialized. Starting training...\n",
      "Phase 1 - Iteration 1/1000\n",
      "Weights updated: True\n",
      "Loss: 57.1400\n",
      "Iteration 1 memory: 476.31 MB\n",
      "Phase 1 - Iteration 2/1000\n",
      "Weights updated: True\n",
      "Loss: 1.4176\n",
      "Iteration 2 memory: 477.11 MB\n",
      "Phase 1 - Iteration 3/1000\n",
      "Weights updated: True\n",
      "Loss: 1.0379\n",
      "Iteration 3 memory: 477.83 MB\n",
      "Phase 1 - Iteration 4/1000\n",
      "Weights updated: True\n",
      "Loss: 0.7200\n",
      "Iteration 4 memory: 478.50 MB\n",
      "Phase 1 - Iteration 5/1000\n",
      "Weights updated: True\n",
      "Loss: 1.1816\n",
      "Iteration 5 memory: 479.12 MB\n",
      "Phase 1 - Iteration 6/1000\n",
      "Weights updated: True\n",
      "Loss: 1.4076\n",
      "Iteration 6 memory: 479.62 MB\n",
      "Phase 1 - Iteration 7/1000\n",
      "Weights updated: True\n",
      "Loss: 1.6659\n",
      "Iteration 7 memory: 480.11 MB\n",
      "Phase 1 - Iteration 8/1000\n",
      "Weights updated: True\n",
      "Loss: 1.1001\n",
      "Iteration 8 memory: 480.59 MB\n",
      "Phase 1 - Iteration 9/1000\n",
      "Weights updated: True\n",
      "Loss: 1.3779\n",
      "Iteration 9 memory: 481.06 MB\n",
      "Phase 1 - Iteration 10/1000\n",
      "Weights updated: True\n",
      "Loss: 1.4923\n",
      "Iteration 10 memory: 481.53 MB\n",
      "Phase 1 - Iteration 11/1000\n",
      "Weights updated: True\n",
      "Loss: 1.5525\n",
      "Iteration 11 memory: 482.14 MB\n",
      "Phase 1 - Iteration 12/1000\n",
      "Weights updated: True\n",
      "Loss: 1.1948\n",
      "Iteration 12 memory: 482.84 MB\n",
      "Phase 1 - Iteration 13/1000\n",
      "Weights updated: True\n",
      "Loss: 1.0904\n",
      "Iteration 13 memory: 483.42 MB\n",
      "Phase 1 - Iteration 14/1000\n",
      "Weights updated: True\n",
      "Loss: 0.7875\n",
      "Iteration 14 memory: 483.95 MB\n",
      "Phase 1 - Iteration 15/1000\n",
      "Weights updated: True\n",
      "Loss: 1.6801\n",
      "Iteration 15 memory: 484.41 MB\n",
      "Phase 1 - Iteration 16/1000\n",
      "Weights updated: True\n",
      "Loss: 1.1356\n",
      "Iteration 16 memory: 484.91 MB\n",
      "Phase 1 - Iteration 17/1000\n",
      "Weights updated: True\n",
      "Loss: 1.2757\n",
      "Iteration 17 memory: 485.41 MB\n",
      "Phase 1 - Iteration 18/1000\n",
      "Weights updated: True\n",
      "Loss: 1.2570\n",
      "Iteration 18 memory: 485.86 MB\n",
      "Phase 1 - Iteration 19/1000\n",
      "Weights updated: True\n",
      "Loss: 0.9782\n",
      "Iteration 19 memory: 486.33 MB\n",
      "Phase 1 - Iteration 20/1000\n",
      "\n",
      "Training interrupted. Saving policy and metrics...\n",
      "Metrics saved to logs/test_3x3_no_random/PPO trained by self-play_20250512_180425/metrics.npz\n",
      "INFO:tensorflow:Assets written to: logs/test_3x3_no_random/PPO trained by self-play_20250512_180425/policy_v1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: logs/test_3x3_no_random/PPO trained by self-play_20250512_180425/policy_v1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy V1 saved to logs/test_3x3_no_random/PPO trained by self-play_20250512_180425/policy_v1\n",
      "INFO:tensorflow:Assets written to: logs/test_3x3_no_random/PPO trained by self-play_20250512_180425/policy_v2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: logs/test_3x3_no_random/PPO trained by self-play_20250512_180425/policy_v2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy V2 saved to logs/test_3x3_no_random/PPO trained by self-play_20250512_180425/policy_v2\n",
      "Closing PrintLogger...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Only tf.keras.optimizers.Optimiers are well supported, got a non-TF2 optimizer: <__main__.ScheduledAdamOptimizer object at 0x2b1eefdd0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PrintLogger initialized. Starting training...\n",
      "Phase 1 - Iteration 1/10\n",
      "Weights updated: True\n",
      "Loss: 51.6583\n",
      "Iteration 1 memory: 493.91 MB\n",
      "Phase 1 - Iteration 2/10\n",
      "Weights updated: True\n",
      "Loss: 1.7028\n",
      "Iteration 2 memory: 494.53 MB\n",
      "Phase 1 - Iteration 3/10\n",
      "Weights updated: True\n",
      "Loss: 1.1683\n",
      "Iteration 3 memory: 495.27 MB\n",
      "Phase 1 - Iteration 4/10\n",
      "Weights updated: True\n",
      "Loss: 1.2776\n",
      "Iteration 4 memory: 495.84 MB\n",
      "Phase 1 - Iteration 5/10\n",
      "Weights updated: True\n",
      "Loss: 1.1655\n",
      "Iteration 5 memory: 496.41 MB\n",
      "Phase 1 - Iteration 6/10\n",
      "Weights updated: True\n",
      "Loss: 1.3747\n",
      "Iteration 6 memory: 496.91 MB\n",
      "Phase 1 - Iteration 7/10\n",
      "Weights updated: True\n",
      "Loss: 1.6819\n",
      "Iteration 7 memory: 497.48 MB\n",
      "Phase 1 - Iteration 8/10\n",
      "Weights updated: True\n",
      "Loss: 1.7542\n",
      "Iteration 8 memory: 497.95 MB\n",
      "Phase 1 - Iteration 9/10\n",
      "Weights updated: True\n",
      "Loss: 1.4530\n",
      "Iteration 9 memory: 498.44 MB\n",
      "Phase 1 - Iteration 10/10\n",
      "Weights updated: True\n",
      "Loss: 1.3151\n",
      "Iteration 10 memory: 498.95 MB\n",
      "INFO:tensorflow:Assets written to: logs/test_3x3_no_random/PPO trained by self-play_20250512_180446/policy_v1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: logs/test_3x3_no_random/PPO trained by self-play_20250512_180446/policy_v1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy V1 saved to logs/test_3x3_no_random/PPO trained by self-play_20250512_180446/policy_v1\n",
      "Phase 2 - Iteration 11/20\n",
      "Weights updated: True\n",
      "Loss: 1.4749\n",
      "Iteration 11 memory: 502.91 MB\n",
      "Phase 2 - Iteration 12/20\n",
      "Weights updated: True\n",
      "Loss: 1.6755\n",
      "Iteration 12 memory: 503.66 MB\n",
      "Phase 2 - Iteration 13/20\n",
      "Weights updated: True\n",
      "Loss: 1.4029\n",
      "Iteration 13 memory: 504.48 MB\n",
      "Phase 2 - Iteration 14/20\n",
      "\n",
      "Training interrupted. Saving policy and metrics...\n",
      "Metrics saved to logs/test_3x3_no_random/PPO trained by self-play_20250512_180446/metrics.npz\n",
      "INFO:tensorflow:Assets written to: logs/test_3x3_no_random/PPO trained by self-play_20250512_180446/policy_v1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: logs/test_3x3_no_random/PPO trained by self-play_20250512_180446/policy_v1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy V1 saved to logs/test_3x3_no_random/PPO trained by self-play_20250512_180446/policy_v1\n",
      "INFO:tensorflow:Assets written to: logs/test_3x3_no_random/PPO trained by self-play_20250512_180446/policy_v2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: logs/test_3x3_no_random/PPO trained by self-play_20250512_180446/policy_v2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy V2 saved to logs/test_3x3_no_random/PPO trained by self-play_20250512_180446/policy_v2\n",
      "Closing PrintLogger...\n"
     ]
    }
   ],
   "source": [
    "board_size = (3, 3)\n",
    "win_condition = [3, 3, 3]\n",
    "def_level = 0.5\n",
    "place_prob = 1\n",
    "unplayable_grids = np.zeros(board_size)\n",
    "rewards = {\n",
    "    'win': 1.0, 'lose': -1.0, 'tie': 0.0, 'illegal': -1.0, 'forfeited': 0.0, 'step': -0.1,\n",
    "    'row_dead_2': 0.1,\n",
    "    'col_dead_2': 0.1,\n",
    "    'diag_dead_2': 0.1\n",
    "}\n",
    "\n",
    "config = {\n",
    "    'board_size': board_size,\n",
    "    'win_condition': win_condition,\n",
    "    'unplayable_grids': unplayable_grids,\n",
    "    'rewards': rewards,\n",
    "    'def_level': def_level,\n",
    "    'place_prob': place_prob,\n",
    "    'phase1_iterations': 1000,\n",
    "    'phase2_iterations': 1000,\n",
    "    'num_collect_episodes': 10,\n",
    "    'random_proportion': 1,\n",
    "    'num_eval_episodes': 50,\n",
    "    'eval_interval': 50,\n",
    "    'initial_learning_rate': 5e-4,\n",
    "    'end_learning_rate': 1e-4,\n",
    "    'decay_steps': 2000,\n",
    "    'fc_layer_params': (64,),\n",
    "    'train_log_dir': os.path.join('logs/test_3x3_no_random', f\"PPO trained against random policy_{datetime.now().strftime('%Y%m%d_%H%M%S')}\")\n",
    "}\n",
    "\n",
    "log_file = os.path.join(config['train_log_dir'], 'terminal_output.log')\n",
    "try:\n",
    "    os.makedirs(config['train_log_dir'], exist_ok=True)\n",
    "    if not os.access(config['train_log_dir'], os.W_OK):\n",
    "        raise PermissionError(f\"No write permission for directory: {config['train_log_dir']}\")\n",
    "    sys.stdout = PrintLogger(sys.stdout, log_file)\n",
    "    sys.stderr = PrintLogger(sys.stderr, log_file)\n",
    "    print(\"PrintLogger initialized. Starting training...\")\n",
    "    \n",
    "    # Optionally resume from a checkpoint\n",
    "    resume_checkpoint = None\n",
    "    trainer = PPOTrainer(config, resume_from_checkpoint=resume_checkpoint)\n",
    "    trainer.train()\n",
    "except OSError as e:\n",
    "    print(f\"Failed to initialize PrintLogger: {e}\", file=sys.__stdout__)\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb53220",
   "metadata": {},
   "source": [
    "# 3x3_No random_agent trained by self-play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a560f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Only tf.keras.optimizers.Optimiers are well supported, got a non-TF2 optimizer: <__main__.ScheduledAdamOptimizer object at 0x297f38690>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PrintLogger initialized. Starting training...\n",
      "Phase 1 - Iteration 1/10\n",
      "WARNING:tensorflow:From /var/folders/zg/3l3tmlk16w55k4mhcm059hn80000gn/T/ipykernel_94162/2836184389.py:247: ReplayBuffer.gather_all (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=True)` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/folders/zg/3l3tmlk16w55k4mhcm059hn80000gn/T/ipykernel_94162/2836184389.py:247: ReplayBuffer.gather_all (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=True)` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights updated: True\n",
      "Loss: 67.0096\n",
      "Iteration 1 memory: 435.77 MB\n",
      "Phase 1 - Iteration 2/10\n",
      "Weights updated: True\n",
      "Loss: 1.6868\n",
      "Iteration 2 memory: 437.22 MB\n",
      "Phase 1 - Iteration 3/10\n",
      "Weights updated: True\n",
      "Loss: 1.0518\n",
      "Iteration 3 memory: 438.19 MB\n",
      "Phase 1 - Iteration 4/10\n",
      "Weights updated: True\n",
      "Loss: 1.5383\n",
      "Iteration 4 memory: 439.19 MB\n",
      "Phase 1 - Iteration 5/10\n",
      "Weights updated: True\n",
      "Loss: 1.5510\n",
      "Iteration 5 memory: 440.05 MB\n",
      "Phase 1 - Iteration 6/10\n",
      "Weights updated: True\n",
      "Loss: 1.3818\n",
      "Iteration 6 memory: 440.62 MB\n",
      "Phase 1 - Iteration 7/10\n",
      "Weights updated: True\n",
      "Loss: 1.3638\n",
      "Iteration 7 memory: 441.25 MB\n",
      "Phase 1 - Iteration 8/10\n",
      "Weights updated: True\n",
      "Loss: 1.1466\n",
      "Iteration 8 memory: 441.73 MB\n",
      "Phase 1 - Iteration 9/10\n",
      "Weights updated: True\n",
      "Loss: 1.5619\n",
      "Iteration 9 memory: 442.44 MB\n",
      "Phase 1 - Iteration 10/10\n",
      "Weights updated: True\n",
      "Loss: 1.2079\n",
      "Iteration 10 memory: 443.34 MB\n",
      "INFO:tensorflow:Assets written to: logs/test_3x3_no_random/PPO trained by self-play_20250512_180529/policy_v1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: logs/test_3x3_no_random/PPO trained by self-play_20250512_180529/policy_v1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy V1 saved to logs/test_3x3_no_random/PPO trained by self-play_20250512_180529/policy_v1\n",
      "Phase 2 - Iteration 11/20\n",
      "Weights updated: True\n",
      "Loss: 1.3029\n",
      "Iteration 11 memory: 459.45 MB\n",
      "Phase 2 - Iteration 12/20\n",
      "Weights updated: True\n",
      "Loss: 1.2683\n",
      "Iteration 12 memory: 460.33 MB\n",
      "Phase 2 - Iteration 13/20\n",
      "Weights updated: True\n",
      "Loss: 1.2252\n",
      "Iteration 13 memory: 460.98 MB\n",
      "Phase 2 - Iteration 14/20\n",
      "Weights updated: True\n",
      "Loss: 1.4602\n",
      "Iteration 14 memory: 461.59 MB\n",
      "Phase 2 - Iteration 15/20\n",
      "Weights updated: True\n",
      "Loss: 1.2661\n",
      "Iteration 15 memory: 462.08 MB\n",
      "Phase 2 - Iteration 16/20\n",
      "Weights updated: True\n",
      "Loss: 1.2976\n",
      "Iteration 16 memory: 462.66 MB\n",
      "Phase 2 - Iteration 17/20\n",
      "Weights updated: True\n",
      "Loss: 1.2963\n",
      "Iteration 17 memory: 463.20 MB\n",
      "Phase 2 - Iteration 18/20\n",
      "Weights updated: True\n",
      "Loss: 1.2033\n",
      "Iteration 18 memory: 463.70 MB\n",
      "Phase 2 - Iteration 19/20\n",
      "Weights updated: True\n",
      "Loss: 1.2687\n",
      "Iteration 19 memory: 464.23 MB\n",
      "Phase 2 - Iteration 20/20\n",
      "Weights updated: True\n",
      "Loss: 1.0359\n",
      "Iteration 20 memory: 464.80 MB\n",
      "INFO:tensorflow:Assets written to: logs/test_3x3_no_random/PPO trained by self-play_20250512_180529/policy_v2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: logs/test_3x3_no_random/PPO trained by self-play_20250512_180529/policy_v2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy V2 saved to logs/test_3x3_no_random/PPO trained by self-play_20250512_180529/policy_v2\n",
      "Metrics saved to logs/test_3x3_no_random/PPO trained by self-play_20250512_180529/metrics.npz\n",
      "Sleeping now...\n",
      "Closing PrintLogger...\n"
     ]
    }
   ],
   "source": [
    "board_size = (3, 3)\n",
    "win_condition = [3, 3, 3]\n",
    "def_level = 0.5\n",
    "place_prob = 1\n",
    "unplayable_grids = np.zeros(board_size)\n",
    "rewards = {\n",
    "    'win': 1.0, 'lose': -1.0, 'tie': 0.0, 'illegal': -1.0, 'forfeited': 0.0, 'step': -0.1,\n",
    "    'row_dead_2': 0.1,\n",
    "    'col_dead_2': 0.1,\n",
    "    'diag_dead_2': 0.1\n",
    "}\n",
    "\n",
    "config = {\n",
    "    'board_size': board_size,\n",
    "    'win_condition': win_condition,\n",
    "    'unplayable_grids': unplayable_grids,\n",
    "    'rewards': rewards,\n",
    "    'def_level': def_level,\n",
    "    'place_prob': place_prob,\n",
    "    'phase1_iterations': 1000,\n",
    "    'phase2_iterations': 1000,\n",
    "    'num_collect_episodes': 10,\n",
    "    'random_proportion': 0.75,\n",
    "    'num_eval_episodes': 50,\n",
    "    'eval_interval': 50,\n",
    "    'initial_learning_rate': 5e-4,\n",
    "    'end_learning_rate': 1e-4,\n",
    "    'decay_steps': 2000,\n",
    "    'fc_layer_params': (64,),\n",
    "    'train_log_dir': os.path.join('logs/test_3x3_no_random', f\"PPO trained by self-play_{datetime.now().strftime('%Y%m%d_%H%M%S')}\")\n",
    "}\n",
    "\n",
    "log_file = os.path.join(config['train_log_dir'], 'terminal_output.log')\n",
    "try:\n",
    "    os.makedirs(config['train_log_dir'], exist_ok=True)\n",
    "    if not os.access(config['train_log_dir'], os.W_OK):\n",
    "        raise PermissionError(f\"No write permission for directory: {config['train_log_dir']}\")\n",
    "    sys.stdout = PrintLogger(sys.stdout, log_file)\n",
    "    sys.stderr = PrintLogger(sys.stderr, log_file)\n",
    "    print(\"PrintLogger initialized. Starting training...\")\n",
    "    \n",
    "    # Optionally resume from a checkpoint\n",
    "    resume_checkpoint = None\n",
    "    trainer = PPOTrainer(config, resume_from_checkpoint=resume_checkpoint)\n",
    "    trainer.train()\n",
    "except OSError as e:\n",
    "    print(f\"Failed to initialize PrintLogger: {e}\", file=sys.__stdout__)\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec5436f",
   "metadata": {},
   "source": [
    "# 3x3_With random_trained solely against random agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb64927",
   "metadata": {},
   "outputs": [],
   "source": [
    "board_size = (3, 3)\n",
    "win_condition = [3, 3, 3]\n",
    "def_level = 0.5\n",
    "place_prob = 0.5\n",
    "unplayable_grids = np.zeros(board_size)\n",
    "rewards = {\n",
    "    'win': 1.0, 'lose': -1.0, 'tie': 0.0, 'illegal': -1.0, 'forfeited': 0.0, 'step': -0.1,\n",
    "    'row_dead_2': 0.1,\n",
    "    'col_dead_2': 0.1,\n",
    "    'diag_dead_2': 0.1\n",
    "}\n",
    "\n",
    "config = {\n",
    "    'board_size': board_size,\n",
    "    'win_condition': win_condition,\n",
    "    'unplayable_grids': unplayable_grids,\n",
    "    'rewards': rewards,\n",
    "    'def_level': def_level,\n",
    "    'place_prob': place_prob,\n",
    "    'phase1_iterations': 1000,\n",
    "    'phase2_iterations': 1000,\n",
    "    'num_collect_episodes': 10,\n",
    "    'random_proportion': 1,\n",
    "    'num_eval_episodes': 50,\n",
    "    'eval_interval': 50,\n",
    "    'initial_learning_rate': 5e-4,\n",
    "    'end_learning_rate': 1e-4,\n",
    "    'decay_steps': 2000,\n",
    "    'fc_layer_params': (64,),\n",
    "    'train_log_dir': os.path.join('logs/test_3x3_with_random', f\"PPO trained against random policy_{datetime.now().strftime('%Y%m%d_%H%M%S')}\")\n",
    "}\n",
    "\n",
    "log_file = os.path.join(config['train_log_dir'], 'terminal_output.log')\n",
    "try:\n",
    "    os.makedirs(config['train_log_dir'], exist_ok=True)\n",
    "    if not os.access(config['train_log_dir'], os.W_OK):\n",
    "        raise PermissionError(f\"No write permission for directory: {config['train_log_dir']}\")\n",
    "    sys.stdout = PrintLogger(sys.stdout, log_file)\n",
    "    sys.stderr = PrintLogger(sys.stderr, log_file)\n",
    "    print(\"PrintLogger initialized. Starting training...\")\n",
    "    \n",
    "    # Optionally resume from a checkpoint\n",
    "    resume_checkpoint = None\n",
    "    trainer = PPOTrainer(config, resume_from_checkpoint=resume_checkpoint)\n",
    "    trainer.train()\n",
    "except OSError as e:\n",
    "    print(f\"Failed to initialize PrintLogger: {e}\", file=sys.__stdout__)\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6ade37",
   "metadata": {},
   "source": [
    "# 3x3_With random_trained by self-play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328f1a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "board_size = (3, 3)\n",
    "win_condition = [3, 3, 3]\n",
    "def_level = 0.5\n",
    "place_prob = 0.5\n",
    "unplayable_grids = np.zeros(board_size)\n",
    "rewards = {\n",
    "    'win': 1.0, 'lose': -1.0, 'tie': 0.0, 'illegal': -1.0, 'forfeited': 0.0, 'step': -0.1,\n",
    "    'row_dead_2': 0.1,\n",
    "    'col_dead_2': 0.1,\n",
    "    'diag_dead_2': 0.1\n",
    "}\n",
    "\n",
    "config = {\n",
    "    'board_size': board_size,\n",
    "    'win_condition': win_condition,\n",
    "    'unplayable_grids': unplayable_grids,\n",
    "    'rewards': rewards,\n",
    "    'def_level': def_level,\n",
    "    'place_prob': place_prob,\n",
    "    'phase1_iterations': 1000,\n",
    "    'phase2_iterations': 1000,\n",
    "    'num_collect_episodes': 10,\n",
    "    'random_proportion': 0.75,\n",
    "    'num_eval_episodes': 50,\n",
    "    'eval_interval': 50,\n",
    "    'initial_learning_rate': 5e-4,\n",
    "    'end_learning_rate': 1e-4,\n",
    "    'decay_steps': 2000,\n",
    "    'fc_layer_params': (64,),\n",
    "    'train_log_dir': os.path.join('logs/test_3x3_with_random', f\"PPO trained by self-play_{datetime.now().strftime('%Y%m%d_%H%M%S')}\")\n",
    "}\n",
    "\n",
    "log_file = os.path.join(config['train_log_dir'], 'terminal_output.log')\n",
    "try:\n",
    "    os.makedirs(config['train_log_dir'], exist_ok=True)\n",
    "    if not os.access(config['train_log_dir'], os.W_OK):\n",
    "        raise PermissionError(f\"No write permission for directory: {config['train_log_dir']}\")\n",
    "    sys.stdout = PrintLogger(sys.stdout, log_file)\n",
    "    sys.stderr = PrintLogger(sys.stderr, log_file)\n",
    "    print(\"PrintLogger initialized. Starting training...\")\n",
    "    \n",
    "    # Optionally resume from a checkpoint\n",
    "    resume_checkpoint = None\n",
    "    trainer = PPOTrainer(config, resume_from_checkpoint=resume_checkpoint)\n",
    "    trainer.train()\n",
    "except OSError as e:\n",
    "    print(f\"Failed to initialize PrintLogger: {e}\", file=sys.__stdout__)\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef9fe9e",
   "metadata": {},
   "source": [
    "# 12x12_With random_trained solely against random agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716112c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "board_size = (12, 12)\n",
    "win_condition = [4, 4, 5]\n",
    "def_level = 0.5\n",
    "place_prob = 0.5\n",
    "unplayable_grids = np.zeros(board_size)\n",
    "corner_size = 4\n",
    "unplayable_grids[:corner_size, :corner_size] = 1\n",
    "unplayable_grids[:corner_size, -corner_size:] = 1\n",
    "unplayable_grids[-corner_size:, :corner_size] = 1\n",
    "unplayable_grids[-corner_size:, -corner_size:] = 1\n",
    "\n",
    "rewards = {\n",
    "    'win': 1.0, 'lose': -1.0, 'tie': 0.0, 'illegal': -1.0, 'forfeited': 0.0, 'step': -0.06,\n",
    "    'row_live_3': 0.16, 'row_dead_3': 0.08, 'row_live_2': 0.04, 'row_dead_2': 0.02,\n",
    "    'col_live_3': 0.16, 'col_dead_3': 0.08, 'col_live_2': 0.04, 'col_dead_2': 0.02,\n",
    "    'diag_live_4': 0.16, 'diag_dead_4': 0.08, 'diag_live_3': 0.04, 'diag_dead_3': 0.02, 'diag_live_2': 0.01, 'diag_dead_2': 0.005\n",
    "}\n",
    "\n",
    "config = {\n",
    "    'board_size': board_size,\n",
    "    'win_condition': win_condition,\n",
    "    'unplayable_grids': unplayable_grids,\n",
    "    'rewards': rewards,\n",
    "    'def_level': def_level,\n",
    "    'place_prob': place_prob,\n",
    "    'phase1_iterations': 1000,\n",
    "    'phase2_iterations': 1000,\n",
    "    'num_collect_episodes': 10,\n",
    "    'random_proportion': 1,\n",
    "    'num_eval_episodes': 50,\n",
    "    'eval_interval': 50,\n",
    "    'initial_learning_rate': 5e-4,\n",
    "    'end_learning_rate': 1e-4,\n",
    "    'decay_steps': 2000,\n",
    "    'fc_layer_params': (64,),\n",
    "    'train_log_dir': os.path.join('logs/test_12x12_with_random', f\"PPO trained against random policy_{datetime.now().strftime('%Y%m%d_%H%M%S')}\")\n",
    "}\n",
    "\n",
    "log_file = os.path.join(config['train_log_dir'], 'terminal_output.log')\n",
    "try:\n",
    "    os.makedirs(config['train_log_dir'], exist_ok=True)\n",
    "    if not os.access(config['train_log_dir'], os.W_OK):\n",
    "        raise PermissionError(f\"No write permission for directory: {config['train_log_dir']}\")\n",
    "    sys.stdout = PrintLogger(sys.stdout, log_file)\n",
    "    sys.stderr = PrintLogger(sys.stderr, log_file)\n",
    "    print(\"PrintLogger initialized. Starting training...\")\n",
    "    \n",
    "    # Optionally resume from a checkpoint\n",
    "    resume_checkpoint = None\n",
    "    trainer = PPOTrainer(config, resume_from_checkpoint=resume_checkpoint)\n",
    "    trainer.train()\n",
    "except OSError as e:\n",
    "    print(f\"Failed to initialize PrintLogger: {e}\", file=sys.__stdout__)\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2f438d",
   "metadata": {},
   "source": [
    "# 12x12_With random_trained by self-play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "400ba897",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Only tf.keras.optimizers.Optimiers are well supported, got a non-TF2 optimizer: <__main__.ScheduledAdamOptimizer object at 0x1194e8790>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PrintLogger initialized. Starting training...\n",
      "Phase 1 - Iteration 1/1000\n",
      "WARNING:tensorflow:From /var/folders/zg/3l3tmlk16w55k4mhcm059hn80000gn/T/ipykernel_94209/2836184389.py:247: ReplayBuffer.gather_all (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=True)` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/folders/zg/3l3tmlk16w55k4mhcm059hn80000gn/T/ipykernel_94209/2836184389.py:247: ReplayBuffer.gather_all (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=True)` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights updated: True\n",
      "Loss: 221.1087\n",
      "Iteration 1 memory: 519.23 MB\n",
      "Phase 1 - Iteration 2/1000\n",
      "Weights updated: True\n",
      "Loss: 14.2152\n",
      "Iteration 2 memory: 533.59 MB\n",
      "Phase 1 - Iteration 3/1000\n",
      "Weights updated: True\n",
      "Loss: 13.3386\n",
      "Iteration 3 memory: 546.30 MB\n",
      "Phase 1 - Iteration 4/1000\n",
      "Weights updated: True\n",
      "Loss: 11.8281\n",
      "Iteration 4 memory: 555.42 MB\n",
      "Phase 1 - Iteration 5/1000\n",
      "Weights updated: True\n",
      "Loss: 12.3907\n",
      "Iteration 5 memory: 562.61 MB\n",
      "Phase 1 - Iteration 6/1000\n",
      "Weights updated: True\n",
      "Loss: 14.5515\n",
      "Iteration 6 memory: 575.38 MB\n",
      "Phase 1 - Iteration 7/1000\n",
      "Weights updated: True\n",
      "Loss: 12.7034\n",
      "Iteration 7 memory: 577.70 MB\n",
      "Phase 1 - Iteration 8/1000\n",
      "\n",
      "Training interrupted. Saving policy and metrics...\n",
      "Metrics saved to logs/test_12x12_with_random/PPO trained by self-play_20250512_181046/metrics.npz\n",
      "INFO:tensorflow:Assets written to: logs/test_12x12_with_random/PPO trained by self-play_20250512_181046/policy_v1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: logs/test_12x12_with_random/PPO trained by self-play_20250512_181046/policy_v1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy V1 saved to logs/test_12x12_with_random/PPO trained by self-play_20250512_181046/policy_v1\n",
      "INFO:tensorflow:Assets written to: logs/test_12x12_with_random/PPO trained by self-play_20250512_181046/policy_v2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: logs/test_12x12_with_random/PPO trained by self-play_20250512_181046/policy_v2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy V2 saved to logs/test_12x12_with_random/PPO trained by self-play_20250512_181046/policy_v2\n",
      "Closing PrintLogger...\n"
     ]
    }
   ],
   "source": [
    "board_size = (12, 12)\n",
    "win_condition = [4, 4, 5]\n",
    "def_level = 0.5\n",
    "place_prob = 0.5\n",
    "unplayable_grids = np.zeros(board_size)\n",
    "corner_size = 4\n",
    "unplayable_grids[:corner_size, :corner_size] = 1\n",
    "unplayable_grids[:corner_size, -corner_size:] = 1\n",
    "unplayable_grids[-corner_size:, :corner_size] = 1\n",
    "unplayable_grids[-corner_size:, -corner_size:] = 1\n",
    "\n",
    "rewards = {\n",
    "    'win': 1.0, 'lose': -1.0, 'tie': 0.0, 'illegal': -1.0, 'forfeited': 0.0, 'step': -0.06,\n",
    "    'row_live_3': 0.16, 'row_dead_3': 0.08, 'row_live_2': 0.04, 'row_dead_2': 0.02,\n",
    "    'col_live_3': 0.16, 'col_dead_3': 0.08, 'col_live_2': 0.04, 'col_dead_2': 0.02,\n",
    "    'diag_live_4': 0.16, 'diag_dead_4': 0.08, 'diag_live_3': 0.04, 'diag_dead_3': 0.02, 'diag_live_2': 0.01, 'diag_dead_2': 0.005\n",
    "}\n",
    "\n",
    "config = {\n",
    "    'board_size': board_size,\n",
    "    'win_condition': win_condition,\n",
    "    'unplayable_grids': unplayable_grids,\n",
    "    'rewards': rewards,\n",
    "    'def_level': def_level,\n",
    "    'place_prob': place_prob,\n",
    "    'phase1_iterations': 1000,\n",
    "    'phase2_iterations': 1000,\n",
    "    'num_collect_episodes': 10,\n",
    "    'random_proportion': 0.75,\n",
    "    'num_eval_episodes': 50,\n",
    "    'eval_interval': 50,\n",
    "    'initial_learning_rate': 5e-4,\n",
    "    'end_learning_rate': 1e-4,\n",
    "    'decay_steps': 2000,\n",
    "    'fc_layer_params': (64,),\n",
    "    'train_log_dir': os.path.join('logs/test_12x12_with_random', f\"PPO trained by self-play_{datetime.now().strftime('%Y%m%d_%H%M%S')}\")\n",
    "}\n",
    "\n",
    "log_file = os.path.join(config['train_log_dir'], 'terminal_output.log')\n",
    "try:\n",
    "    os.makedirs(config['train_log_dir'], exist_ok=True)\n",
    "    if not os.access(config['train_log_dir'], os.W_OK):\n",
    "        raise PermissionError(f\"No write permission for directory: {config['train_log_dir']}\")\n",
    "    sys.stdout = PrintLogger(sys.stdout, log_file)\n",
    "    sys.stderr = PrintLogger(sys.stderr, log_file)\n",
    "    print(\"PrintLogger initialized. Starting training...\")\n",
    "    \n",
    "    # Optionally resume from a checkpoint\n",
    "    resume_checkpoint = None\n",
    "    trainer = PPOTrainer(config, resume_from_checkpoint=resume_checkpoint)\n",
    "    trainer.train()\n",
    "except OSError as e:\n",
    "    print(f\"Failed to initialize PrintLogger: {e}\", file=sys.__stdout__)\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea07009",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_standard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
